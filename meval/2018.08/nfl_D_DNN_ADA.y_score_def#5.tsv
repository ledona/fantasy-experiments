{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"], "extra_stats": [], "model_player_stat": null, "model_team_stat": "y_score_def#5", "player_stats": [], "prev_opp_team_stats": [], "team_stats": ["def_block_fg", "def_block_punt", "def_block_xpt", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds", "pts", "turnovers", "yds"]}, "impute": true, "models_path": "/Users/delano/working/fantasy/MODELS_keras", "normalize": true, "player_pos": []}, "datetime_utc": "20180820 033853", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.29.1-14-g5b7e911e", "filename_prefix": "nfl_D_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 1750, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 755690871, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-5.2121294	-0.0795281	tanh	0.5462667648	none	3	adagrad	1169	132	6	400	41
-5.3116746	-0.1267534	linear	0.6638996838	none	1	nadam	301	44	2	500	30
-5.5330236	-0.2350119	linear	0.6961837787	none	1	adam	442	88	4	400	93
-5.2895315	-0.2179959	sigmoid	0.5695481542	none	2	adagrad	926	154	7	900	90
-5.090795	-0.0858178	sigmoid	0.3901739926	none	1	adagrad	1453	154	7	900	50
-5.3149522	-0.2212013	tanh	0.3681169506	none	2	adamax	906	22	1	800	80
-4.9678091	-0.0381449	sigmoid	0.5832707232	none	1	adadelta	1416	88	4	600	89
-5.113528	-0.1024479	sigmoid	0.6732080428	none	1	adadelta	1599	154	7	800	97
-5.1640872	-0.1173097	sigmoid	0.4118486589	none	1	adadelta	1309	154	7	1000	100
-4.9482207	-0.0442572	sigmoid	0.5536645247	none	1	adadelta	1452	66	3	600	73
-4.7609222	0.0081221	sigmoid	0.6360300717	none	2	adamax	1555	44	2	100	66
-4.8232632	-0.0049096	sigmoid	0.3	none	3	adadelta	1550	22	1	100	55
-4.8280578	-0.0017567	sigmoid	0.6804599071	none	1	adamax	1509	22	1	100	33
-4.8112367	0.0046165	sigmoid	0.7	none	1	adagrad	1698	66	3	100	71
-4.8353648	0.0056823	sigmoid	0.6952772491	none	3	adamax	1572	44	2	100	88
-4.8219765	-0.0099832	sigmoid	0.356703631	none	1	adagrad	1750	22	1	100	20
-4.7725906	-0.0046197	linear	0.3	none	2	nadam	1606	44	2	100	20
-4.8764135	-0.0046293	linear	0.3	none	2	adadelta	1548	44	2	100	20
-4.8511047	-0.0140392	sigmoid	0.3012216722	none	2	nadam	1616	22	1	100	44
-4.8133216	0.0020094	sigmoid	0.5736190589	none	2	adam	1619	22	1	100	38
-4.7364966	-0.0153166	linear	0.6978211669	none	1	adagrad	1750	22	1	100	20
-4.735123	-0.0396336	linear	0.7	none	3	adagrad	1750	22	1	100	20
-4.7719726	0.00113	linear	0.7	none	3	adamax	1750	22	1	100	41
-4.9353206	-0.1906927	linear	0.7	none	5	adagrad	1750	22	1	100	20
-4.8057052	-0.0245227	relu	0.7	none	1	adagrad	1750	22	1	100	71
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7528379	-0.0026951	linear	0.6333588109	none	2	adagrad	1750	22	1	100	44
-4.7911734	0.0026298	linear	0.3498672053	none	2	adagrad	1750	22	1	1000	20
-4.7750232	-0.0204417	linear	0.7	none	2	adagrad	1685	44	2	200	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.789385	-0.0142286	linear	0.4917611109	none	2	adagrad	1750	22	1	100	20
-4.842439	-0.0096119	linear	0.3	none	1	adamax	1750	88	4	1000	20
-4.8431581	0.0056252	linear	0.3	none	2	nadam	1734	66	3	400	20
-4.8793396	-0.0112941	linear	0.7	none	2	adamax	1750	22	1	500	51
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7825457	-0.0272084	linear	0.7	none	1	adagrad	1750	154	7	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.8531303	-0.0048923	linear	0.3	none	5	adagrad	1750	22	1	1000	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20
-4.7232245	-0.024606	linear	0.7	none	2	adagrad	1750	22	1	100	20

{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["asst", "blks", "d_reb", "fg_att", "fg_made", "fouls", "ft_att", "ft_made", "o_reb", "op_asst", "op_fg_att", "op_fg_made", "op_ft_att", "op_ft_made", "op_o_reb", "op_pts", "op_tfg_att", "op_tfg_made", "pts", "stls", "tfg_att", "tfg_made", "turnovers"], "extra_stats": ["home_C", "player_home_H", "team_win"], "model_player_stat": "dk_score#2", "model_team_stat": null, "player_stats": ["asst", "blks", "d_reb", "fg_att", "fg_made", "fouls", "ft_att", "ft_made", "o_reb", "pm", "pts", "starter", "stls", "tfg_att", "tfg_made", "time", "turnovers"], "prev_opp_team_stats": [], "team_stats": ["asst", "blks", "d_reb", "fg_att", "fg_made", "fouls", "ft_att", "ft_made", "o_reb", "op_asst", "op_fg_att", "op_fg_made", "op_ft_att", "op_ft_made", "op_o_reb", "op_pts", "op_tfg_att", "op_tfg_made", "pts", "stls", "tfg_att", "tfg_made", "turnovers"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["C", "F", "G", "PF", "PG", "SF", "SG"]}, "datetime_utc": "20181112 155725", "db_id": 2, "db_path": "nba.db", "fantasy_version": "v0.31.1-41-g3fbe8bf", "filename_prefix": "nba_DNN_ADA", "folds": 3, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 32500, "increment": 1, "low": 500, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1570655238, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [20142015, 20152016, 20162017, 20172018]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-7.6857438	0.4826099	tanh	0.5833629948	none	2	adamax	24708	196	3	800	92
-9.2263882	0.2555155	relu	0.4689069249	none	3	nadam	7324	131	2	800	30
-7.9166454	0.469551	linear	0.6969342765	none	3	adadelta	13780	131	2	600	21
-10.3729826	0.0453955	relu	0.6403291198	none	3	nadam	13839	66	1	300	44
-8.095768	0.4463384	relu	0.5607232077	none	2	adadelta	17134	196	3	300	96
-9.0839026	0.2608208	relu	0.3726900276	none	4	adadelta	19123	326	5	400	51
-7.5053579	0.513907	relu	0.4073760437	none	2	adagrad	29629	326	5	800	47
-7.4525545	0.5165041	linear	0.5291777741	none	2	adagrad	32500	261	4	1000	20
-7.5282809	0.5194408	relu	0.3407341929	none	2	adagrad	32500	391	6	900	20
-7.6646449	0.4920556	linear	0.7	none	2	adagrad	30637	131	2	1000	38
-8.3257722	0.3657495	tanh	0.3179998062	none	2	adam	2613	131	2	1000	80
-7.5829863	0.5109058	linear	0.6959212569	none	3	adam	13869	391	6	600	42
-7.3189609	0.533572	linear	0.3	none	2	adagrad	32500	456	7	1000	20
-7.318789	0.5300375	linear	0.5276330368	none	1	adagrad	32500	456	7	600	20
-7.322371	0.5321473	linear	0.4521121536	none	1	adagrad	29875	456	7	600	43
-7.3625493	0.5294005	linear	0.7	none	1	adam	18503	326	5	600	100
-7.3729815	0.5287423	linear	0.5217007916	none	2	adagrad	32500	456	7	500	20
-7.5304874	0.5081116	linear	0.7	none	2	adagrad	32500	456	7	700	20
-7.3461671	0.5319569	linear	0.3	none	1	adagrad	26456	456	7	1000	91
-7.422208	0.5234986	linear	0.3	none	3	adagrad	19733	456	7	1000	20
-7.961355	0.4666813	relu	0.7	none	1	adamax	18282	66	1	200	100
-7.5533928	0.5042127	tanh	0.6313517204	none	1	adam	29665	456	7	500	100
-7.3779284	0.5270456	linear	0.7	none	1	adam	19466	456	7	900	44
-7.9715177	0.4428166	tanh	0.5691445244	none	1	adagrad	32500	66	1	400	20
-8.5397657	0.3581317	relu	0.7	none	1	adam	500	66	1	100	100
-7.3208164	0.5329251	linear	0.6518545073	none	1	adagrad	32500	326	5	700	100
-7.322515	0.5368506	linear	0.5514803273	none	1	adagrad	31572	456	7	700	98
-7.3955212	0.5281303	linear	0.7	none	1	adam	29545	391	6	700	100
-7.3146482	0.5330583	linear	0.6523797325	none	1	adagrad	32500	456	7	400	87
-8.0725062	0.445881	relu	0.6869948267	none	1	adam	25350	456	7	900	100
-7.3657683	0.5297683	linear	0.3360704981	none	2	adagrad	32500	326	5	800	20
-7.2973304	0.5352747	linear	0.5792827583	none	1	adagrad	32500	456	7	500	100
-7.5666087	0.502062	linear	0.5836558354	none	1	adagrad	32500	131	2	500	100
-7.3521406	0.5267941	linear	0.6177563453	none	1	adagrad	30530	456	7	200	33
-7.5553224	0.509727	relu	0.4631336592	none	1	adagrad	27538	261	4	1000	100
-7.3388878	0.529898	linear	0.5627440806	none	1	adamax	32500	391	6	500	100
-7.6145502	0.5051524	linear	0.7	none	1	adagrad	6711	391	6	600	100
-7.3397086	0.5331896	linear	0.5731226945	none	1	adagrad	32323	391	6	500	100
-7.3826384	0.5308138	linear	0.7	none	1	adamax	18453	326	5	500	100
-7.3030323	0.5341568	linear	0.3	none	2	adagrad	32500	456	7	500	100
-7.3318602	0.5338129	linear	0.3	none	1	adagrad	32500	391	6	800	100
-7.3039515	0.5343761	linear	0.6305943723	none	1	adagrad	25626	391	6	1000	100
-7.3440336	0.5318319	linear	0.4382317999	none	2	adagrad	22526	391	6	1000	100
-7.7777116	0.4885441	relu	0.3	none	2	adagrad	32500	131	2	900	100
-7.3941571	0.5259577	linear	0.6275198328	none	1	adagrad	22481	326	5	1000	100
-7.3175331	0.5340551	linear	0.3716425499	none	2	adagrad	32500	456	7	1000	100
-7.3601521	0.5317061	linear	0.4356545787	none	1	adamax	32500	456	7	1000	100
-7.3133835	0.5338607	linear	0.4957571328	none	1	adagrad	32500	456	7	500	100
-8.3551598	0.3307743	relu	0.7	none	1	adadelta	500	66	1	100	100
-12.8100845	-0.4510532	linear	0.3	none	1	adagrad	500	456	7	1000	100
-7.4410321	0.5319073	linear	0.7	none	1	adagrad	9060	456	7	400	100
-7.448125	0.514383	linear	0.7	none	1	adagrad	8968	326	5	500	100
-7.3780405	0.5250346	linear	0.3342865234	none	4	adagrad	23958	456	7	1000	100
-7.3391016	0.535477	linear	0.4646596036	none	1	adagrad	25765	456	7	1000	100
-7.3425165	0.5277894	linear	0.3608640809	none	1	adagrad	22197	391	6	1000	100
-7.5706403	0.5005716	tanh	0.7	none	1	adam	23054	456	7	500	100
-7.3209528	0.5308563	linear	0.4551525662	none	1	adagrad	23655	456	7	1000	100
-7.3313084	0.5349948	linear	0.61747698	none	1	adamax	32500	456	7	1000	100
-7.3491905	0.5346103	linear	0.4497516629	none	1	adagrad	23774	456	7	100	100
-8.2754386	0.410025	tanh	0.7	none	5	nadam	32500	456	7	300	94
-7.3077374	0.5336017	linear	0.447670427	none	1	adagrad	23910	456	7	1000	100
-7.762778	0.4836099	tanh	0.7	none	5	adadelta	27176	456	7	1000	100
-7.3274188	0.5313544	linear	0.3	none	2	adagrad	32171	456	7	1000	100
-7.5469494	0.508168	relu	0.4558191519	none	1	adagrad	32500	456	7	1000	100
-7.2949402	0.5344385	linear	0.4449461433	none	1	adagrad	23697	456	7	1000	100
-7.9938169	0.4565008	linear	0.6894928139	none	1	adam	32500	66	1	100	20
-7.3417488	0.5268859	linear	0.7	none	1	adagrad	20411	456	7	1000	100
-7.320134	0.5274731	linear	0.379200245	none	1	adagrad	23016	456	7	1000	20
-7.3787245	0.5255711	linear	0.5948940096	none	1	adam	25765	456	7	1000	100
-7.3462454	0.5375098	linear	0.3920643714	none	1	adagrad	22966	456	7	1000	100

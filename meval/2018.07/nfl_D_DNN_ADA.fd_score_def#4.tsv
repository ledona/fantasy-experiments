{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"], "extra_stats": [], "model_player_stat": null, "model_team_stat": "fd_score_def#4", "player_stats": [], "prev_opp_team_stats": [], "team_stats": ["def_block_fg", "def_block_punt", "def_block_xpt", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds", "pts", "turnovers", "yds"]}, "impute": true, "models_path": "/Users/delano/working/fantasy/MODELS_keras", "normalize": true, "player_pos": []}, "datetime_utc": "20180725 011505", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.28.3-31-g1679bfa5", "filename_prefix": "nfl_D_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 1750, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1198897890, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-5.2959154	-0.0895837	sigmoid	0.5287201651	none	3	adamax	118	110	5	300	49
-4.8243651	-0.0437337	linear	0.4162867402	none	2	nadam	1173	88	4	200	99
-5.1329546	-0.1796519	tanh	0.3336176637	none	3	adamax	1456	22	1	500	73
-4.9610774	-0.0440263	tanh	0.6669964898	none	2	adam	1091	66	3	800	23
-5.478224	-0.2554744	relu	0.3078899256	none	2	adam	1572	88	4	100	91
-5.3443408	-0.2005516	sigmoid	0.6271701729	none	4	adam	110	110	5	200	72
-5.1755339	-0.1311406	tanh	0.3374501083	none	2	nadam	1694	88	4	900	65
-4.7867736	0.0023319	linear	0.6094147924	none	4	nadam	1516	88	4	300	45
-4.7819066	0.0057235	linear	0.6668396997	none	5	nadam	1000	44	2	700	41
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-4.7176485	-0.0199371	linear	0.7	none	5	adam	100	22	1	1000	20
-5.462542	-0.4586185	linear	0.7	none	5	adagrad	100	22	1	1000	20
-4.7214421	-0.0116115	linear	0.7	none	5	adadelta	100	22	1	1000	20
-5.3069008	-0.3188305	relu	0.3021839072	none	4	adagrad	389	110	5	500	85
-5.4696811	-0.1997911	linear	0.3	none	5	adam	100	22	1	1000	20
-5.786266	-0.4048063	tanh	0.4900795826	none	5	adam	100	22	1	700	52
-5.376707	-0.1752497	linear	0.4707878923	none	5	nadam	100	22	1	1000	24
-4.7148731	0.0083614	linear	0.7	none	5	adam	1750	154	7	100	100
-5.0072508	-0.2450044	relu	0.7	none	5	adam	1750	154	7	100	100
-4.8287717	-0.0324734	linear	0.7	none	1	adam	1750	154	7	100	100
-4.7518413	0.0099462	linear	0.6978469468	none	5	adam	1548	154	7	100	100
-4.8206562	-0.0113702	linear	0.6470250406	none	5	adam	1750	132	6	100	100
-4.80104	0.0009355	linear	0.7	none	5	nadam	1750	44	2	700	32
-5.0447369	-0.064007	linear	0.7	none	4	adam	524	88	4	800	25
-4.9277423	-0.014871	linear	0.7	none	5	adam	432	22	1	1000	24
-4.7701013	0.0081087	linear	0.5696305619	none	5	nadam	1219	22	1	300	80
-4.8698769	-0.0005098	linear	0.7	none	5	nadam	1209	22	1	700	78
-4.9054306	-0.0074803	linear	0.551720179	none	5	nadam	1291	154	7	200	20
-4.7960642	-0.0081015	linear	0.5463657183	none	2	nadam	1044	22	1	1000	100
-4.84882	-0.0098911	linear	0.7	none	5	adamax	1691	154	7	900	79
-4.7495406	0.0066751	linear	0.7	none	5	adagrad	1696	154	7	1000	86
-4.6851751	-0.0040018	linear	0.7	none	5	adagrad	1700	154	7	300	93
-4.9107485	-0.17639	linear	0.7	none	5	adagrad	1702	154	7	100	96
-4.673762	0.0072967	linear	0.7	none	5	adagrad	1700	154	7	500	92
-4.7343104	-0.0045106	linear	0.7	none	5	adagrad	1701	154	7	400	79
-4.6542809	0.0045806	linear	0.7	none	5	adagrad	1699	154	7	400	100
-4.7016768	0.0068352	linear	0.7	none	5	adagrad	1702	154	7	600	100
-4.6796222	0.0082082	linear	0.7	none	5	adagrad	1699	110	5	400	98
-4.7232868	-0.0035427	linear	0.7	none	5	adagrad	1700	154	7	400	98
-4.7347486	0.0004989	linear	0.7	none	5	adagrad	1634	44	2	500	100
-4.9212046	-0.006918	linear	0.4949073687	none	5	nadam	1096	44	2	600	100
-4.7446138	-0.0007321	linear	0.7	none	5	adagrad	1750	132	6	500	100
-4.6514926	0.0022778	linear	0.7	none	5	adagrad	1597	154	7	400	100
-4.721816	0.0048343	linear	0.7	none	5	adagrad	1563	154	7	500	100
-4.686075	-0.0029439	linear	0.7	none	5	adagrad	1616	154	7	400	100
-4.7020763	-0.0033225	linear	0.7	none	5	adagrad	1649	154	7	400	100
-4.6819831	0.0041316	linear	0.7	none	5	adagrad	1653	154	7	400	100
-4.8249689	-0.0051114	linear	0.7	none	5	nadam	1656	154	7	300	100
-4.873782	-0.0024157	linear	0.5951614268	none	1	nadam	1345	22	1	700	100
-4.6738694	0.0046326	linear	0.7	none	5	adagrad	1621	154	7	400	100
-4.686075	-0.0029439	linear	0.7	none	5	adagrad	1616	154	7	400	100
-4.6718677	0.0019213	linear	0.7	none	5	adagrad	1619	154	7	400	100
-4.642364	0.0018062	linear	0.7	none	5	adagrad	1613	154	7	400	100
-4.6716748	-0.006265	linear	0.7	none	5	adagrad	1591	154	7	400	100
-4.726962	-0.0076064	linear	0.7	none	5	adagrad	1584	154	7	400	100
-4.7161472	0.004331	linear	0.7	none	5	adagrad	1672	154	7	500	100
-4.6757719	0.0071699	linear	0.7	none	5	adagrad	1648	154	7	400	100
-4.722506	0.0045404	linear	0.7	none	5	adagrad	1646	154	7	400	100
-4.7916242	-0.0093062	linear	0.7	none	5	adagrad	1750	154	7	1000	20
-4.7058382	-0.0006112	linear	0.7	none	5	adagrad	1628	154	7	500	100
-5.6067684	-0.2186251	tanh	0.7	none	5	adagrad	1625	154	7	400	100
-4.7238872	-0.0035982	linear	0.7	none	5	adagrad	1637	154	7	400	100
-4.6605828	0.0077181	linear	0.7	none	5	adagrad	1646	154	7	500	100
-4.7771012	-0.0056734	linear	0.7	none	5	nadam	1528	22	1	100	20
-4.679367	0.0140487	linear	0.6988972992	none	5	adagrad	1627	154	7	500	100

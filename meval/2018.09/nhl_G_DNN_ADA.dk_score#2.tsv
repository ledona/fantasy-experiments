{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["fo", "fo_win_pct", "giveaway", "goal", "goal_pp", "goal_sh", "hit", "ot", "pen", "pen_min", "pp", "shot", "so", "takeaway"], "extra_stats": ["player_win"], "model_player_stat": "dk_score#2", "model_team_stat": null, "player_stats": ["goal_ag", "loss", "save", "toi_g"], "prev_opp_team_stats": [], "team_stats": ["fo", "fo_win_pct", "giveaway", "goal", "goal_ag", "goal_pk_ag", "goal_pp", "goal_sh_ag", "hit", "ot", "pen", "pen_min", "pk", "pp", "shot_ag", "shot_b", "so", "takeaway"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["G"]}, "datetime_utc": "20180915 002046", "db_id": 4, "db_path": "nhl.db", "fantasy_version": "v0.30.2-11-gf54b675", "filename_prefix": "nhl_G_DNN_ADA", "folds": 3, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 3340, "increment": 1, "low": 500, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1930790915, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [20142015, 20152016, 20162017, 20172018]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-3.0688223	-0.1534831	relu	0.6461056226	none	5	adamax	1980	185	5	700	98
-3.0408209	-0.0558911	linear	0.6552419242	none	2	adagrad	2650	185	5	900	89
-2.9581376	-0.0233952	linear	0.5442721582	none	4	nadam	2656	111	3	600	79
-3.1270614	-0.2368921	relu	0.3428076353	none	2	adagrad	3260	259	7	600	66
-2.9970446	-0.0752565	tanh	0.4346282448	none	2	adagrad	3139	111	3	900	46
-3.2168973	-0.2365331	tanh	0.5134899763	none	5	adadelta	1440	37	1	1000	80
-3.1450788	-0.2224251	sigmoid	0.4015500209	none	4	adadelta	585	74	2	700	43
-2.9701019	-0.0149207	linear	0.6637202841	none	4	nadam	1696	37	1	100	71
-3.0550641	-0.1242275	tanh	0.3	none	5	nadam	3340	74	2	100	20
-2.9933832	-0.0972623	sigmoid	0.6099516514	none	3	nadam	2425	259	7	900	100
-2.9844786	-0.03336	linear	0.3846629561	none	4	nadam	3340	222	6	1000	100
-3.3171265	-0.3436927	tanh	0.3	none	3	nadam	3340	37	1	1000	92
-2.9652731	-0.042347	tanh	0.4553998641	none	1	adagrad	3024	111	3	800	99
-3.1364705	-0.157438	tanh	0.5307803735	none	2	adagrad	2409	185	5	300	100
-2.9754528	-0.033027	linear	0.4429634187	none	5	nadam	3340	259	7	400	100
-2.9871219	-0.0084599	linear	0.6072401712	none	2	nadam	3248	74	2	500	20
-2.9713571	-0.0466288	linear	0.3441578749	none	5	adam	2112	259	7	100	100
-3.0296768	-0.0798459	linear	0.3476240722	none	5	adamax	1980	222	6	800	86
-2.8515756	-0.005254	linear	0.6840134022	none	3	adadelta	1294	37	1	100	94
-2.991585	-0.0358194	linear	0.7	none	4	adadelta	500	37	1	200	100
-2.9647721	-0.0069714	linear	0.4893847611	none	4	nadam	2707	148	4	800	89
-3.064013	-0.1127902	sigmoid	0.3303886708	none	1	nadam	3340	148	4	1000	31
-2.9681858	-0.0537539	linear	0.3	none	2	nadam	3340	259	7	1000	89
-2.9668459	-0.0109515	linear	0.6888297623	none	3	adadelta	1686	37	1	100	100
-2.9570583	-0.0491646	linear	0.4007752069	none	1	adagrad	848	37	1	100	40
-2.9898939	-0.0016523	sigmoid	0.661259398	none	4	adagrad	1006	37	1	1000	73
-3.3987314	-0.4225927	sigmoid	0.3123568882	none	2	adadelta	773	259	7	100	56
-3.3422132	-0.4703265	linear	0.7	none	5	adagrad	1275	259	7	100	28
-3.1382182	-0.1832924	relu	0.5391177967	none	2	adam	1520	111	3	900	55
-2.9713993	-0.0318648	linear	0.489875207	none	1	adadelta	3340	148	4	100	77
-2.9703937	-0.0571407	linear	0.569511231	none	2	adadelta	810	37	1	300	92
-2.9739859	-0.0321718	linear	0.5019763658	none	1	adagrad	1594	37	1	1000	25
-2.9785663	-0.0196052	linear	0.324486303	none	1	adadelta	2018	37	1	1000	100
-3.0119627	-0.0951059	linear	0.6969170618	none	2	adadelta	1258	148	4	200	94
-3.0086675	-0.0505234	relu	0.3191040756	none	3	adagrad	2252	37	1	100	45
-2.9364702	-0.0068259	linear	0.3	none	5	adagrad	3340	37	1	500	100
-3.0294948	-0.073375	linear	0.5919442223	none	1	adadelta	1089	111	3	1000	25
-3.3316622	-0.3136866	tanh	0.3102604091	none	4	adagrad	677	37	1	600	94
-2.9807435	-0.013261	linear	0.4051915443	none	1	nadam	3340	37	1	100	100
-3.0804303	-0.1498917	tanh	0.4039104799	none	1	adadelta	3340	259	7	1000	20
-3.2032051	-0.2402681	tanh	0.3570293965	none	3	adam	3308	37	1	900	56
-2.9992011	-0.0350515	linear	0.6787055929	none	3	adagrad	1242	37	1	600	100
-2.9543112	-0.0226325	linear	0.7	none	1	adagrad	3340	37	1	100	20
-3.6549145	-0.5953009	tanh	0.3237323496	none	5	adadelta	500	259	7	400	20
-2.9958872	-0.0386132	linear	0.7	none	1	adamax	2568	111	3	100	100
-3.328285	-0.4562534	linear	0.3	none	5	adam	500	259	7	100	100
-2.9123107	0.0001093	linear	0.7	none	5	adadelta	3340	148	4	100	100
-3.0645934	-0.1139498	linear	0.7	none	5	adagrad	3340	37	1	100	20
-2.9737505	-0.011294	linear	0.6171411542	none	2	adadelta	3340	148	4	600	100
-2.9728557	-0.0115234	linear	0.6446595191	none	5	adadelta	3340	148	4	100	100
-2.9749371	-0.0133706	linear	0.544178978	none	2	adam	3340	148	4	500	100
-2.9767821	-0.0195877	linear	0.4331959392	none	2	adadelta	3340	148	4	400	100
-2.9123107	0.0001093	linear	0.7	none	5	adadelta	3340	148	4	100	100
-2.9123107	0.0001093	linear	0.7	none	5	adadelta	3340	148	4	100	100
-2.9543112	-0.0226325	linear	0.7	none	1	adagrad	3340	37	1	100	20
-2.9513194	-0.0108776	linear	0.7	none	1	adagrad	3340	37	1	100	100
-2.9532381	-0.0095439	linear	0.3	none	1	adagrad	3340	37	1	100	100
-2.9532381	-0.0095439	linear	0.3	none	1	adagrad	3340	37	1	100	100
-2.9532381	-0.0095439	linear	0.3	none	1	adagrad	3340	37	1	100	100
-2.9372812	-0.0093163	linear	0.3	none	1	adagrad	3228	37	1	1000	100
-2.9893864	-0.0316694	linear	0.7	none	5	adagrad	3340	37	1	100	100
-2.9771932	-0.0150011	linear	0.3	none	1	adagrad	3340	37	1	100	20
-2.9532381	-0.0095439	linear	0.3	none	1	adagrad	3340	37	1	100	100
-2.9532381	-0.0095439	linear	0.3	none	1	adagrad	3340	37	1	100	100
-2.9780852	-0.0159976	linear	0.4502430939	none	1	adagrad	3340	37	1	100	20
-2.9587698	-0.0209802	linear	0.5436088698	none	5	adadelta	1199	37	1	600	100
-2.9532381	-0.0095439	linear	0.3	none	1	adagrad	3340	37	1	100	100
-2.9513194	-0.0108776	linear	0.7	none	1	adagrad	3340	37	1	100	100
-2.9513194	-0.0108776	linear	0.7	none	1	adagrad	3340	37	1	100	100
-2.9572851	-0.0286381	linear	0.7	none	1	adagrad	2904	148	4	200	20

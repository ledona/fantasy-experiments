{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xp", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds", "pen_yds", "pens"], "extra_stats": ["home_C", "player_home_H", "team_home_H", "team_win"], "model_player_stat": "dk_score_off#2", "model_team_stat": null, "player_stats": ["fumbles_lost", "receiving_rec", "receiving_targets", "receiving_tds", "receiving_twoptm", "receiving_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["TE", "WR"]}, "datetime_utc": "20181029 160442", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.31.0-1-gb300643", "filename_prefix": "nfl_WT_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 9000, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1293789603, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-5.5575448	-0.0052414	tanh	0.441068056	none	4	adam	365	63	2	500	26
-5.2736292	0.207392	tanh	0.6819766602	none	2	adagrad	7067	218	7	1000	94
-5.2152159	0.1458767	sigmoid	0.5894241778	none	5	adam	2582	94	3	300	98
-6.3193258	-0.0801563	tanh	0.6437154796	none	2	adam	195	187	6	400	52
-5.1093506	0.1587963	sigmoid	0.472384814	none	4	adadelta	8514	32	1	900	94
-5.4298461	0.1810549	tanh	0.6672024953	none	2	adagrad	4180	187	6	600	88
-5.120758	0.1225717	tanh	0.4406083347	none	4	adadelta	8645	125	4	900	83
-5.3838726	0.0230495	sigmoid	0.7	none	4	adadelta	100	32	1	900	100
-5.5312199	0.0418344	relu	0.7	none	5	adadelta	9000	32	1	1000	100
-5.1949858	0.1457096	sigmoid	0.6089977246	none	4	nadam	9000	32	1	1000	100
-5.1563391	0.1392393	sigmoid	0.5170657011	none	4	adadelta	7652	32	1	800	100
-5.0738096	0.1556317	sigmoid	0.4019219112	none	4	adadelta	9000	32	1	1000	79
-5.115554	0.1814715	linear	0.3	none	4	adadelta	9000	32	1	1000	26
-5.1437739	0.1261674	sigmoid	0.3	none	4	adadelta	9000	32	1	1000	100
-5.1440585	0.1647151	sigmoid	0.7	none	4	adadelta	9000	32	1	900	59
-5.1207183	0.1705385	sigmoid	0.4407677059	none	4	adadelta	9000	32	1	1000	20
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-5.3832661	0.0530783	tanh	0.3	none	5	adadelta	9000	218	7	1000	100
-4.9566951	0.2349192	linear	0.3	none	5	adagrad	9000	94	3	1000	81
-5.1788598	0.1628128	linear	0.4538215033	none	5	adagrad	5468	32	1	600	20
-5.520982	0.0510892	tanh	0.3	none	4	adagrad	9000	218	7	1000	100
-5.0451452	0.190039	sigmoid	0.3	none	5	adagrad	9000	187	6	1000	100
-5.021074	0.2391138	linear	0.4773407585	none	5	adagrad	9000	218	7	200	23
-5.0921049	0.1774665	linear	0.3	none	2	adagrad	9000	32	1	1000	100
-4.9288549	0.2432885	linear	0.5964980965	none	5	adagrad	9000	94	3	1000	97
-5.201792	0.1618603	tanh	0.6329517764	none	5	adadelta	9000	32	1	1000	89
-5.1266371	0.1813469	linear	0.4580233098	none	5	adagrad	9000	32	1	1000	100
-4.9302961	0.2378834	linear	0.3	none	4	adagrad	9000	94	3	1000	100
-4.9304031	0.2378057	linear	0.4191819514	none	4	adagrad	9000	94	3	1000	83
-4.9257422	0.2375512	linear	0.5458195722	none	3	adagrad	9000	94	3	1000	100
-4.9225167	0.2351826	sigmoid	0.3	none	2	adagrad	9000	94	3	1000	75
-4.9256924	0.2378656	linear	0.4158665955	none	2	adagrad	9000	94	3	1000	100
-4.9547336	0.2317795	sigmoid	0.5296654853	none	1	adadelta	9000	94	3	200	74
-5.0255373	0.2354706	sigmoid	0.3	none	1	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9743221	0.251078	linear	0.3	none	5	adamax	9000	218	7	1000	100
-4.9651076	0.2527285	linear	0.3	none	5	adagrad	9000	218	7	1000	90
-4.9880823	0.2349435	sigmoid	0.5032356061	none	1	adamax	9000	94	3	200	20
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9316355	0.2394241	linear	0.5448057386	none	1	adagrad	9000	94	3	1000	100
-4.9323038	0.2393622	linear	0.5234298738	none	1	adagrad	9000	94	3	900	99
-4.948102	0.2203358	sigmoid	0.362970831	none	4	adagrad	9000	94	3	1000	95
-5.3094085	0.151739	tanh	0.7	none	1	adadelta	1685	218	7	1000	78
-4.9541954	0.2413707	linear	0.3	none	1	adagrad	9000	94	3	1000	100
-4.9441273	0.2416252	linear	0.561673915	none	1	adagrad	9000	94	3	1000	88
-4.9592351	0.2410504	linear	0.5337009495	none	5	adagrad	9000	94	3	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-5.0118872	0.2439407	linear	0.3	none	5	adagrad	9000	218	7	1000	71
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-5.0043705	0.2421232	linear	0.7	none	5	adagrad	9000	218	7	1000	100
-5.008965	0.2440847	linear	0.3	none	5	adagrad	9000	218	7	900	100
-4.908105	0.2443288	linear	0.4978147931	none	1	adadelta	9000	94	3	1000	100
-5.0653118	0.231981	linear	0.3	none	5	adadelta	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.939249	0.2330387	linear	0.7	none	5	adagrad	9000	94	3	1000	92
-4.9513634	0.2371926	linear	0.5868938168	none	3	adadelta	9000	94	3	1000	94
-4.9165585	0.2395597	linear	0.4047608394	none	1	adagrad	9000	94	3	1000	81
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9066543	0.2460326	linear	0.6118487219	none	1	adagrad	9000	125	4	800	100
-4.9184237	0.236701	linear	0.7	none	3	adagrad	9000	156	5	100	47
-4.960771	0.2424441	linear	0.7	none	1	adamax	9000	125	4	1000	100
-4.929585	0.2449149	linear	0.6057629814	none	3	adagrad	9000	125	4	900	98
-4.9158004	0.2447715	linear	0.6321759235	none	1	adagrad	9000	125	4	300	100
-5.0043342	0.248762	linear	0.3	none	1	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100
-4.9643588	0.2509832	linear	0.3	none	5	adagrad	9000	218	7	1000	100

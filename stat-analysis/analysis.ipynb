{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Summary/Analysis\n",
    "Use this notebook to calculate summary stats, correlation analyses\n",
    "and other useful metrics for training and evalution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Analysis = Literal[\"summary\", \"error\", \"histogram\"]\n",
    "\n",
    "ANALYSES: list[Analysis]\n",
    "COLS_TO_DROP = None\n",
    "COLS_TO_ANALYZE = None\n",
    "FILTER_QUERY = None\n",
    "PREVIEW_DATA = False\n",
    "TARGET_PATTERN = None\n",
    "HISTOGRAM_COLS = 3\n",
    "HISTOGRAM_BINS = 10\n",
    "HISTOGRAM_INCHES_PER_ROW = 3\n",
    "HISTOGRAM_INCHES_PER_COL = 5\n",
    "\"\"\"show a preview of data before analysis\"\"\"\n",
    "\n",
    "# NFL DFS score predict\n",
    "DATA_FILES = glob(os.path.join(\"/\", \"fantasy-experiments\", \"models\", \"2023.12\", \"nfl_RB*csv\"))\n",
    "ANALYSES = [\"histogram\", \"summary\"]\n",
    "COLS_TO_ANALYZE = r\"(stat|extra|calc):(?!venue).*\"\n",
    "PREVIEW_DATA = True\n",
    "TARGET_PATTERN = r\"calc:.*\"\n",
    "# COLS_TO_ANALYZE = r\"(calc:.*)|(((stat)|(extra)).*((recent-mean)|(std)).*)|\"\n",
    "COLS_TO_ANALYZE = r\"(calc:.*)|(.*-mean.*)\"\n",
    "\n",
    "# LOL dfs win score feature summary and correlation analysis\n",
    "# DATA_FILES = [os.path.join(\n",
    "#     \"/\", \"fantasy-experiments\", \"df-hist\", \"data\", \"lol-draftkings-CLASSIC-GPP.csv\"\n",
    "# )]\n",
    "# COLS_TO_DROP = [\"slate_id\", \"link\", \"style\", \"type\", \"date\"]\n",
    "# FILTER_QUERY = \"slate_id.notna()\"\n",
    "# ANALYSES = [\"summary\"]\n",
    "\n",
    "# DFS win score prediction error analysis\n",
    "# DATA_FILES = [\n",
    "#     filepath\n",
    "#     for filepath in glob(\n",
    "#         os.path.join(\n",
    "#             \"/\",\n",
    "#             \"fantasy-experiments\",\n",
    "#             \"df-hist\",\n",
    "#             \"eval_results\",\n",
    "#             \"*.prediction.csv\",\n",
    "#         )\n",
    "#     )\n",
    "# ]\n",
    "# ANALYSES = [\"error\"]\n",
    "\n",
    "assert len(DATA_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import sqrt\n",
    "from typing import Pattern\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def load(\n",
    "    path: str,\n",
    "    cols_to_drop: list[str] | None = None,\n",
    "    cols_to_analyze: Pattern[str] | None = None,\n",
    "    filter_query: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    filter_query: Rows not matching this query will be dropped\n",
    "    cols_to_drop: list of cols to not analyze\n",
    "    cols_to_analyze: list of cols to analyze. cols are names or regexs\n",
    "    \"\"\"\n",
    "    assert (cols_to_drop is None) or (\n",
    "        cols_to_analyze is None\n",
    "    ), \"cols_to_drop and cols_to_analyze cannot both be not None\"\n",
    "    df = pd.read_csv(path)\n",
    "    file_len = len(df)\n",
    "    if filter_query:\n",
    "        df = df.query(filter_query)\n",
    "        print(f\"Filter query dropped {file_len - len(df)} rows, {len(df)} remaining\")\n",
    "    if cols_to_drop is not None:\n",
    "        print(f\"Dropping columns: {cols_to_drop}\")\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    if cols_to_analyze is not None:\n",
    "        cols_to_keep = [col for col in df.columns if re.match(cols_to_analyze, col)]\n",
    "        if (cols_dropped := len(df.columns) - len(cols_to_keep)) > 0:\n",
    "            print(\n",
    "                f\"Dropping {cols_dropped} columns, {len(cols_to_keep)} columns remaining in analysis. \"\n",
    "                f\"Dropped cols: {set(df.columns) - set(cols_to_keep)}\"\n",
    "            )\n",
    "            df = df[cols_to_keep]\n",
    "    print(f\"Analyzing features: {sorted(list(df.columns))}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize(df: pd.DataFrame, targets: list[str] | None):\n",
    "    if targets is not None:\n",
    "        corr_df = pd.DataFrame({target: df.corrwith(df[target]) for target in targets})\n",
    "    else:\n",
    "        print(\"Running full cross correlation\")\n",
    "        corr_df = df.corr()\n",
    "\n",
    "    summary = {\n",
    "        \"summary\": df.describe().transpose().drop(columns=\"count\"),\n",
    "        \"correlation\": corr_df.style.background_gradient(axis=None, cmap=\"RdYlGn\"),\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "\n",
    "def error_analysis(df: pd.DataFrame, desc):\n",
    "    assert {\"truth\", \"prediction\", \"error\"} <= set(df.columns)\n",
    "\n",
    "    r2 = round(metrics.r2_score(df.truth, df.prediction), 4)\n",
    "    rmse = round(sqrt(metrics.mean_squared_error(df.truth, df.prediction)), 4)\n",
    "    mae = round(sqrt(metrics.mean_absolute_error(df.truth, df.prediction)), 4)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    fig.suptitle(f\"{desc or 'unknown model'} : n={len(df)} {r2=} {rmse=} {mae=}\")\n",
    "    for ax in axs:\n",
    "        ax.axis(\"equal\")\n",
    "\n",
    "    min_v = min(df.truth.min(), df.prediction.min())\n",
    "    max_v = max(df.truth.max(), df.prediction.max())\n",
    "\n",
    "    axs[0].plot((min_v, max_v), (min_v, max_v), \"-g\", linewidth=1)\n",
    "    df.plot(kind=\"scatter\", x=\"truth\", y=\"prediction\", ax=axs[0])\n",
    "\n",
    "    axs[1].yaxis.set_label_position(\"right\")\n",
    "    axs[1].plot((min_v, max_v), (0, 0), \"-g\", linewidth=1)\n",
    "    df.plot(kind=\"scatter\", x=\"truth\", y=\"error\", ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in DATA_FILES:\n",
    "    print(f\"Analyzing '{filepath}'\")\n",
    "    df = load(\n",
    "        filepath,\n",
    "        filter_query=FILTER_QUERY,\n",
    "        cols_to_drop=COLS_TO_DROP,\n",
    "        cols_to_analyze=COLS_TO_ANALYZE,\n",
    "    )\n",
    "    if PREVIEW_DATA:\n",
    "        display(f\"data preview total-n={len(df)}\", df.head(5).style.hide())\n",
    "\n",
    "    if \"summary\" in ANALYSES:\n",
    "        targets = (\n",
    "            [col for col in df.columns if re.match(TARGET_PATTERN, col)] if TARGET_PATTERN else None\n",
    "        )\n",
    "        print(f\"{TARGET_PATTERN=} => {targets=}\")\n",
    "        assert (targets is not None and len(targets) > 0) == (TARGET_PATTERN is not None)\n",
    "        summary = summarize(df, targets)\n",
    "        with pd.option_context(\n",
    "            \"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", None\n",
    "        ):\n",
    "            for name, summary_df in summary.items():\n",
    "                display(name)\n",
    "                display(summary_df)\n",
    "\n",
    "    if \"error\" in ANALYSES:\n",
    "        error_analysis(df, os.path.basename(filepath))\n",
    "\n",
    "    if \"histogram\" in ANALYSES:\n",
    "        rows = 1 + (len(df.columns) // HISTOGRAM_COLS)\n",
    "        layout = rows, HISTOGRAM_COLS\n",
    "        figsize = (HISTOGRAM_COLS * HISTOGRAM_INCHES_PER_COL), (rows * HISTOGRAM_INCHES_PER_ROW)\n",
    "        print(f\"{layout=} {figsize=}\")\n",
    "        df.hist(bins=HISTOGRAM_BINS, layout=layout, figsize=figsize)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Summary/Analysis\n",
    "Use this notebook to calculate summary stats, correlation analyses\n",
    "and other useful metrics for training and evalution data.\n",
    "\n",
    "To use:\n",
    "1. Indicate which data file(s) to analyze by setting _DATA_FILES_PATTERN_\n",
    "2. Review/change _COLS_TO_DROP_, _COLS_TO_ANALYZE_, _TARGET_PATTERN_, _ANALYSES_ and other settings\n",
    "\n",
    "### Error Analysis\n",
    "Visualize the error between prediction and truth\n",
    "- For error analysis create the error dataset using _dumpdata.sc_ with the _--model_ argument.\n",
    "- (notebook) Set _ANALYSIS_ to 'error'\n",
    "- In the notebook set _ERROR_COLS_ to a dict with _truth_ and _predict_ values for the columns containing the true and predicted values\n",
    "\n",
    "### Summary\n",
    "Basic summary stats of the loaded dataframe statistics\n",
    "\n",
    "### Histogram\n",
    "Histograms showing distribution of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "AnalysisType = Literal[\"summary\", \"error\", \"histogram\"]\n",
    "\n",
    "ANALYSES: list[AnalysisType]\n",
    "\"\"\"which analyses should be done\"\"\"\n",
    "COLS_TO_DROP = \".*recent-[1-9].*\"\n",
    "COLS_TO_ANALYZE = None\n",
    "FILTER_QUERY = None\n",
    "PREVIEW_DATA = False\n",
    "\"\"\"show a preview of data before analysis\"\"\"\n",
    "TARGET_PATTERN = None\n",
    "\"\"\"regexp of the target columns\"\"\"\n",
    "\n",
    "# histogram visualization settings\n",
    "HISTOGRAM_COLS = 3\n",
    "HISTOGRAM_BINS = 10\n",
    "HISTOGRAM_INCHES_PER_ROW = 3\n",
    "HISTOGRAM_INCHES_PER_COL = 5\n",
    "\n",
    "DATA_LIMIT = 100000\n",
    "\"\"\"limit data to speed up analysis\"\"\"\n",
    "\n",
    "ERROR_COLS = None\n",
    "ADDL_FEATURE_FUNC = None\n",
    "DROP_TARGET_OUTLIERS = True\n",
    "\n",
    "DATA_FILES_DIR = os.path.join(\"/\", \"fantasy-isync\", \"fantasy-modeling\", \"2025.03\", \"data\")\n",
    "\"\"\"the path to data files\"\"\"\n",
    "\n",
    "DATA_FILES_PATTERN: str\n",
    "\"\"\"Pattern to glob for data files to analyze\"\"\"\n",
    "\n",
    "print(\"Defaults set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what analysis will be done\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# DATA_FILES_PATTERN  = \"nfl_team.csv\"\n",
    "# DATA_FILES_PATTERN  = \"nfl_WRTE.csv\"\n",
    "# DATA_FILES_PATTERN  = \"nfl_QB.csv\"\n",
    "# DATA_FILES_PATTERN  = \"nfl_K.csv\"\n",
    "# DATA_FILES_PATTERN  = \"mlb_pitcher.parquet\"\n",
    "DATA_FILES_PATTERN  = \"mlb_hitter.parquet\"\n",
    "# DATA_FILES_PATTERN  = \"mlb_team.parquet\"\n",
    "# DATA_FILES_PATTERN  = \"nhl_goalie.parquet\"\n",
    "\n",
    "\n",
    "GLOB_PATTERN= os.path.join(DATA_FILES_DIR, DATA_FILES_PATTERN)\n",
    "DATA_FILES = glob(GLOB_PATTERN)\n",
    "\n",
    "# ANALYSES = [\"error\"]\n",
    "ERROR_COLS = {\n",
    "    \"truth\": \"calc:dk_score\",\n",
    "    \"predict\": \"calc:dk_score:std-mean\",  #  \"prediction:calc:dk_score\"\n",
    "}\n",
    "TARGET_PATTERN = \"(calc:[^:]+|stat:[^:]+)$\"\n",
    "ANALYSES = [\"histogram\", \"summary\"]\n",
    "# PREVIEW_DATA = True\n",
    "\n",
    "COLS_TO_ANALYZE = r\"^(stat|extra|calc):(?!venue|y_score).*$\"\n",
    "\n",
    "assert len(DATA_FILES) > 0, \"No datafiles found to process\"\n",
    "print(f\"Found {len(DATA_FILES)} files at '{GLOB_PATTERN}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import sqrt\n",
    "from typing import Callable, Pattern\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load(\n",
    "    path: str,\n",
    "    cols_to_drop: Pattern[str] | None = None,\n",
    "    cols_to_analyze: Pattern[str] | None = None,\n",
    "    filter_query: str | None = None,\n",
    "    addl_features_func: Callable | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    filter_query: Rows not matching this query will be dropped\n",
    "    cols_to_drop: list of cols drop, strings or regexs\n",
    "    cols_to_analyze: list of cols to analyze. cols are names or regexs\n",
    "    \"\"\"\n",
    "    extension = path.rsplit('.', 1)[1]\n",
    "    if extension == \"csv\":\n",
    "        df = pd.read_csv(path)\n",
    "    elif extension in ['pq', 'parquet']:\n",
    "        df = pd.read_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown file type for path '{path}'\")\n",
    "    print(f\"Loaded {len(df)=} {len(df.columns)=}\")\n",
    "    if DATA_LIMIT is not None:\n",
    "        df = df.head(DATA_LIMIT)\n",
    "    # if df.isna().any().any():\n",
    "    #     print(\"NAs found. filling na->0.0\")\n",
    "    #     df = df.fillna(0)\n",
    "\n",
    "    if ADDL_FEATURE_FUNC is not None:\n",
    "        cols = sorted(\n",
    "            {\":\".join(col.split(\":\", 2)[:2]) for col in df.columns if col[:4] in (\"stat\", \"calc\")}\n",
    "        )\n",
    "        print(f\"{cols=}\")\n",
    "\n",
    "        tqdm.pandas(desc=\"addl_features\")\n",
    "        addl_df = df.progress_apply(addl_features_func, result_type=\"expand\", axis=1)\n",
    "        addl_cols = list(addl_df.columns)\n",
    "        print(f\"applied addl_func. addl_cols = {addl_cols}\")\n",
    "        df = pd.concat([df, addl_df], axis=1)\n",
    "    else:\n",
    "        addl_cols = []\n",
    "\n",
    "    file_len = len(df)\n",
    "    if filter_query:\n",
    "        df = df.query(filter_query)\n",
    "        print(f\"Filter query dropped {file_len - len(df)} rows, {len(df)} remaining\")\n",
    "    if cols_to_drop is not None:\n",
    "        cols = [col for col in df.columns if re.match(cols_to_drop, col)]\n",
    "        print(f\"Dropping columns from {cols_to_drop=}: {cols}\")\n",
    "        df = df.drop(columns=cols)\n",
    "    if cols_to_analyze is not None:\n",
    "        cols = [col for col in df.columns if re.match(cols_to_analyze, col)]\n",
    "        if (cols_dropped := len(df.columns) - len(cols)) > 0:\n",
    "            print(\n",
    "                f\"Dropping {cols_dropped} columns, {len(cols)} columns remaining in analysis. \"\n",
    "                f\"Dropped cols: {set(df.columns) - set(cols)}\"\n",
    "            )\n",
    "            df = df[cols]\n",
    "    print(f\"Loaded features: {sorted(list(df.columns))}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize(df: pd.DataFrame, targets: list[str] | None):\n",
    "    \"\"\"stat summarization and correlation analysis\"\"\"\n",
    "    if targets is not None:\n",
    "        drop_cols = targets + [col for col in df.columns if \":\" not in col]\n",
    "        no_target_df = df.drop(columns=drop_cols)\n",
    "        print(\n",
    "            f\"Running correlation of {targets=} against numeric features in {sorted(no_target_df.columns)}\"\n",
    "        )\n",
    "        corr_df = pd.DataFrame(\n",
    "            {target: no_target_df.corrwith(df[target], numeric_only=True) for target in targets}\n",
    "        ).sort_values(targets, ascending=False, key=abs)\n",
    "    else:\n",
    "        print(\"Running full cross correlation\")\n",
    "        corr_df = df.corr()\n",
    "\n",
    "    # use a color map that cycles from intense to grey to intense cause highly negative correlation\n",
    "    # is as good as highly positive\n",
    "    cmap = plt.cm.get_cmap(\"PRGn\")  # Choose a diverging colormap\n",
    "\n",
    "    summary = {\n",
    "        \"summary\": df.describe().transpose().drop(columns=\"count\"),\n",
    "        \"correlation\": corr_df.style.background_gradient(axis=None, cmap=cmap, vmin=-1, vmax=1),\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "\n",
    "def drop_target_outliers(df: pd.DataFrame, targets: set[str], outlier_range: float = 2.0):\n",
    "    \"\"\"drop rows with target outliers\"\"\"\n",
    "    df_no_outliers = df\n",
    "    for target in targets:\n",
    "        mean = df[target].mean()\n",
    "        std = df[target].std()\n",
    "        lower_bound = mean - outlier_range * std\n",
    "        upper_bound = mean + outlier_range * std\n",
    "        df = df[(df[target] >= lower_bound) & (df[target] <= upper_bound)]\n",
    "    if len(df) < len(df_no_outliers):\n",
    "        print(f\"Dropped {len(df_no_outliers) - len(df)} rows due to outliers\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def error_analysis(df: pd.DataFrame, desc, truth_col, pred_col):\n",
    "    assert truth_col in df.columns and pred_col in df.columns, \"truth or prediction col not found\"\n",
    "    error_df = df[[truth_col, pred_col]].dropna()\n",
    "    error_df[\"error\"] = error_df[truth_col] - error_df[pred_col]\n",
    "    error_df.rename(columns={truth_col: \"truth\", pred_col: \"prediction\"}, inplace=True)\n",
    "    r2 = round(metrics.r2_score(error_df.truth, error_df.prediction), 4)\n",
    "    rmse = round(sqrt(metrics.mean_squared_error(error_df.truth, error_df.prediction)), 4)\n",
    "    mae = round(sqrt(metrics.mean_absolute_error(error_df.truth, error_df.prediction)), 4)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    fig.suptitle(f\"{desc or 'unknown model'} : n={len(df)} {r2=} {rmse=} {mae=}\")\n",
    "    for ax in axs:\n",
    "        ax.axis(\"equal\")\n",
    "\n",
    "    min_v = min(error_df.truth.min(), error_df.prediction.min())\n",
    "    max_v = max(error_df.truth.max(), error_df.prediction.max())\n",
    "\n",
    "    axs[0].plot((min_v, max_v), (min_v, max_v), \"-g\", linewidth=1)\n",
    "    error_df.plot(kind=\"scatter\", x=\"truth\", y=\"prediction\", ax=axs[0])\n",
    "\n",
    "    axs[1].yaxis.set_label_position(\"right\")\n",
    "    axs[1].plot((min_v, max_v), (0, 0), \"-g\", linewidth=1)\n",
    "    error_df.plot(kind=\"scatter\", x=\"truth\", y=\"error\", ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in DATA_FILES:\n",
    "    print(f\"Analyzing '{filepath}'\")\n",
    "    df = load(\n",
    "        filepath,\n",
    "        filter_query=FILTER_QUERY,\n",
    "        cols_to_drop=COLS_TO_DROP,\n",
    "        cols_to_analyze=COLS_TO_ANALYZE,\n",
    "        addl_features_func=ADDL_FEATURE_FUNC,\n",
    "    )\n",
    "\n",
    "    targets = (\n",
    "        [col for col in df.columns if re.match(TARGET_PATTERN, col)] if TARGET_PATTERN else None\n",
    "    )\n",
    "\n",
    "    if DROP_TARGET_OUTLIERS:\n",
    "        assert (\n",
    "            targets is not None or ERROR_COLS is not None\n",
    "        ), f\"must specify outlier_cols or ERROR_COLS to drop outliers {targets=} {ERROR_COLS=}\"\n",
    "        outlier_cols = set(targets) if targets is not None else {ERROR_COLS[\"truth\"]}\n",
    "        assert outlier_cols <= set(df.columns), f\"{outlier_cols=} must be a subset of {df.columns=}\"\n",
    "        df = drop_target_outliers(df, outlier_cols)\n",
    "\n",
    "    if PREVIEW_DATA:\n",
    "        display(f\"data preview total-n={len(df)}\", df.head(5).style.hide())\n",
    "\n",
    "    if \"summary\" in ANALYSES:\n",
    "        print(f\"{TARGET_PATTERN=} => {targets=}\")\n",
    "        assert (targets is not None and len(targets) > 0) == (TARGET_PATTERN is not None)\n",
    "        summary = summarize(df, targets)\n",
    "        with pd.option_context(\n",
    "            \"display.max_rows\", None, \"display.max_columns\", None, \"display.max_colwidth\", None\n",
    "        ):\n",
    "            for name, summary_df in summary.items():\n",
    "                display(name)\n",
    "                display(summary_df)\n",
    "\n",
    "    if \"error\" in ANALYSES:\n",
    "        assert ERROR_COLS is not None\n",
    "        assert ERROR_COLS['truth'] in df.columns, f\"{ERROR_COLS['truth']=}\"\n",
    "        assert ERROR_COLS['predict'] in df.columns, f\"{ERROR_COLS['predict']} not found in df\"\n",
    "        error_analysis(df, os.path.basename(filepath), ERROR_COLS['truth'], ERROR_COLS['predict'])\n",
    "\n",
    "    if \"histogram\" in ANALYSES:\n",
    "        rows = 1 + (len(df.columns) // HISTOGRAM_COLS)\n",
    "        layout = rows, HISTOGRAM_COLS\n",
    "        figsize = (HISTOGRAM_COLS * HISTOGRAM_INCHES_PER_COL), (rows * HISTOGRAM_INCHES_PER_ROW)\n",
    "        print(f\"{layout=} {figsize=}\")\n",
    "        df.hist(bins=HISTOGRAM_BINS, layout=layout, figsize=figsize)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xpt", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds"], "extra_stats": [], "model_player_stat": "fd_score_off#4", "model_team_stat": null, "player_stats": ["fumbles_lost", "receiving_rec", "receiving_tds", "receiving_twoptm", "receiving_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "/Users/delano/working/fantasy/MODELS_keras", "normalize": true, "player_pos": ["TE", "WR"]}, "datetime_utc": "20180820 010149", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.29.0-17-g27bfdaa7", "filename_prefix": "nfl_WT_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 9000, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1629510883, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-4.5246059	0.0491976	relu	0.3842863313	none	3	nadam	743	100	4	500	81
-4.4102271	0.18171	sigmoid	0.5246094813	none	1	adagrad	1801	50	2	900	88
-4.4214274	0.2082934	linear	0.3053646637	none	5	adam	7353	150	6	300	75
-5.2742938	-0.2355265	tanh	0.5879280569	none	4	adam	309	100	4	1000	71
-4.5449456	0.1296516	sigmoid	0.4629767581	none	4	adam	4507	150	6	600	50
-6.060694	-0.8447604	linear	0.3028828705	none	4	adam	243	150	6	500	27
-4.6230167	0.0915723	relu	0.5900719941	none	5	nadam	6630	75	3	800	54
-4.5576558	0.1265596	sigmoid	0.5810824892	none	1	adagrad	2242	25	1	1000	91
-4.424862	0.2002407	linear	0.587051603	none	2	adamax	5618	100	4	200	100
-4.4102791	0.2090263	linear	0.3568466834	none	5	adam	7877	150	6	300	85
-4.3743341	0.2131982	linear	0.5924837028	none	2	adamax	7024	100	4	200	100
-4.6486403	0.1589766	sigmoid	0.3	none	1	adagrad	1793	150	6	900	20
-4.6282236	0.1254675	tanh	0.6200832892	none	1	adam	1245	50	2	100	100
-4.3992786	0.2061371	linear	0.5984396562	none	2	adamax	8582	100	4	200	100
-4.6630052	0.1019726	sigmoid	0.5956197774	none	1	adagrad	1396	25	1	800	100
-4.6078276	0.1269011	linear	0.7	none	1	adamax	9000	25	1	100	88
-4.48401	0.1184311	tanh	0.7	none	1	adagrad	9000	25	1	100	20
-5.6826403	-0.1044642	sigmoid	0.3533729476	none	1	adagrad	276	125	5	600	82
-4.5629616	0.151965	sigmoid	0.4744888317	none	2	adagrad	2050	75	3	1000	76
-4.4953858	0.1849818	tanh	0.6197817183	none	2	adagrad	7731	100	4	200	36
-4.5350405	0.1068519	sigmoid	0.5333873607	none	5	adam	6295	125	5	600	84
-4.4849352	0.1973942	sigmoid	0.6367544757	none	1	adadelta	7484	150	6	200	100
-4.5981712	0.1159532	tanh	0.7	none	1	adam	2059	25	1	300	100
-4.3959568	0.1996513	linear	0.6498837209	none	1	adamax	6733	100	4	100	100
-4.4589819	0.2134081	linear	0.5641252595	none	4	adamax	8435	150	6	300	95
-4.4499202	0.2013843	linear	0.3877413755	none	1	adadelta	8057	100	4	100	100
-4.5498726	0.1508927	sigmoid	0.4918831892	none	1	adagrad	2362	50	2	1000	80
-4.452528	0.2097674	linear	0.3	none	3	adam	7805	150	6	200	100
-4.4712401	0.195519	linear	0.3015269094	none	4	adam	7161	75	3	200	98
-4.4804364	0.1575824	sigmoid	0.4242076322	none	3	adagrad	2104	50	2	900	100
-4.4135924	0.2157933	linear	0.6820385493	none	3	adamax	7035	150	6	300	86
-4.3729145	0.2014008	linear	0.3366912677	none	3	adamax	6384	75	3	100	100
-4.4442322	0.1940273	linear	0.7	none	1	adamax	6554	75	3	700	20
-4.6059952	0.0815854	relu	0.6392705776	none	3	adam	6853	100	4	100	42
-4.461039	0.2145633	linear	0.7	none	5	adamax	8205	175	7	1000	100
-4.5993335	0.1513181	tanh	0.507341762	none	3	nadam	2859	175	7	100	20
-4.9576843	0.1061119	tanh	0.7	none	3	adagrad	8436	175	7	100	100
-4.458372	0.2008466	linear	0.5082584951	none	2	adamax	6465	100	4	100	100
-5.1171567	0.0241989	tanh	0.7	none	5	adagrad	7393	25	1	100	100
-4.5838882	0.1879124	linear	0.6075943149	none	5	adam	8035	150	6	1000	20
-4.4735033	0.122681	tanh	0.5757142438	none	3	nadam	9000	150	6	300	100
-4.5118721	0.1923913	linear	0.5181701389	none	3	adamax	7986	75	3	800	20
-4.4120395	0.2138884	linear	0.4437339922	none	1	adamax	7965	125	5	800	20
-4.4269737	0.2092184	linear	0.3	none	1	adamax	7580	125	5	100	69
-4.4397044	0.2105843	linear	0.4638963993	none	1	adamax	7953	150	6	400	20
-4.4484581	0.205638	linear	0.4359187835	none	1	adamax	7944	150	6	300	20
-4.4198456	0.2161289	linear	0.4239001406	none	1	adamax	7928	125	5	600	20
-4.4296963	0.2117176	linear	0.3396464037	none	1	adamax	7901	125	5	1000	20
-4.4794936	0.1770696	linear	0.405337398	none	1	adamax	7898	50	2	900	20
-4.4461075	0.2099942	linear	0.5262773938	none	1	adamax	7923	125	5	600	20
-4.4228307	0.1987327	linear	0.3123175504	none	1	adamax	7918	100	4	600	20
-4.4822411	0.1752262	linear	0.5301663511	none	1	adamax	7982	50	2	300	20
-4.4616103	0.1758545	linear	0.3	none	3	adamax	6354	50	2	200	100
-4.4741575	0.2109343	linear	0.6693979205	none	1	adamax	7868	175	7	900	20
-4.4213873	0.200138	linear	0.3	none	1	adamax	7905	100	4	900	20
-4.5545341	0.1669418	tanh	0.3	none	1	adamax	7905	175	7	100	20
-4.3968898	0.2114283	linear	0.3	none	1	adagrad	7832	125	5	400	20
-4.3798989	0.2200356	linear	0.3	none	1	adagrad	7520	175	7	800	42
-4.432297	0.2087768	linear	0.3	none	1	adagrad	7625	175	7	500	64
-4.4536354	0.205571	linear	0.3	none	1	adamax	7264	175	7	100	20
-4.5937802	0.1237695	linear	0.3	none	1	adadelta	5629	25	1	200	20
-4.4158603	0.2064886	linear	0.3	none	1	nadam	9000	100	4	600	20
-4.4648102	0.2114237	linear	0.3	none	1	nadam	8469	175	7	600	94
-4.6062564	0.1299947	tanh	0.3	none	1	nadam	7389	75	3	600	20
-4.4555288	0.1781689	linear	0.3	none	1	nadam	3388	125	5	500	100
-4.8643235	0.0532101	relu	0.5058659137	none	2	adam	2344	75	3	400	20
-4.519402	0.1827306	linear	0.3	none	1	adamax	4297	75	3	600	100
-4.6456841	0.1602442	relu	0.6845398093	none	1	adam	9000	150	6	700	20
-4.4294726	0.2089502	linear	0.3	none	1	adamax	6852	175	7	800	81
-4.82556	-0.0214471	relu	0.7	none	5	adagrad	9000	25	1	100	49

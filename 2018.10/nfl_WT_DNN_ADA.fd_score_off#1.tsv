{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xp", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds"], "extra_stats": [], "model_player_stat": "fd_score_off#1", "model_team_stat": null, "player_stats": ["fumbles_lost", "receiving_rec", "receiving_targets", "receiving_tds", "receiving_twoptm", "receiving_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["TE", "WR"]}, "datetime_utc": "20181025 235625", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.30.6-50-g4995c19", "filename_prefix": "nfl_WT_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 9000, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1467032134, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-4.6897712	0.1409503	tanh	0.4870998135	none	1	nadam	4668	156	6	500	56
-4.3139776	0.2210183	linear	0.5000907986	none	3	adam	7148	78	3	200	41
-4.4997248	-0.0089583	relu	0.6095496908	none	4	nadam	1176	104	4	200	49
-4.8029856	-0.0586848	sigmoid	0.4024626235	none	1	nadam	441	156	6	700	72
-4.3318268	0.1933488	sigmoid	0.3003007925	none	2	adamax	5446	52	2	200	49
-4.519204	0.1078756	relu	0.6062911664	none	2	adadelta	7908	104	4	500	75
-4.3436694	0.2139028	sigmoid	0.6836227509	none	2	adamax	4472	78	3	400	76
-4.377632	0.1938507	linear	0.3	none	5	adam	9000	52	2	100	20
-4.3203691	0.227038	linear	0.3666188522	none	2	adam	9000	130	5	100	20
-4.3621989	0.2207323	linear	0.3	none	3	adam	9000	182	7	100	20
-4.4331365	0.1556996	linear	0.3	none	2	adam	7898	26	1	100	20
-4.6392634	0.1063629	linear	0.5365788535	none	5	adam	1021	104	4	800	100
-4.417777	0.1715594	tanh	0.4825116689	none	5	adamax	6671	182	7	100	36
-4.3451154	0.2259097	linear	0.5628537338	none	5	adam	7771	104	4	200	46
-4.5926542	0.1660369	linear	0.6682138495	none	4	adamax	1512	26	1	1000	37
-4.2921549	0.2143859	sigmoid	0.3	none	1	adamax	5669	104	4	100	46
-4.8483027	-0.0400649	sigmoid	0.3	none	1	adagrad	100	130	5	100	100
-4.597071	0.1351514	sigmoid	0.3	none	1	adam	481	78	3	200	22
-4.3538273	0.2072584	sigmoid	0.6395633792	none	1	adamax	9000	104	4	1000	56
-4.6752384	0.132676	sigmoid	0.3	none	1	adamax	222	104	4	100	62
-4.8222818	0.0025512	relu	0.6981623979	none	5	adagrad	9000	26	1	900	20
-4.2905611	0.2059673	sigmoid	0.3	none	1	adamax	5987	78	3	200	23
-4.3375568	0.2161684	sigmoid	0.3	none	1	adadelta	8264	104	4	100	20
-4.2847711	0.2171911	linear	0.3	none	1	adam	5739	78	3	100	20
-4.3213468	0.2245819	linear	0.3	none	1	adam	9000	130	5	100	20
-4.3059044	0.2239662	linear	0.3	none	1	adagrad	9000	130	5	100	20
-4.3059044	0.2239662	linear	0.3	none	1	adagrad	9000	130	5	100	20
-4.3170715	0.2161245	linear	0.3	none	1	adam	6091	78	3	100	24
-4.3257446	0.2212768	sigmoid	0.3185823305	none	1	adamax	5560	78	3	200	20
-4.3426633	0.2055192	linear	0.5686760808	none	5	adam	5462	78	3	500	40
-5.262388	-0.1275566	relu	0.3852941426	none	1	adadelta	4935	182	7	700	100
-4.4198516	0.1325598	sigmoid	0.3642769242	none	4	adamax	5823	104	4	700	69
-4.3045192	0.2147917	sigmoid	0.7	none	1	adagrad	6964	130	5	100	27
-4.3278041	0.2095015	sigmoid	0.3154720076	none	1	adamax	6112	78	3	100	34
-4.4439693	0.1722167	sigmoid	0.6014645157	none	5	adamax	5811	78	3	100	26
-4.3967218	0.2191124	linear	0.4113141937	none	1	adamax	5847	130	5	900	20
-4.4561088	0.1555006	linear	0.6348627902	none	1	adagrad	7263	26	1	700	45
-4.3682527	0.2268479	sigmoid	0.3	none	1	adagrad	7197	182	7	100	20
-4.4031891	0.1604112	sigmoid	0.6020410779	none	1	adagrad	9000	26	1	100	23
-4.3869116	0.199622	linear	0.3	none	4	adam	5393	104	4	100	47
-4.4932224	0.1371932	relu	0.7	none	3	adadelta	9000	26	1	300	48
-4.3769712	0.1632285	sigmoid	0.5313993359	none	4	adadelta	3004	52	2	400	76
-4.3874386	0.1861424	tanh	0.5123802653	none	1	adam	6676	78	3	100	57
-4.3979623	0.217674	linear	0.7	none	5	adadelta	7803	182	7	100	100
-4.3607782	0.2108653	linear	0.4370936221	none	1	adam	5913	78	3	100	69
-4.3748523	0.1978761	linear	0.3	none	1	adadelta	6174	52	2	100	20
-4.7180741	0.0009507	relu	0.7	none	1	adadelta	100	26	1	100	100
-4.370442	0.1899437	relu	0.7	none	1	adadelta	9000	52	2	100	100
-4.370442	0.1899437	relu	0.7	none	1	adadelta	9000	52	2	100	100
-4.3257991	0.2230239	linear	0.3	none	1	adam	6556	104	4	300	20
-4.374175	0.2026543	relu	0.7	none	1	adadelta	9000	78	3	100	100
-4.5942478	0.1531943	sigmoid	0.3	none	1	adam	5755	156	6	500	50
-4.3505088	0.196517	linear	0.3	none	1	adagrad	6627	52	2	300	20
-4.3737191	0.1952857	sigmoid	0.7	none	1	adagrad	6581	52	2	300	100
-4.3404424	0.2331276	linear	0.3	none	5	adagrad	9000	182	7	1000	20
-4.3707625	0.2104359	linear	0.3	none	5	adamax	5871	104	4	400	20
-4.3802028	0.1928639	relu	0.6704022441	none	1	adadelta	9000	52	2	100	100
-4.370442	0.1899437	relu	0.7	none	1	adadelta	9000	52	2	100	100
-4.3202177	0.2193956	sigmoid	0.5066120028	none	1	adagrad	7362	104	4	500	20
-4.3574287	0.2169201	tanh	0.5834822473	none	1	adamax	9000	156	6	100	20
-4.2952976	0.2193161	sigmoid	0.7	none	1	adagrad	9000	104	4	100	65
-4.2916678	0.2191327	sigmoid	0.7	none	1	adagrad	9000	104	4	100	61
-4.3397031	0.2122243	linear	0.3097083665	none	3	adagrad	5074	78	3	200	20
-4.3206821	0.2138765	linear	0.3095774212	none	1	adam	5007	78	3	500	20
-4.2982627	0.2200752	sigmoid	0.7	none	1	adagrad	9000	104	4	100	60
-4.3057096	0.219545	sigmoid	0.3702204726	none	1	adagrad	6272	104	4	300	43
-4.4294025	0.159552	linear	0.3	none	1	adadelta	9000	26	1	100	100
-4.4294025	0.159552	linear	0.3	none	1	adadelta	9000	26	1	100	100
-4.4294025	0.159552	linear	0.3	none	1	adadelta	9000	26	1	100	100
-4.4339735	0.1604543	relu	0.3478792841	none	1	adadelta	9000	26	1	100	94

{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xp", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds"], "extra_stats": [], "model_player_stat": "fd_score_off#1", "model_team_stat": null, "player_stats": ["fumbles_lost", "receiving_rec", "receiving_targets", "receiving_tds", "receiving_twoptm", "receiving_yds", "rushing_att", "rushing_tds", "rushing_twoptm", "rushing_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["RB"]}, "datetime_utc": "20181025 165723", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.30.6-50-g4995c19", "filename_prefix": "nfl_RB_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 3500, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 2118956894, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-5.0271529	0.2068643	linear	0.4397537984	none	2	nadam	557	60	2	500	34
-4.9159631	0.2320291	linear	0.3740885709	none	4	adam	2533	210	7	400	64
-5.5432207	-0.0370098	relu	0.4595968353	none	2	adadelta	1800	210	7	600	27
-5.220524	0.1016017	relu	0.6989326449	none	4	adadelta	1479	120	4	900	22
-4.9336239	0.2131049	sigmoid	0.4490156778	none	4	nadam	1719	180	6	600	21
-4.8142737	0.2104049	sigmoid	0.3064612088	none	2	adam	2249	30	1	900	61
-4.6857108	0.2740896	linear	0.4710706605	none	1	adamax	2234	90	3	300	72
-4.6875242	0.2780362	sigmoid	0.7	none	1	adamax	3500	180	6	100	83
-6.0454983	-0.0886103	linear	0.3	none	1	adamax	100	30	1	1000	90
-4.5601741	0.2887961	linear	0.5559400033	none	1	adagrad	2286	90	3	200	100
-4.5884506	0.2964403	linear	0.7	none	1	adagrad	2753	150	5	100	100
-5.0493908	0.1565768	relu	0.3	none	3	adagrad	100	30	1	100	75
-5.2221111	0.1388219	tanh	0.3	none	3	adagrad	100	30	1	100	99
-4.9611604	0.1200564	relu	0.5724915626	none	3	adagrad	2400	180	6	100	22
-4.5884398	0.2804531	linear	0.6938096105	none	1	adagrad	3328	180	6	200	22
-4.6851319	0.2575633	linear	0.3723289305	none	1	adagrad	788	30	1	200	100
-4.6535361	0.2750074	linear	0.7	none	1	nadam	3500	150	5	200	100
-4.6102072	0.2700437	linear	0.7	none	2	adagrad	2474	30	1	200	100
-4.7152997	0.2244783	sigmoid	0.6615562357	none	5	adadelta	1545	30	1	1000	98
-4.6440814	0.2387608	sigmoid	0.7	none	5	adadelta	1212	60	2	100	100
-4.6892883	0.2610819	linear	0.5780965773	none	1	adagrad	3156	210	7	100	20
-5.8185679	-0.041788	sigmoid	0.3	none	5	adadelta	100	30	1	100	20
-4.6333981	0.2870451	linear	0.5472158468	none	1	adagrad	1906	60	2	200	100
-4.6706543	0.2770193	linear	0.4430017581	none	1	adagrad	3500	210	7	300	27
-4.7231132	0.2574848	linear	0.7	none	5	adadelta	3500	30	1	100	100
-5.548246	0.0003807	sigmoid	0.5363611803	none	4	adadelta	100	90	3	100	63
-4.5288173	0.2969042	linear	0.5914757166	none	1	adagrad	2203	60	2	200	100
-4.7516222	0.259723	relu	0.7	none	1	adagrad	3374	210	7	1000	38
-4.7735091	0.2682507	linear	0.6687311818	none	1	adagrad	2139	180	6	200	73
-4.6620556	0.2470752	sigmoid	0.7	none	3	adagrad	3082	30	1	800	100
-4.5799646	0.2686182	linear	0.7	none	1	adamax	2759	30	1	200	100
-4.7061094	0.2440188	sigmoid	0.6176791348	none	1	nadam	2178	30	1	800	100
-4.7991071	0.2235513	relu	0.5821513109	none	1	adamax	2780	30	1	800	100
-4.5615441	0.2540219	sigmoid	0.7	none	3	adagrad	1013	90	3	100	100
-5.0044916	0.2592733	sigmoid	0.7	none	1	adagrad	988	210	7	300	100
-4.5538806	0.2983706	linear	0.7	none	2	adagrad	2904	90	3	100	85
-4.5727054	0.2696037	linear	0.7	none	3	adagrad	1127	60	2	100	100
-4.8964629	0.2560377	tanh	0.7	none	2	adagrad	2458	90	3	300	81
-4.630863	0.2673035	linear	0.7	none	1	adagrad	2201	60	2	100	100
-4.6183641	0.2457219	sigmoid	0.7	none	5	adadelta	1930	30	1	100	100
-4.517132	0.2979624	linear	0.4862788318	none	4	adagrad	2709	90	3	100	86
-4.5153754	0.2485687	linear	0.7	none	3	adagrad	899	30	1	100	85
-4.7295379	0.2290884	sigmoid	0.7	none	4	adagrad	863	30	1	100	100
-4.92551	0.1921122	linear	0.7	none	4	adagrad	1132	30	1	100	70
-4.5662322	0.2557776	linear	0.4722841716	none	3	adagrad	1807	30	1	100	90
-4.6646711	0.254111	sigmoid	0.6533533433	none	2	nadam	3388	30	1	900	95
-4.7755632	0.2405608	linear	0.7	none	3	adadelta	2742	30	1	900	100
-5.5872225	-0.0596808	linear	0.7	none	5	adagrad	3500	120	4	100	26
-4.6498633	0.2672356	linear	0.3756147772	none	1	adagrad	2423	30	1	100	100
-4.7391091	0.2473264	sigmoid	0.7	none	1	adam	3107	30	1	600	20
-4.5995782	0.2484153	linear	0.6790498039	none	3	adagrad	1902	30	1	100	100
-4.56407	0.2517947	linear	0.7	none	4	adagrad	2775	150	5	100	91
-4.745988	0.2546316	linear	0.7	none	2	adagrad	1119	30	1	100	91
-4.5564114	0.2724162	linear	0.3	none	3	adagrad	2166	30	1	100	100
-4.6442606	0.2549518	sigmoid	0.3	none	4	adagrad	2881	30	1	100	96
-4.5536253	0.2992418	linear	0.4110066607	none	3	adagrad	3500	120	4	100	88
-4.5208043	0.2940075	linear	0.4772541587	none	3	adagrad	3500	90	3	100	84
-4.7183648	0.2487578	linear	0.7	none	3	adagrad	1870	210	7	100	85
-4.7568537	0.2505225	linear	0.4936789575	none	3	adagrad	2947	30	1	300	88
-4.6522565	0.2680742	linear	0.5176395824	none	1	adamax	3500	30	1	100	89
-4.5957365	0.2833048	linear	0.6336170503	none	1	adamax	1474	60	2	200	100
-4.6491795	0.2910823	linear	0.3136889459	none	3	adam	3500	90	3	100	93
-4.6390038	0.2706463	linear	0.5393937891	none	1	adamax	2539	30	1	200	100
-4.6562837	0.2483663	linear	0.7	none	1	adamax	723	60	2	100	100
-4.6729089	0.2742971	linear	0.4238790783	none	4	adagrad	3500	30	1	100	85
-4.6042166	0.2848607	linear	0.3	none	3	adagrad	3500	90	3	100	93
-4.5568808	0.2061121	linear	0.7	none	4	adagrad	791	90	3	100	88
-4.617737	0.2854655	sigmoid	0.6671055061	none	3	adagrad	3500	90	3	100	100
-5.0152209	0.1767564	tanh	0.5807896328	none	1	adagrad	1904	210	7	800	38
-4.6397578	0.2440764	linear	0.7	none	5	adagrad	3500	30	1	1000	100

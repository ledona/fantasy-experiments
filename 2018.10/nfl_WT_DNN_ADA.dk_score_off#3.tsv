{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xpt", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds"], "extra_stats": [], "model_player_stat": "dk_score_off#3", "model_team_stat": null, "player_stats": ["fumbles_lost", "receiving_rec", "receiving_tds", "receiving_twoptm", "receiving_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["TE", "WR"]}, "datetime_utc": "20181022 222052", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.30.6-26-g58e3da5", "filename_prefix": "nfl_WT_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 9000, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 481751271, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-5.1851061	0.1723428	sigmoid	0.6145950242	none	3	adadelta	5170	50	2	600	29
-5.3162015	0.1231252	relu	0.5072833512	none	3	adamax	7297	125	5	500	30
-5.4272178	0.0465532	tanh	0.6419179433	none	3	adam	2656	100	4	700	77
-5.3279884	0.1220156	tanh	0.3526380812	none	2	adamax	7482	100	4	1000	43
-5.1205257	0.1741864	sigmoid	0.4703520453	none	4	adadelta	8413	50	2	500	38
-5.3746786	0.1411749	tanh	0.5079630797	none	5	adagrad	1611	75	3	500	42
-5.3343968	0.0685791	relu	0.540339119	none	5	nadam	6756	175	7	900	69
-5.0879847	0.169629	sigmoid	0.4938731213	none	4	adamax	5154	150	6	400	60
-6.7056851	-0.6236022	sigmoid	0.3	none	1	nadam	100	175	7	1000	100
-5.0134293	0.2415545	linear	0.3	none	5	adamax	9000	175	7	100	23
-4.9968738	0.2420923	linear	0.3	none	1	adagrad	9000	175	7	100	100
-6.0065935	-0.1208011	sigmoid	0.3	none	1	adagrad	100	175	7	100	100
-5.2248178	0.1392181	relu	0.7	none	1	adagrad	9000	25	1	100	100
-4.9968738	0.2420923	linear	0.3	none	1	adagrad	9000	175	7	100	100
-4.9968738	0.2420923	linear	0.3	none	1	adagrad	9000	175	7	100	100
-7.6522107	-0.4911497	linear	0.7	none	1	adagrad	100	175	7	100	100
-5.1103757	0.2045656	linear	0.300582644	none	4	adam	5806	75	3	900	32
-5.3741524	0.1277695	tanh	0.3	none	5	adagrad	2596	25	1	200	74
-5.1715405	0.1882348	sigmoid	0.3	none	1	adagrad	4615	50	2	200	100
-5.7856397	-6.48e-05	relu	0.7	none	5	adamax	6869	175	7	100	20
-5.1370297	0.1794201	relu	0.3307754377	none	1	adagrad	9000	75	3	700	100
-5.0227059	0.239116	linear	0.3425132897	none	1	adagrad	8673	175	7	100	100
-5.041659	0.2145164	linear	0.3	none	1	adagrad	8579	75	3	500	100
-5.1704994	0.1891543	sigmoid	0.4942944207	none	5	adamax	6158	175	7	100	100
-5.0255758	0.2383728	linear	0.3689879808	none	1	adagrad	9000	175	7	200	97
-5.098073	0.2077861	sigmoid	0.3004287009	none	1	adagrad	6073	175	7	900	100
-4.9968738	0.2420923	linear	0.3	none	1	adagrad	9000	175	7	100	100
-5.027123	0.2393257	linear	0.3	none	3	adam	8931	175	7	100	38
-4.9968738	0.2420923	linear	0.3	none	1	adagrad	9000	175	7	100	100
-4.9821556	0.2448393	linear	0.3	none	1	adagrad	9000	150	6	100	100
-5.2663018	0.1440558	linear	0.3	none	1	adagrad	9000	25	1	100	100
-5.018122	0.2204307	linear	0.3	none	1	adagrad	7847	100	4	600	100
-5.0127209	0.2370101	linear	0.3	none	1	adagrad	8897	150	6	200	100
-5.037831	0.2232392	linear	0.3278605576	none	1	adagrad	7978	100	4	100	100
-5.0673497	0.2151891	linear	0.3	none	1	adagrad	7208	75	3	1000	100
-5.0128798	0.2369357	linear	0.3615251367	none	4	adagrad	9000	150	6	100	100
-5.0028366	0.2216714	linear	0.3918995778	none	1	adagrad	6031	100	4	700	30
-5.0709201	0.2220629	sigmoid	0.3907325736	none	1	adagrad	5267	125	5	500	100
-5.0462124	0.217258	linear	0.3	none	1	adagrad	6554	100	4	600	20
-4.9902279	0.2314494	linear	0.4503432176	none	1	adagrad	5825	125	5	800	77
-4.9821556	0.2448393	linear	0.3	none	1	adagrad	9000	150	6	100	100
-4.9711339	0.223274	linear	0.4632633977	none	1	adagrad	6199	100	4	1000	20
-4.9821556	0.2448393	linear	0.3	none	1	adagrad	9000	150	6	100	100
-4.9821556	0.2448393	linear	0.3	none	1	adagrad	9000	150	6	100	100
-4.9821556	0.2448393	linear	0.3	none	1	adagrad	9000	150	6	100	100
-5.0272506	0.2345838	linear	0.3309911127	none	1	adamax	9000	125	5	100	69
-4.998343	0.2389718	linear	0.3	none	1	adagrad	9000	150	6	100	85
-5.3014451	0.1411831	relu	0.3	none	1	adamax	7233	25	1	1000	20
-4.9960577	0.2369301	linear	0.3	none	1	adamax	9000	150	6	100	100
-4.9821556	0.2448393	linear	0.3	none	1	adagrad	9000	150	6	100	100
-5.0387025	0.2148646	linear	0.3509342264	none	1	adagrad	6023	100	4	1000	35
-5.0529545	0.2197771	sigmoid	0.4611532883	none	2	adagrad	5937	125	5	1000	20
-5.0458464	0.2118883	linear	0.4732168174	none	3	adagrad	5964	75	3	1000	20
-5.0117496	0.2188676	linear	0.4619724904	none	1	adagrad	6289	100	4	1000	20
-5.0459699	0.2266235	linear	0.4575352723	none	3	adagrad	6101	125	5	600	24
-5.0825711	0.2212945	linear	0.4787170644	none	1	adam	6065	100	4	300	51
-4.9930334	0.2420425	linear	0.3	none	1	adagrad	7410	175	7	200	100
-5.0779546	0.2174939	linear	0.4770218779	none	1	adamax	6068	100	4	400	39
-4.9676406	0.2381952	linear	0.3349698876	none	5	adam	8465	150	6	200	100
-5.2562614	0.1674612	linear	0.3	none	5	nadam	9000	150	6	400	100
-5.0482355	0.2177503	linear	0.4735243232	none	1	adagrad	6071	100	4	700	75
-5.0303251	0.2239383	linear	0.4589407942	none	1	adagrad	5920	100	4	1000	20
-4.9848433	0.2363283	linear	0.436013552	none	1	adagrad	5744	125	5	1000	100
-5.0147247	0.2381739	linear	0.3003622188	none	2	adagrad	8331	150	6	500	100
-5.2172269	0.15508	sigmoid	0.3619793281	none	5	adam	8463	125	5	100	100
-5.052401	0.2197847	linear	0.4492842148	none	4	adagrad	8429	100	4	400	42
-5.0592279	0.2243711	linear	0.3541769571	none	5	adadelta	8460	125	5	100	100
-5.2345575	0.163232	relu	0.428569235	none	1	adam	6179	75	3	1000	20
-5.0790914	0.2317463	linear	0.4183122094	none	3	adamax	5711	150	6	500	100
-5.1050409	0.2151977	linear	0.4188729859	none	1	nadam	6191	100	4	1000	20

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8036a1-f812-4cbb-ba69-8132f15b2ca4",
   "metadata": {},
   "source": [
    "# This notebook creates a dataset for min/max winning scores\n",
    "## Prep\n",
    "- Ensure that database filenames and dates in SPORT_CFG are correct and that the files exist in $FANTASY_HOME\n",
    "- For LOL make sure that cost csv files in $FANTASY_LINEUP_CACHE_DIR\n",
    "\n",
    "## Data will include\n",
    "- min win df score\n",
    "- max win df score\n",
    "- median team score (real game scores)\n",
    "- 75th percentile team score (real game scores)\n",
    "- number of slate games\n",
    "- median df score for each player position\n",
    "- 75th percentile df score for each player position\n",
    "- median df score of top 50% of players for each position over the previous W weeks\n",
    "- 75th percentile df score of top 50% for each position over the previous W weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading log filters from '/fantasy/log-filter.yaml'\n"
     ]
    }
   ],
   "source": [
    "# Configuration and imports\n",
    "\n",
    "from datetime import date\n",
    "from functools import partial\n",
    "import re\n",
    "from typing import Optional, Callable\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from fantasy_py import ContestStyle\n",
    "from fantasy_py.lineup.strategy import GeneralPrizePool, FiftyFifty, Contest\n",
    "\n",
    "from best_possible_lineup_score import get_stat_names\n",
    "\n",
    "\n",
    "FANTASY_HOME = os.environ['FANTASY_HOME']\n",
    "CONTEST_DATA_PATH = os.path.join(os.environ['FANTASY_ARCHIVE_BASE'], \"betting\")\n",
    "\n",
    "# the datasets to generate, dict mapping sport to dict with keys sport, min_date, max_date, historic data filename\n",
    "SPORT_CFGS = {\n",
    "    'mlb': {\n",
    "        'min_date': date(2019, 1, 1),\n",
    "        'max_date': date(2021, 1, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"mlb_hist_20082021.scored.db\"),\n",
    "        'cost_pos_drop': {'DH', 'RP'},\n",
    "        'cost_pos_rename': {'SP': 'P'},\n",
    "    },\n",
    "    'nfl': {\n",
    "        'min_date': date(2020, 1, 12),  # no NHL dfs slates before this date\n",
    "        'max_date': date(2021, 4, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"nfl_hist_2009-2020.scored.db\"),\n",
    "    },\n",
    "    'nba': {\n",
    "        'min_date': {None: date(2017, 8, 1), 'yahoo': date(2020, 8, 1)},\n",
    "        'max_date': date(2021, 8, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"nba_hist_20082009-20202021.scored.db\"),\n",
    "    },\n",
    "    'nhl': {\n",
    "        'min_date': {'draftkings': date(2019, 10, 9),   # dk changed scoring formula for nhl\n",
    "                     'fanduel': date(2019, 8, 1),       # fd missing positional data prior to 2019 season\n",
    "                     None: date(2017, 8, 1)},\n",
    "        'max_date': date(2021, 4, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"nhl_hist_20072008-20192020.scored.db\"),\n",
    "        'cost_pos_rename': {'LW': 'W', 'RW': 'W'},\n",
    "    },\n",
    "    'lol': {\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"lol_hist_2014-2021.scored.db\"),\n",
    "        'min_date': date(2020, 1, 1),\n",
    "        'max_date': date(2021, 1, 1),\n",
    "        'services': ['draftkings', 'fanduel'],\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# days to use to identify top players going into a slate\n",
    "TOP_PLAYER_DAYS = 21\n",
    "# players above this percentil over the last TOP_PLAYER_DAYS are considered top players\n",
    "TOP_PLAYER_PERCENTILE = .70\n",
    "\n",
    "\n",
    "# fanduel/draftkings/yahoo\n",
    "SERVICES = [\n",
    "    'draftkings',\n",
    "    'fanduel',\n",
    "    'yahoo',\n",
    "]\n",
    "\n",
    "STYLES: list[str] = [\n",
    "    ContestStyle.CLASSIC,\n",
    "    ContestStyle.SHOWDOWN,\n",
    "]\n",
    "\n",
    "CONTEST_TYPES: list[Contest] = [\n",
    "    FiftyFifty,\n",
    "    GeneralPrizePool,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617fba26-4d6a-4f02-b988-bc7ca0f93f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get contest data\n",
    "def infer_contest_style(service, title) -> ContestStyle:\n",
    "    if service == \"draftkings\":\n",
    "        if \"Showdown\" in title or re.match(\".*.{2,3} vs .{2,3}\\)\", title):\n",
    "            return ContestStyle.SHOWDOWN\n",
    "        return ContestStyle.CLASSIC\n",
    "    if service == \"fanduel\":\n",
    "        if \"@\" in (title or \"\"):\n",
    "            return ContestStyle.SHOWDOWN\n",
    "        return ContestStyle.CLASSIC\n",
    "    if service == \"yahoo\":\n",
    "        if (\n",
    "            \" Cup \" in title\n",
    "            or \" to 1st]\" in title\n",
    "            or \" 50/50\" in title\n",
    "            or \"QuickMatch vs \" in title\n",
    "            or \"H2H vs \" in title\n",
    "            or \"-Team\" in title\n",
    "            or \"Freeroll\" in title  # N-team contests are classic\n",
    "            or \"Quadruple Up\" in title\n",
    "            or \"Guaranteed\" in title\n",
    "        ):\n",
    "            return ContestStyle.CLASSIC\n",
    "    raise NotImplementedError(f\"Could not infer contest style for {service=} {title=}\")\n",
    "\n",
    "\n",
    "def infer_contest_type(service, title) -> str:\n",
    "    if service == \"draftkings\":\n",
    "        if re.match(\".* vs\\. [^)]+$\", title):\n",
    "            return \"H2H\"\n",
    "        return FiftyFifty.NAME if \"Double Up\" in title else GeneralPrizePool.NAME\n",
    "    if service == \"fanduel\":\n",
    "        if \"Head-to-head\" in (title or \"\"):\n",
    "            return \"H2H\"\n",
    "        if (title or \"\").startswith(\"50/50\"):\n",
    "            return FiftyFifty.NAME\n",
    "        return GeneralPrizePool.NAME\n",
    "    if service == \"yahoo\":\n",
    "        if \" QuickMatch vs \" in title or \"H2H vs \" in title:\n",
    "            return \"H2H\"\n",
    "        if \" 50/50\" in title:\n",
    "            return FiftyFifty.NAME\n",
    "        if (\n",
    "            \" Cup \" in title\n",
    "            or \" to 1st]\" in title\n",
    "            or \"Freeroll\" in title\n",
    "            or \"Quadruple Up\" in title\n",
    "            or\n",
    "            # multi-team games are GPP if not caught by 50/50\n",
    "            \"-Team\" in title\n",
    "            or\n",
    "            # treat winner takes all like a gpp\n",
    "            title.endswith(\"Team Winner Takes All\")\n",
    "            or \"Guaranteed\" in title\n",
    "        ):\n",
    "            return GeneralPrizePool.NAME\n",
    "    raise NotImplementedError(f\"Could not infer contest type for {service=} {title=}\")\n",
    "\n",
    "\n",
    "def add_bet_links(service, contest_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_contest_df(\n",
    "    service, sport, style, contest_type, min_date, max_date\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    create a dataframe from the contest dataset\n",
    "    \"\"\"\n",
    "    contest_csv_path = os.path.join(CONTEST_DATA_PATH, service + \".contest.csv\")\n",
    "    contest_df = pd.read_csv(contest_csv_path, parse_dates=[\"date\"]).query(\n",
    "        \"sport == @sport and @min_date <= date < @max_date\"\n",
    "    )[[\"contest_id\", \"date\", \"title\", \"top_score\", \"last_winning_score\", \"entries\"]]\n",
    "    contest_df.date = contest_df.date.dt.normalize()\n",
    "    contest_df = contest_df.where(contest_df.notnull(), None)\n",
    "\n",
    "    # add style and type\n",
    "    #     with pd.option_context('max_rows', 1000, 'max_colwidth', 100):\n",
    "    #         display(contest_df)\n",
    "    contest_df[\"style\"] = contest_df.title.map(partial(infer_contest_style, service))\n",
    "    contest_df[\"type\"] = contest_df.title.map(partial(infer_contest_type, service))\n",
    "    queries = []\n",
    "    if style is not None:\n",
    "        # print(f\"Filtering for {style=}\")\n",
    "        queries.append(\"style == @style\")\n",
    "    if contest_type is not None:\n",
    "        # print(f\"Filtering for {contest_type=}\")\n",
    "        queries.append(\"type == @contest_type.NAME\")\n",
    "    if len(queries) > 0:\n",
    "        contest_df = contest_df.query(\" and \".join(queries))\n",
    "\n",
    "    betting_csv_path = os.path.join(CONTEST_DATA_PATH, service + \".betting.csv\")\n",
    "    bet_df = (\n",
    "        pd.read_csv(betting_csv_path)\n",
    "        .drop_duplicates(\"contest_id\")\n",
    "        .set_index(\"contest_id\")[[\"link\"]]\n",
    "    )\n",
    "    contest_df = contest_df.merge(bet_df, how=\"left\", on=\"contest_id\")\n",
    "    return contest_df\n",
    "\n",
    "\n",
    "# contest_df = get_contest_df(\"draftkings\", \"lol\", ContestStyle.CLASSIC, FiftyFifty, date(2019, 1, 1), date(2020, 1, 1))\n",
    "# with pd.option_context('max_rows', 1000, 'max_columns', 100, 'max_colwidth', 99999):\n",
    "#    display(contest_df.sort_values(['style', 'type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b41b142-0915-4b2b-85b9-e91effe5f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# player draft dataframe creation\n",
    "\n",
    "SERVICE_ABBR = {\n",
    "    'fanduel': 'fd',\n",
    "    'draftkings': 'dk',\n",
    "    'yahoo': 'y'\n",
    "}\n",
    "\n",
    "# TODO: better solution for LOL would be to take the team name and use team_remaps\n",
    "# remapping of team abbrs found in draft data to those found in database,\n",
    "# dict[sport -> dict[service -> dict[draft abbr -> db abbr]]]\n",
    "# if service is None, then use all services\n",
    "LOL_ABBR_REMAPS = {\n",
    "    None: {\n",
    "        'AF':  'KF',  # Afreeca Freecs -> Kwangdong Freecs\n",
    "        'AGO': 'RGO',\n",
    "        'APK': 'SP',\n",
    "        'EST': 'ES',  # eStar\n",
    "        'FCS': 'S04',\n",
    "        'FTC': 'FNC',\n",
    "        'FQ':  'FLY',\n",
    "        'IM':  'IMT',\n",
    "        'ITZ': 'INTZ',\n",
    "        'MG':  'MSF',\n",
    "        'ML':  'MAD',\n",
    "        'OHT': '100',\n",
    "        'ROG': 'RGE',\n",
    "        'SB':  'LSB',\n",
    "        'SK':  'SKG',  # SK Gaming\n",
    "        'TD':  'NS',\n",
    "        'VFG': 'GIA',\n",
    "        'VG':  'RA',\n",
    "    },\n",
    "    'fanduel': {\n",
    "        'ES':  'XL',  # Excel\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def lol_abbr_remap(service, data_row) -> str:\n",
    "    \"\"\" for lol return a remapped team abbr if there is a remapping\"\"\"\n",
    "    for service_key in [service, None]:\n",
    "        if service_key in LOL_ABBR_REMAPS and data_row.team_abbr in LOL_ABBR_REMAPS[service_key]:\n",
    "            return LOL_ABBR_REMAPS[service_key][data_row.team_abbr]\n",
    "    return data_row.team_abbr\n",
    "\n",
    "\n",
    "def nfl_abbr_remap(service, row): return \\\n",
    "    'OAK' if (row.team_abbr == 'LV' and row.date <\n",
    "              pd.Timestamp(2020, 7, 1)) else row.team_abbr\n",
    "\n",
    "\n",
    "def mlb_abbr_remap(service, row): return \\\n",
    "    'WAS' if (row.team_abbr == 'WSH' and row.date <\n",
    "              pd.Timestamp(2020, 1, 1)) else row.team_abbr\n",
    "\n",
    "\n",
    "ABBR_REMAPPERS: dict[str, Callable[[str, str], str]] = {\n",
    "    'lol': lol_abbr_remap,\n",
    "    'nfl': nfl_abbr_remap,\n",
    "    'mlb': mlb_abbr_remap,\n",
    "}\n",
    "\n",
    "\n",
    "def get_draft_df(service, sport, style, min_date, max_date) -> pd.DataFrame:\n",
    "    csv_path = os.path.join(CONTEST_DATA_PATH, service + \".draft.csv\")\n",
    "    draft_df = pd.read_csv(csv_path, parse_dates=['date']) \\\n",
    "                 .query('sport == @sport and @min_date <= date < @max_date')\n",
    "    assert len(draft_df) > 0, \\\n",
    "        f\"no draft data found for {sport=}, {service=}, {style=}, {min_date=}, {max_date=}\"\n",
    "\n",
    "    draft_df['service'] = draft_df.contest.map(\n",
    "        lambda contest: contest.split('-', 1)[0])\n",
    "    draft_df.team_abbr = draft_df.team_abbr.str.upper()\n",
    "    if sport in ABBR_REMAPPERS:\n",
    "        draft_df.team_abbr = draft_df.apply(\n",
    "            partial(ABBR_REMAPPERS[sport], service),\n",
    "            axis=1,\n",
    "        )\n",
    "    service_abbr = SERVICE_ABBR[service]\n",
    "    draft_df = draft_df.query('service == @service_abbr and team_abbr.notnull()')[\n",
    "        ['position', 'name', 'team_abbr', 'contest_id']]\n",
    "\n",
    "    return draft_df\n",
    "\n",
    "\n",
    "# draft_df = get_draft_df(SERVICE, SPORT, STYLE, MIN_DATE, MAX_DATE)\n",
    "# display(draft_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e119b90b-0d6a-453d-9c1f-16f9c934153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create team contest dataframes\n",
    "\n",
    "from fantasy_py import FANTASY_SERVICE_DOMAIN, util\n",
    "\n",
    "\n",
    "def create_team_contest_df(contest_df, draft_df, service, sport):\n",
    "    service_cls = util.CLSRegistry.get_class(FANTASY_SERVICE_DOMAIN, service)\n",
    "    abbr_remaps = service_cls.get_team_abbr_remapping(sport)\n",
    "\n",
    "    # add team/lineup draft data\n",
    "    team_contest_df = pd.merge(contest_df, draft_df, on=\"contest_id\")\n",
    "    team_contest_df.team_abbr = team_contest_df.team_abbr.map(\n",
    "        lambda abbr: abbr_remaps.get(abbr) or abbr\n",
    "    )\n",
    "\n",
    "    return team_contest_df\n",
    "\n",
    "\n",
    "# team_contest_df = create_team_contest_df(contest_df, draft_df, SERVICE, SPORT)\n",
    "# print(f\"{len(team_contest_df.contest_id.unique())} contests\")\n",
    "# display(team_contest_df)\n",
    "\n",
    "\n",
    "def common_title(title_series: pd.Series) -> str:\n",
    "    \"\"\"the title of a contest will be the common prefix amongst all the possible contest titles\"\"\"\n",
    "    title_list = title_series.tolist()\n",
    "    if None in title_list:\n",
    "        return \"\"\n",
    "    return os.path.commonprefix(title_list)\n",
    "\n",
    "\n",
    "def create_teams_contest_df(tc_df):\n",
    "    \"\"\"group contests together and create team sets used in each contest\"\"\"\n",
    "    tc_df = pd.DataFrame(\n",
    "        tc_df.groupby([\"contest_id\", \"date\", \"style\", \"type\", \"link\", \"entries\"]).agg(\n",
    "            {\n",
    "                \"team_abbr\": set,\n",
    "                \"title\": common_title,\n",
    "                \"top_score\": lambda score: score.mean(),\n",
    "                \"last_winning_score\": lambda score: score.mean(),\n",
    "            }\n",
    "        )\n",
    "    ).reset_index()\n",
    "    tc_df = tc_df.rename(columns={\"team_abbr\": \"teams\"})\n",
    "    tc_df[\"draft_team_count\"] = tc_df.teams.map(len)\n",
    "    return tc_df\n",
    "\n",
    "\n",
    "# teams_contest_df = create_teams_contest_df(team_contest_df)\n",
    "# display(f\"{len(teams_contest_df)} team sets\")\n",
    "# display(teams_contest_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a3d846-dec9-4f92-bf99-0b1534b9d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load slate data from db\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_slate_df(\n",
    "    db_filename, service, style, min_date, max_date\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    sql = f\"\"\"\n",
    "    select distinct daily_fantasy_slate.id as slate_id, date, \n",
    "        daily_fantasy_slate.name as slate_name, style as contest_style, abbr\n",
    "    from daily_fantasy_slate \n",
    "        join daily_fantasy_cost on daily_fantasy_slate.id = daily_fantasy_cost.daily_fantasy_slate_id\n",
    "        join team on team_id = team.id\n",
    "    where service = '{service}' and date between '{min_date}' and date('{max_date}', '-1 days')\n",
    "    \"\"\"\n",
    "\n",
    "    if style is not None:\n",
    "        sql += f\" and style = '{style.name}'\"\n",
    "\n",
    "    # print(sql)\n",
    "    db_df = pd.read_sql_query(sql, conn, parse_dates=[\"date\"])\n",
    "    # with pd.option_context('max_rows', 100):\n",
    "    #     display(db_df)\n",
    "    conn.close()\n",
    "    if len(db_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # get team sets\n",
    "    slate_db_df = pd.DataFrame(\n",
    "        db_df.groupby([\"slate_id\", \"date\", \"slate_name\", \"contest_style\"]).agg(\n",
    "            {\"abbr\": set}\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    try:\n",
    "        slate_db_df = slate_db_df.set_index(\"date\").rename(columns={\"abbr\": \"teams\"})\n",
    "    except Exception as ex:\n",
    "        raise ValueError(\"Error processing slate db df\", slate_db_df) from ex\n",
    "\n",
    "    slate_db_df[\"team_count\"] = slate_db_df.teams.map(len)\n",
    "    return slate_db_df\n",
    "\n",
    "\n",
    "# slate_db_df = get_slate_df('/fantasy/lol_hist_2014-2021.scored.db', \"draftkings\", ContestStyle.CLASSIC, '2020-09-09', '2020-09-10')\n",
    "# with pd.option_context('display.max_rows', 100):\n",
    "#     display(slate_db_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62e21f0-df36-41a9-9417-253ea5d800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get slate id\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "NO_SLATE_ID_FOUND = pd.Series({'slate_id': None, 'team_count': None})\n",
    "\n",
    "def get_slate_id(contest_row, slate_db_df) -> pd.Series:\n",
    "    \"\"\" \n",
    "    guesses the db slate id contest_row\n",
    "    returns - series of (slate_id, number of teams playing in slate)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_slates = slate_db_df.loc[[\n",
    "            contest_row.date]].sort_values('team_count')\n",
    "    except KeyError as ke:\n",
    "        print(f\"get_slate_id:: Key error/No slates found for {contest_row.date}\")\n",
    "        return NO_SLATE_ID_FOUND\n",
    "    try:\n",
    "        slates = date_slates.query(\"@contest_row.teams <= teams\")\n",
    "    except Exception as e:\n",
    "        print(f\"get_slate_id:: Unhandled exception querying for teams date {contest_row.date}: {e}\")\n",
    "        return NO_SLATE_ID_FOUND\n",
    "\n",
    "    slates_found = len(slates)\n",
    "    if slates_found == 0:\n",
    "        with pd.option_context('display.max_colwidth', None):\n",
    "            display(f\"No slates found for {contest_row.date} that matches teams {contest_row.teams}. date_slates_df=\",\n",
    "                    date_slates)\n",
    "        return NO_SLATE_ID_FOUND\n",
    "\n",
    "    return slates.iloc[0][['slate_id', 'team_count']]\n",
    "\n",
    "# slate_ids_df = teams_contest_df.apply(get_slate_id, axis=1)\n",
    "# display(slate_ids_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1781066-a71e-4332-8864-c2b5339434db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slate game score info\n",
    "\n",
    "def create_team_score_df(db_filename, slate_ids_str, top_player_percentile) -> Optional[pd.DataFrame]:\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    sql = f\"\"\"\n",
    "    select distinct daily_fantasy_slate.id as slate_id, game.id as game_id, \n",
    "           game.score_home, game.score_away\n",
    "    from daily_fantasy_slate\n",
    "        join daily_fantasy_cost on daily_fantasy_slate.id = daily_fantasy_cost.daily_fantasy_slate_id\n",
    "        join game on ((game.date = daily_fantasy_slate.date or \n",
    "\t\t               game.dt between daily_fantasy_slate.date and datetime(daily_fantasy_slate.date, '+1 days', '+6 hours')) and\n",
    "                      game.season = daily_fantasy_slate.season and \n",
    "                      (daily_fantasy_cost.team_id in (game.away_team_id, game.home_team_id)))\n",
    "    where daily_fantasy_slate.id in ({slate_ids_str})\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"team score sql\\n\", sql)\n",
    "    db_team_score_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    conn.close()\n",
    "    # display(\"team score df\", db_team_score_df)\n",
    "    if len(db_team_score_df) == 0:\n",
    "        return None\n",
    "\n",
    "    team_score_df = db_team_score_df.melt(id_vars=['slate_id', 'game_id'], value_vars=['score_home', 'score_away']) \\\n",
    "        .groupby(['slate_id']) \\\n",
    "        .agg({'value': ['median', lambda x: np.percentile(x, top_player_percentile * 100)]})\n",
    "    team_score_df.columns = ['team-med',\n",
    "                             f'team-{top_player_percentile * 100}th_pctl']\n",
    "    return team_score_df\n",
    "\n",
    "\n",
    "# for mlb double headers this will cause inaccuracy for players that played in both games\n",
    "# slate_ids_str = ','.join(map(str, slate_ids_df.slate_id.dropna()))\n",
    "# team_score_df = create_team_score_df(DB_FILENAME, slate_ids_str, TOP_PLAYER_PERCENTILE)\n",
    "# display(team_score_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0644384-abe0-421d-aaae-7479cc227f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get position scores\n",
    "from fantasy_py import SPORT_DB_MANAGER_DOMAIN, util\n",
    "\n",
    "def get_exploded_pos_df(\n",
    "    db_filename, sport, service_abbr, slate_ids_str,\n",
    "    cost_pos_drop: None | set, \n",
    "    cost_pos_rename: None | dict,\n",
    ") -> None | pd.DataFrame:\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    stat_names = get_stat_names(sport, service_abbr, as_str=True)\n",
    "\n",
    "    # for mlb double headers this query will cause inaccuracy for players that played in both games\n",
    "    # games have a date equal to the slate date or must have a datetime starting prior to 6am on the following date\n",
    "    sql = f\"\"\"\n",
    "    select daily_fantasy_slate.id as slate_id, positions as cost_positions, \n",
    "        player_position.abbr as stat_position, \n",
    "        value as score, daily_fantasy_cost.team_id, daily_fantasy_cost.player_id\n",
    "    from daily_fantasy_slate\n",
    "        join daily_fantasy_cost on \n",
    "           daily_fantasy_slate.id = daily_fantasy_cost.daily_fantasy_slate_id\n",
    "        join game on (\n",
    "           (game.date = daily_fantasy_slate.date or \n",
    "\t\t    game.dt between daily_fantasy_slate.date and datetime(daily_fantasy_slate.date, '+1 days', '+6 hours')) and\n",
    "           game.season = daily_fantasy_slate.season and \n",
    "           (daily_fantasy_cost.team_id in (game.away_team_id, game.home_team_id))\n",
    "        )\n",
    "        join calculation_datum on (\n",
    "            calculation_datum.game_id = game.id and \n",
    "            calculation_datum.player_id is daily_fantasy_cost.player_id and\n",
    "            calculation_datum.team_id = daily_fantasy_cost.team_id\n",
    "        )\n",
    "        join statistic on calculation_datum.statistic_id = statistic.id\n",
    "        join player on daily_fantasy_cost.player_id = player.id\n",
    "        join player_position on player.player_position_id = player_position.id\n",
    "    where daily_fantasy_slate.id in ({slate_ids_str}) and\n",
    "        statistic.name in ({stat_names})\n",
    "    \"\"\"\n",
    "    # print(\"Exploded POS data:\\n\", sql)\n",
    "\n",
    "    db_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    conn.close()\n",
    "\n",
    "    if len(db_df) == 0:\n",
    "        return None\n",
    "\n",
    "    db_manager = util.CLSRegistry.get_class(SPORT_DB_MANAGER_DOMAIN, sport)\n",
    "\n",
    "    def apply_func(row): \n",
    "        \"\"\" \n",
    "        use cost positions if available and valid\n",
    "        otherwise try to use stat_pos_to_cost_pos if available\n",
    "        otherwise use stat_position\n",
    "        \"\"\"\n",
    "        if row.cost_positions is not None and 'UNKNOWN' not in row.cost_positions.upper():\n",
    "            return row.cost_positions\n",
    "        if db_manager.STAT_POSITION_TO_COST_POSITIONS is not None:\n",
    "            cost_positions = db_manager \\\n",
    "                .STAT_POSITION_TO_COST_POSITIONS \\\n",
    "                .get(row.stat_position)\n",
    "            return '/'.join(cost_positions) if cost_positions else row.stat_position\n",
    "        return row.stat_position\n",
    "\n",
    "    db_df['position'] = db_df.apply(\n",
    "        apply_func,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    db_exploded_pos_df = db_df.assign(position=db_df.position.str.split('/')) \\\n",
    "                              .explode('position')\n",
    "\n",
    "    if cost_pos_drop is not None:\n",
    "        db_exploded_pos_df = db_exploded_pos_df.query(\n",
    "            'position not in @cost_pos_drop')\n",
    "    if cost_pos_rename is not None:\n",
    "        for old_pos, new_pos in cost_pos_rename.items():\n",
    "            db_exploded_pos_df.loc[db_exploded_pos_df.position ==\n",
    "                                   old_pos, 'position'] = new_pos\n",
    "    return db_exploded_pos_df\n",
    "\n",
    "\n",
    "def get_position_scores(db_exploded_pos_df, top_player_percentile):\n",
    "    db_pos_scores_df = db_exploded_pos_df[['slate_id', 'position', 'score']] \\\n",
    "        .groupby(['slate_id', 'position']) \\\n",
    "        .agg(['median', lambda x: np.percentile(x, top_player_percentile * 100)])\n",
    "    db_pos_scores_df.columns = ['med-dfs',\n",
    "                                f'{top_player_percentile * 100}th-pctl-dfs']\n",
    "    db_pos_scores_df = db_pos_scores_df.reset_index(level='position') \\\n",
    "        .pivot(columns='position', values=['med-dfs', f'{top_player_percentile * 100}th-pctl-dfs'])\n",
    "    return db_pos_scores_df\n",
    "\n",
    "\n",
    "# SPORT = 'lol'\n",
    "# SERVICE = 'draftkings'\n",
    "\n",
    "# db_exploded_pos_df = get_exploded_pos_df(DB_FILENAME, SPORT, SERVICE_ABBR[SERVICE], slate_ids_str)\n",
    "# display(db_exploded_pos_df)\n",
    "# db_pos_scores_df = get_position_scores(db_exploded_pos_df, TOP_PLAYER_PERCENTILE)\n",
    "# display(db_pos_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6651cfb6-f6ec-4df3-816f-fa69c680aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_scores(db_filename, db_exploded_pos_df,\n",
    "                      sport, service_abbr, top_player_days, min_date, max_date):\n",
    "    \"\"\" Get top player scores (e.g. players that are likely to be highly drafted) \"\"\"\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    stat_names = get_stat_names(sport, service_abbr, as_str=True)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    select game.date, calculation_datum.player_id, calculation_datum.team_id, calculation_datum.value as score \n",
    "    from game\n",
    "        join calculation_datum on calculation_datum.game_id = game.id\n",
    "        join statistic on calculation_datum.statistic_id = statistic.id\n",
    "    where statistic.name in ({stat_names}) \n",
    "        and date between date('{min_date}', '-{top_player_days} days') and date('{max_date}', '-1 days')\n",
    "    \"\"\"\n",
    "    # print(sql)\n",
    "    db_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    conn.close()\n",
    "    # display(db_df)\n",
    "\n",
    "    db_filtered_df = db_df.query(\n",
    "        '(player_id in @db_exploded_pos_df.player_id) '\n",
    "        'or (player_id.isnull() and team_id in @db_exploded_pos_df.team_id)'\n",
    "    )\n",
    "    return db_filtered_df\n",
    "\n",
    "\n",
    "# db_filtered_df = get_player_scores(DB_FILENAME, SPORT, SERVICE_ABBR[SERVICE], TOP_PLAYER_DAYS, MIN_DATE, MAX_DATE)\n",
    "# display(db_filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba062b9-2e3c-49aa-a2a8-af4bf313cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_df(teams_contest_df, slate_ids_df, team_score_df, db_pos_scores_df, top_lineup_scores) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    join contest, slate id, team score and player position scores\n",
    "    \"\"\"\n",
    "\n",
    "    dfs = [\n",
    "        teams_contest_df[['date', 'style', 'type',\n",
    "                          'top_score', 'last_winning_score', 'link']],\n",
    "        top_lineup_scores,\n",
    "        slate_ids_df,\n",
    "    ]\n",
    "    predict_df = pd.concat(dfs, axis='columns') \\\n",
    "                   .join(team_score_df, on='slate_id') \\\n",
    "                   .join(db_pos_scores_df, on='slate_id')\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "# predict_df = create_predict_df(teams_contest_df, slate_ids_df, team_score_df, db_pos_scores_df)\n",
    "# with pd.option_context('max_columns', 100):\n",
    "#     display(predict_df)\n",
    "\n",
    "\n",
    "# filename = f\"{SPORT}-{SERVICE}-{STYLE.name}-{CONTEST_TYPE.NAME}.csv\"\n",
    "# print(f\"Writing data to file '{filename}'\")\n",
    "# predict_df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b12c30-f03e-46bb-a79e-8f55d10b21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "\n",
    "from best_possible_lineup_score import (\n",
    "    TopScoreCacheMode, best_possible_lineup_score, best_score_cache\n",
    ")\n",
    "\n",
    "\n",
    "def generate_dataset(\n",
    "    sport, cfg, service, style, contest_type,\n",
    "    min_date=None, max_date=None, max_count: Optional[int] = None,\n",
    "    top_score_cache_mode: TopScoreCacheMode = 'default',\n",
    "    datapath: str = \"data\",\n",
    "    screen_lineup_constraints_mode='fail',\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    max_count - maximum number of slates to process\n",
    "    min_date - includsive\n",
    "    max_date - not inclusive\n",
    "    top_score_cache_mode - \n",
    "        'default'=load and use the cache, \n",
    "        'overwrite'=overwrite all existing cache data if any exists\n",
    "        'missing'=use all existing valid cache data, any cached failures will be rerun\n",
    "    \"\"\"\n",
    "    assert (min_date is None) or (max_date is None) or min_date < max_date, \\\n",
    "        \"invalidate date range. max_date must be greater than min_date. Or one must be None\"\n",
    "    filename = f\"{sport}-{service}-{style.name}-{contest_type.NAME}.csv\"\n",
    "    # print(f\"Creating data for file '{filename}'\")\n",
    "\n",
    "    db_filename = cfg['db_filename']\n",
    "    if min_date is None:\n",
    "        min_date = cfg['min_date']\n",
    "    if max_date is None:\n",
    "        max_date = cfg['max_date']\n",
    "\n",
    "    contest_df = get_contest_df(\n",
    "        service, sport, style, contest_type, min_date, max_date)\n",
    "    if contest_df is not None:\n",
    "        contest_df = contest_df.head(max_count)\n",
    "\n",
    "    draft_df = get_draft_df(service, sport, style, min_date, max_date)\n",
    "    # display(draft_df)\n",
    "\n",
    "    team_contest_df = create_team_contest_df(\n",
    "        contest_df, draft_df, service, sport)\n",
    "    # display(f\"{len(team_contest_df.contest_id.unique())} contests\", team_contest_df)\n",
    "\n",
    "    teams_contest_df = create_teams_contest_df(team_contest_df)\n",
    "    # with pd.option_context('display.max_rows', 100, 'display.max_colwidth', None):\n",
    "    #     display(f\"{len(teams_contest_df)} slate team sets in team_contest_df\",\n",
    "    #              teams_contest_df)\n",
    "\n",
    "    slate_db_df = get_slate_df(db_filename, service, style, min_date, max_date)\n",
    "    if slate_db_df is None:\n",
    "        raise ValueError(\"No slates found for\", service,\n",
    "                         style, min_date, max_date)\n",
    "    # with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    #     display(\"Slate db df\", slate_db_df)\n",
    "\n",
    "    slate_ids_df = teams_contest_df.apply(\n",
    "        get_slate_id, axis=1, args=(slate_db_df, ))\n",
    "    # display(slate_ids_df)\n",
    "\n",
    "    if len(slate_ids_df) == 0:\n",
    "        raise ValueError(\"No slates ids found (based on teams contest df)\")\n",
    "\n",
    "    try:\n",
    "        # need this for subsequent sql queries\n",
    "        slate_ids_str = ','.join(\n",
    "            map(str, slate_ids_df.slate_id.dropna().astype(int)))\n",
    "    except Exception as ex:\n",
    "        raise ValueError(\"Something wrong with slate_ids_df\",\n",
    "                         slate_ids_df) from ex\n",
    "\n",
    "    if len(slate_ids_str) == 0:\n",
    "        raise ValueError(\"No slate ids found after removing Nones\")\n",
    "    team_score_df = create_team_score_df(\n",
    "        db_filename, slate_ids_str, TOP_PLAYER_PERCENTILE)\n",
    "    if team_score_df is None:\n",
    "        raise ValueError(\"Empty team score df\")\n",
    "    # display(\"team score df\", team_score_df)\n",
    "\n",
    "    db_exploded_pos_df = get_exploded_pos_df(\n",
    "        db_filename, sport, SERVICE_ABBR[service], slate_ids_str,\n",
    "        cfg.get('cost_pos_drop'),\n",
    "        cfg.get('cost_pos_rename'),\n",
    "    )\n",
    "\n",
    "    if db_exploded_pos_df is None:\n",
    "        raise ValueError(\"No exploded positional data returned!\")\n",
    "    # with pd.option_context('display.max_rows', 100):\n",
    "    #     display(db_exploded_pos_df)\n",
    "    # return\n",
    "\n",
    "    db_pos_scores_df = get_position_scores(\n",
    "        db_exploded_pos_df, TOP_PLAYER_PERCENTILE)\n",
    "    # display(db_pos_scores_df)\n",
    "\n",
    "    # db_filtered_df = get_player_scores(\n",
    "    #     db_filename, db_exploded_pos_df,\n",
    "    #     sport, SERVICE_ABBR[service], TOP_PLAYER_DAYS, min_date, max_date\n",
    "    # )\n",
    "    # display(db_filtered_df)\n",
    "\n",
    "    # cache for top scores\n",
    "    with best_score_cache(sport, top_score_cache_mode, cache_dir=datapath) as top_score_dict:\n",
    "        best_possible_lineup_score_part = partial(\n",
    "            best_possible_lineup_score,\n",
    "            db_filename,\n",
    "            SERVICE_ABBR[service],\n",
    "            sport=sport,\n",
    "            best_score_cache=top_score_dict,\n",
    "            screen_lineup_constraints_mode=screen_lineup_constraints_mode\n",
    "        )\n",
    "\n",
    "        top_lineup_scores = slate_ids_df.slate_id.map(\n",
    "            best_possible_lineup_score_part\n",
    "        )\n",
    "\n",
    "    top_lineup_scores.name = 'best-possible-score'\n",
    "    predict_df = create_predict_df(\n",
    "        teams_contest_df, slate_ids_df, team_score_df, db_pos_scores_df, top_lineup_scores)\n",
    "    # with pd.option_context('max_columns', 100):\n",
    "    #     display(\"predict df\", predict_df)\n",
    "\n",
    "    filepath = os.path.join(\n",
    "        datapath, f\"{sport}-{service}-{style.name}-{contest_type.NAME}.csv\")\n",
    "    print(f\"Writing data to '{filepath}'\")\n",
    "    predict_df.to_csv(filepath, index=False)\n",
    "    return predict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a965c2-3f9a-4e8c-8770-35b707456d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mlb, draftkings, classic, FIFTY_FIFTY\n"
     ]
    },
    {
     "ename": "UndefinedVariableError",
     "evalue": "name 'contest_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/scope.py:198\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_resolvers:\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolvers[key]\n\u001b[1;32m    200\u001b[0m \u001b[39m# if we're here that means that we have no locals and we also have\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m# no resolvers\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/collections/__init__.py:986\u001b[0m, in \u001b[0;36mChainMap.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__missing__\u001b[39;49m(key)\n",
      "File \u001b[0;32m/usr/lib/python3.10/collections/__init__.py:978\u001b[0m, in \u001b[0;36mChainMap.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__missing__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m--> 978\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'contest_type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/scope.py:209\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39m# last ditch effort we look in temporaries\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[39m# these are created when parsing indexing expressions\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39m# e.g., df[df > 0]\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemps[key]\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'contest_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     slcm \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m (sport, service) \u001b[39min\u001b[39;00m WARN_ON_SCREEN_LINEUP_CONSTRAINTS_ERR \u001b[39melse\u001b[39;00m \\\n\u001b[1;32m     23\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m     df \u001b[39m=\u001b[39m generate_dataset(\n\u001b[1;32m     25\u001b[0m         sport, SPORT_CFGS[sport], service, style, contest_type,\n\u001b[1;32m     26\u001b[0m         min_date\u001b[39m=\u001b[39;49mmin_date, max_date\u001b[39m=\u001b[39;49mmax_date,\n\u001b[1;32m     27\u001b[0m         top_score_cache_mode\u001b[39m=\u001b[39;49mTOP_SCORE_CACHE_MODE,\n\u001b[1;32m     28\u001b[0m         screen_lineup_constraints_mode\u001b[39m=\u001b[39;49mslcm,\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[39mwith\u001b[39;00m pd\u001b[39m.\u001b[39moption_context(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m100\u001b[39m):\n\u001b[1;32m     31\u001b[0m         display(df)\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(sport, cfg, service, style, contest_type, min_date, max_date, max_count, top_score_cache_mode, datapath, screen_lineup_constraints_mode)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m max_date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     max_date \u001b[39m=\u001b[39m cfg[\u001b[39m'\u001b[39m\u001b[39mmax_date\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 35\u001b[0m contest_df \u001b[39m=\u001b[39m get_contest_df(\n\u001b[1;32m     36\u001b[0m     service, sport, style, contest_type, min_date, max_date)\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m contest_df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     contest_df \u001b[39m=\u001b[39m contest_df\u001b[39m.\u001b[39mhead(max_count)\n",
      "Cell \u001b[0;32mIn[2], line 90\u001b[0m, in \u001b[0;36mget_contest_df\u001b[0;34m(service, sport, style, contest_type, min_date, max_date)\u001b[0m\n\u001b[1;32m     88\u001b[0m     queries\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mtype == @contest_type.NAME\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(queries) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     contest_df \u001b[39m=\u001b[39m contest_df\u001b[39m.\u001b[39;49mquery(\u001b[39m'\u001b[39;49m\u001b[39m and \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(queries))\n\u001b[1;32m     92\u001b[0m betting_csv_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     93\u001b[0m     CONTEST_DATA_PATH, \n\u001b[1;32m     94\u001b[0m     service \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.betting.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     96\u001b[0m bet_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(betting_csv_path) \\\n\u001b[1;32m     97\u001b[0m            \u001b[39m.\u001b[39mdrop_duplicates(\u001b[39m'\u001b[39m\u001b[39mcontest_id\u001b[39m\u001b[39m'\u001b[39m) \\\n\u001b[1;32m     98\u001b[0m            \u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mcontest_id\u001b[39m\u001b[39m'\u001b[39m)[[\u001b[39m'\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/frame.py:4471\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4469\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m   4470\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 4471\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval(expr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   4473\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   4474\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[res]\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/frame.py:4609\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4606\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   4607\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mresolvers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresolvers\u001b[39m\u001b[39m\"\u001b[39m, ())) \u001b[39m+\u001b[39m resolvers\n\u001b[0;32m-> 4609\u001b[0m \u001b[39mreturn\u001b[39;00m _eval(expr, inplace\u001b[39m=\u001b[39;49minplace, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/eval.py:353\u001b[0m, in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[1;32m    345\u001b[0m env \u001b[39m=\u001b[39m ensure_scope(\n\u001b[1;32m    346\u001b[0m     level \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m    347\u001b[0m     global_dict\u001b[39m=\u001b[39mglobal_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m     target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m    351\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m parsed_expr \u001b[39m=\u001b[39m Expr(expr, engine\u001b[39m=\u001b[39;49mengine, parser\u001b[39m=\u001b[39;49mparser, env\u001b[39m=\u001b[39;49menv)\n\u001b[1;32m    355\u001b[0m \u001b[39m# construct the engine and evaluate the parsed expression\u001b[39;00m\n\u001b[1;32m    356\u001b[0m eng \u001b[39m=\u001b[39m ENGINES[engine]\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:813\u001b[0m, in \u001b[0;36mExpr.__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser \u001b[39m=\u001b[39m parser\n\u001b[1;32m    812\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visitor \u001b[39m=\u001b[39m PARSERS[parser](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser)\n\u001b[0;32m--> 813\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse()\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:832\u001b[0m, in \u001b[0;36mExpr.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    829\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39m    Parse an expression.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 832\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visitor\u001b[39m.\u001b[39;49mvisit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpr)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:421\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mSyntaxError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39monly a single expression is allowed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m expr \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mbody[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(expr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:424\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Expr\u001b[39m(\u001b[39mself\u001b[39m, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mvalue, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:750\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BoolOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_evaluate_binop(op, node\u001b[39m.\u001b[39mop, lhs, rhs)\n\u001b[1;32m    749\u001b[0m operands \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 750\u001b[0m \u001b[39mreturn\u001b[39;00m reduce(visitor, operands)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:744\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BoolOp.<locals>.visitor\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisitor\u001b[39m(x, y):\n\u001b[1;32m    743\u001b[0m     lhs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_visit_binop(x)\n\u001b[0;32m--> 744\u001b[0m     rhs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_visit_binop(y)\n\u001b[1;32m    746\u001b[0m     op, op_class, lhs, rhs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_transform_eq_ne(node, lhs, rhs)\n\u001b[1;32m    747\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_evaluate_binop(op, node\u001b[39m.\u001b[39mop, lhs, rhs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:739\u001b[0m, in \u001b[0;36mBaseExprVisitor._try_visit_binop\u001b[0;34m(self, bop)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(bop, (Op, Term)):\n\u001b[1;32m    738\u001b[0m     \u001b[39mreturn\u001b[39;00m bop\n\u001b[0;32m--> 739\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(bop)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:723\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Compare\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m     op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslate_In(ops[\u001b[39m0\u001b[39m])\n\u001b[1;32m    722\u001b[0m     binop \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mBinOp(op\u001b[39m=\u001b[39mop, left\u001b[39m=\u001b[39mnode\u001b[39m.\u001b[39mleft, right\u001b[39m=\u001b[39mcomps[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 723\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(binop)\n\u001b[1;32m    725\u001b[0m \u001b[39m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[1;32m    726\u001b[0m left \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mleft\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:536\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BinOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_BinOp\u001b[39m(\u001b[39mself\u001b[39m, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 536\u001b[0m     op, op_class, left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_transform_eq_ne(node)\n\u001b[1;32m    537\u001b[0m     left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_downcast_constants(left, right)\n\u001b[1;32m    538\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_evaluate_binop(op, op_class, left, right)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:458\u001b[0m, in \u001b[0;36mBaseExprVisitor._maybe_transform_eq_ne\u001b[0;34m(self, node, left, right)\u001b[0m\n\u001b[1;32m    456\u001b[0m     left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mleft, side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m right \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m     right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mright, side\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mright\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    459\u001b[0m op, op_class, left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rewrite_membership_op(node, left, right)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m op, op_class, left, right\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:645\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Attribute\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m ctx \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mctx\n\u001b[1;32m    643\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ctx, ast\u001b[39m.\u001b[39mLoad):\n\u001b[1;32m    644\u001b[0m     \u001b[39m# resolve the value\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m     resolved \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    646\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m         v \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(resolved, attr)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/expr.py:549\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Name\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Name\u001b[39m(\u001b[39mself\u001b[39m, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 549\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mterm_type(node\u001b[39m.\u001b[39;49mid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/ops.py:85\u001b[0m, in \u001b[0;36mTerm.__init__\u001b[0;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[1;32m     83\u001b[0m tname \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(name)\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_local \u001b[39m=\u001b[39m tname\u001b[39m.\u001b[39mstartswith(LOCAL_TAG) \u001b[39mor\u001b[39;00m tname \u001b[39min\u001b[39;00m DEFAULT_GLOBALS\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_name()\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding \u001b[39m=\u001b[39m encoding\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/ops.py:109\u001b[0m, in \u001b[0;36mTerm._resolve_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m local_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mscope \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mscope[local_name], \u001b[39mtype\u001b[39m\n\u001b[1;32m    106\u001b[0m ):\n\u001b[1;32m    107\u001b[0m     is_local \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mresolve(local_name, is_local\u001b[39m=\u001b[39;49mis_local)\n\u001b[1;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(res)\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(res, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m res\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m/venv/lib/python3.10/site-packages/pandas/core/computation/scope.py:211\u001b[0m, in \u001b[0;36mScope.resolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemps[key]\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m UndefinedVariableError(key, is_local) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mUndefinedVariableError\u001b[0m: name 'contest_type' is not defined"
     ]
    }
   ],
   "source": [
    "TOP_SCORE_CACHE_MODE: TopScoreCacheMode = 'default'\n",
    "# set of tuples of (sport, service) that will only warn on a screen lineup constraint violation\n",
    "WARN_ON_SCREEN_LINEUP_CONSTRAINTS_ERR: set[tuple[str, str]] = {\n",
    "    (\"mlb\", \"fanduel\")\n",
    "}\n",
    "SPORTS = SPORT_CFGS\n",
    "\n",
    "for sport in SPORTS:\n",
    "    cfg_min_date = SPORT_CFGS[sport]['min_date']\n",
    "    cfg_max_date = SPORT_CFGS[sport]['max_date']\n",
    "    for service in SPORT_CFGS[sport].get('services', SERVICES):\n",
    "        min_date = cfg_min_date.get(service, cfg_min_date.get(None)) \\\n",
    "            if isinstance(cfg_min_date, dict) else cfg_min_date\n",
    "        max_date = cfg_max_date.get(service, cfg_max_date.get(None)) \\\n",
    "            if isinstance(cfg_max_date, dict) else cfg_max_date\n",
    "        for style in STYLES:\n",
    "            for contest_type in CONTEST_TYPES:\n",
    "                print(\n",
    "                    f\"Processing {sport}, {service}, {style}, {contest_type.NAME}\")\n",
    "                try:\n",
    "                    slcm = \"warn\" \\\n",
    "                        if (sport, service) in WARN_ON_SCREEN_LINEUP_CONSTRAINTS_ERR else \\\n",
    "                        \"fail\"\n",
    "                    df = generate_dataset(\n",
    "                        sport, SPORT_CFGS[sport], service, style, contest_type,\n",
    "                        min_date=min_date, max_date=max_date,\n",
    "                        top_score_cache_mode=TOP_SCORE_CACHE_MODE,\n",
    "                        screen_lineup_constraints_mode=slcm,\n",
    "                    )\n",
    "                    with pd.option_context('display.max_rows', 1000, 'display.max_columns', 100):\n",
    "                        display(df)\n",
    "                except ValueError as ex:\n",
    "                    failure = ex\n",
    "                    print(\n",
    "                        f\"********************* Error for {sport}, {service}, {style}, {contest_type.NAME}: {ex}\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "006d5deb8e6cdcd4312641bdf15f3bc20f0769a7305d81173599a7b40f33b4a2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

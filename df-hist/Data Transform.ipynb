{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8036a1-f812-4cbb-ba69-8132f15b2ca4",
   "metadata": {},
   "source": [
    "# This notebook creates a dataset for min/max winning scores\n",
    "## Prep\n",
    "- Ensure that database filenames and dates in SPORT_CFG are correct and that the files exist in $FANTASY_HOME\n",
    "- For LOL make sure that cost csv files in $FANTASY_LINEUP_CACHE_DIR\n",
    "\n",
    "## Data will include\n",
    "- min win df score\n",
    "- max win df score\n",
    "- median team score (real game scores)\n",
    "- 75th percentile team score (real game scores)\n",
    "- number of slate games\n",
    "- median df score for each player position\n",
    "- 75th percentile df score for each player position\n",
    "- median df score of top 50% of players for each position over the previous W weeks\n",
    "- 75th percentile df score of top 50% for each position over the previous W weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all daily fantasy contest data\n",
    "from datetime import date\n",
    "from functools import partial\n",
    "import re\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from fantasy_py import ContestStyle\n",
    "from fantasy_py.lineup.strategy import GeneralPrizePool, FiftyFifty, Contest\n",
    "\n",
    "from best_possible_lineup_score import get_stat_names\n",
    "\n",
    "\n",
    "FANTASY_HOME = os.environ['FANTASY_HOME']\n",
    "CONTEST_DATA_PATH = os.path.join(os.environ['FANTASY_ARCHIVE_BASE'], \"betting\")\n",
    "\n",
    "# the datasets to generate, dict mapping sport to dict with keys sport, min_date, max_date, historic data filename\n",
    "SPORT_CFGS = {\n",
    "    'mlb': {\n",
    "        'min_date': date(2019, 1, 1),\n",
    "        'max_date': date(2021, 1, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"mlb_hist_20082021.scored.db\"),\n",
    "        'cost_pos_drop': {'DH', 'RP'},\n",
    "        'cost_pos_rename': {'SP': 'P'},\n",
    "    },\n",
    "    'nfl': {\n",
    "        'min_date': date(2020, 8, 1),\n",
    "        'max_date': date(2021, 1, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"nfl_hist_2009-2020.scored.db\"),\n",
    "    },\n",
    "    'nba': {\n",
    "        'min_date': {None: date(2019, 8, 1), 'yahoo': date(2020, 8, 1)},\n",
    "        'max_date': date(2021, 8, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"nba_hist_20082009-20202021.scored.db\"),\n",
    "    },\n",
    "    'nhl': {\n",
    "        'min_date': {'draftkings': date(2019, 10, 9),   # dk changed scoring formula for nhl\n",
    "                     None: date(2017, 8, 1)},\n",
    "        'max_date': date(2021, 4, 1),\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"nhl_hist_20072008-20192020.scored.db\"),\n",
    "        'cost_pos_rename': {'LW': 'W', 'RW': 'W'},\n",
    "    },\n",
    "    'lol': {\n",
    "        'db_filename': os.path.join(FANTASY_HOME, \"lol_hist_2014-2021.scored.db\"),\n",
    "        'min_date': date(2020, 1, 1),\n",
    "        'max_date': date(2021, 1, 1),\n",
    "        'services': ['draftkings', 'fanduel'],\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# days to use to identify top players going into a slate\n",
    "TOP_PLAYER_DAYS = 21\n",
    "# players above this percentil over the last TOP_PLAYER_DAYS are considered top players\n",
    "TOP_PLAYER_PERCENTILE = .70\n",
    "\n",
    "\n",
    "# fanduel/draftkings/yahoo\n",
    "SERVICES = [\n",
    "    'draftkings',\n",
    "    'fanduel',\n",
    "    'yahoo',\n",
    "]\n",
    "\n",
    "STYLES: list[str] = [\n",
    "    ContestStyle.CLASSIC,\n",
    "    ContestStyle.SHOWDOWN,\n",
    "]\n",
    "\n",
    "CONTEST_TYPES: list[Contest] = [\n",
    "    FiftyFifty,\n",
    "    GeneralPrizePool,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fba26-4d6a-4f02-b988-bc7ca0f93f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_contest_style(service, title) -> ContestStyle:\n",
    "    if service == 'draftkings':\n",
    "        if ('Showdown' in title or\n",
    "                re.match('.*.{2,3} vs .{2,3}\\)', title)):\n",
    "            return ContestStyle.SHOWDOWN\n",
    "        return ContestStyle.CLASSIC\n",
    "    if service == 'fanduel':\n",
    "        if '@' in (title or ''):\n",
    "            return ContestStyle.SHOWDOWN\n",
    "        return ContestStyle.CLASSIC\n",
    "    if service == 'yahoo':\n",
    "        if (' Cup ' in title or\n",
    "            ' to 1st]' in title or\n",
    "            ' 50/50' in title or\n",
    "            'QuickMatch vs ' in title or\n",
    "            'H2H vs ' in title or\n",
    "            '-Team' in title or   # N-team contests are classic\n",
    "            'Freeroll' in title or\n",
    "            'Quadruple Up' in title or\n",
    "                'Guaranteed' in title):\n",
    "            return ContestStyle.CLASSIC\n",
    "    raise NotImplementedError(\n",
    "        f\"Could not infer contest style for {service=} {title=}\")\n",
    "\n",
    "\n",
    "def infer_contest_type(service, title) -> str:\n",
    "    if service == 'draftkings':\n",
    "        if re.match('.* vs\\. [^)]+$', title):\n",
    "            return 'H2H'\n",
    "        return FiftyFifty.NAME if 'Double Up' in title else GeneralPrizePool.NAME\n",
    "    if service == 'fanduel':\n",
    "        if 'Head-to-head' in (title or ''):\n",
    "            return 'H2H'\n",
    "        if (title or '').startswith('50/50'):\n",
    "            return FiftyFifty.NAME\n",
    "        return GeneralPrizePool.NAME\n",
    "    if service == 'yahoo':\n",
    "        if (' QuickMatch vs ' in title or\n",
    "                'H2H vs ' in title):\n",
    "            return 'H2H'\n",
    "        if ' 50/50' in title:\n",
    "            return FiftyFifty.NAME\n",
    "        if (' Cup ' in title or\n",
    "            ' to 1st]' in title or\n",
    "            'Freeroll' in title or\n",
    "            'Quadruple Up' in title or\n",
    "            # multi-team games are GPP if not caught by 50/50\n",
    "            '-Team' in title or\n",
    "            # treat winner takes all like a gpp\n",
    "            title.endswith('Team Winner Takes All') or\n",
    "                'Guaranteed' in title):\n",
    "            return GeneralPrizePool.NAME\n",
    "    raise NotImplementedError(\n",
    "        f\"Could not infer contest type for {service=} {title=}\")\n",
    "\n",
    "\n",
    "def add_bet_links(service, contest_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_contest_df(service, sport, style, contest_type, min_date, max_date) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    create a dataframe from the contest dataset\n",
    "    \"\"\"\n",
    "    contest_csv_path = os.path.join(\n",
    "        CONTEST_DATA_PATH, service + \".contest.csv\")\n",
    "    contest_df = pd.read_csv(contest_csv_path, parse_dates=['date']) \\\n",
    "                   .query('sport == @sport and @min_date <= date < @max_date')[['contest_id', 'date', 'title', 'top_score', 'last_winning_score', 'entries']]\n",
    "    contest_df.date = contest_df.date.dt.normalize()\n",
    "    contest_df = contest_df.where(contest_df.notnull(), None)\n",
    "\n",
    "    # add style and type\n",
    "    #     with pd.option_context('max_rows', 1000, 'max_colwidth', 100):\n",
    "    #         display(contest_df)\n",
    "    contest_df['style'] = contest_df.title.map(\n",
    "        partial(infer_contest_style, service)\n",
    "    )\n",
    "    contest_df['type'] = contest_df.title.map(\n",
    "        partial(infer_contest_type, service)\n",
    "    )\n",
    "    queries = []\n",
    "    if style is not None:\n",
    "        # print(f\"Filtering for {style=}\")\n",
    "        queries.append('style == @style')\n",
    "    if contest_type is not None:\n",
    "        # print(f\"Filtering for {contest_type=}\")\n",
    "        queries.append('type == @contest_type.NAME')\n",
    "    if len(queries) > 0:\n",
    "        contest_df = contest_df.query(' and '.join(queries))\n",
    "\n",
    "    betting_csv_path = os.path.join(\n",
    "        CONTEST_DATA_PATH, \n",
    "        service + \".betting.csv\"\n",
    "    )\n",
    "    bet_df = pd.read_csv(betting_csv_path) \\\n",
    "               .drop_duplicates('contest_id') \\\n",
    "               .set_index('contest_id')[['link']]\n",
    "    contest_df = contest_df.merge(bet_df, how='left', on='contest_id')\n",
    "    return contest_df\n",
    "\n",
    "\n",
    "# contest_df = get_contest_df(\"draftkings\", \"nhl\", ContestStyle.CLASSIC, FiftyFifty, date(2019, 1, 1), date(2020, 1, 1))\n",
    "# with pd.option_context('max_rows', 1000, 'max_columns', 100, 'max_colwidth', 99999):\n",
    "#    display(contest_df.sort_values(['style', 'type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41b142-0915-4b2b-85b9-e91effe5f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ABBR = {\n",
    "    'fanduel': 'fd',\n",
    "    'draftkings': 'dk',\n",
    "    'yahoo': 'y'\n",
    "}\n",
    "\n",
    "\n",
    "def get_draft_df(service, sport, style, min_date, max_date) -> pd.DataFrame:\n",
    "    csv_path = os.path.join(CONTEST_DATA_PATH, service + \".draft.csv\")\n",
    "    draft_df = pd.read_csv(csv_path, parse_dates=['date']) \\\n",
    "                 .query('sport == @sport and @min_date <= date < @max_date')\n",
    "    assert len(draft_df) > 0, \\\n",
    "        f\"no draft data found for {sport=}, {service=}, {style=}, {min_date=}, {max_date=}\"\n",
    "\n",
    "    draft_df['service'] = draft_df.contest.map(\n",
    "        lambda contest: contest.split('-', 1)[0])\n",
    "    draft_df.team_abbr = draft_df.team_abbr.str.upper()\n",
    "    service_abbr = SERVICE_ABBR[service]\n",
    "    draft_df = draft_df.query('service == @service_abbr and team_abbr.notnull()')[\n",
    "        ['position', 'name', 'team_abbr', 'contest_id']]\n",
    "\n",
    "    return draft_df\n",
    "\n",
    "\n",
    "# draft_df = get_draft_df(SERVICE, SPORT, STYLE, MIN_DATE, MAX_DATE)\n",
    "# display(draft_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119b90b-0d6a-453d-9c1f-16f9c934153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fantasy_py import FANTASY_SERVICE_DOMAIN, util\n",
    "\n",
    "\n",
    "def create_team_contest_df(contest_df, draft_df, service, sport):\n",
    "    service_cls = util.CLSRegistry.get_class(FANTASY_SERVICE_DOMAIN, service)\n",
    "    abbr_remaps = service_cls.get_team_abbr_remapping(sport)\n",
    "\n",
    "    # add team/lineup draft data\n",
    "    team_contest_df = pd.merge(contest_df, draft_df, on='contest_id')\n",
    "    team_contest_df.team_abbr = team_contest_df.team_abbr.map(\n",
    "        lambda abbr: abbr_remaps.get(abbr) or abbr\n",
    "    )\n",
    "\n",
    "    return team_contest_df\n",
    "\n",
    "\n",
    "# team_contest_df = create_team_contest_df(contest_df, draft_df, SERVICE, SPORT)\n",
    "# print(f\"{len(team_contest_df.contest_id.unique())} contests\")\n",
    "# display(team_contest_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23642274-6159-44e4-ae93-29e5aea104ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def common_title(title_series: pd.Series) -> str:\n",
    "    \"\"\" the title of a contest will be the common prefix amongst all the possible contest titles \"\"\"\n",
    "    title_list = title_series.tolist()\n",
    "    if None in title_list:\n",
    "        return \"\"\n",
    "    return os.path.commonprefix(title_list)\n",
    "\n",
    "\n",
    "def create_teams_contest_df(tc_df):\n",
    "    \"\"\" group contests together and create team sets used in each contest \"\"\"\n",
    "    tc_df = pd.DataFrame(\n",
    "        tc_df.groupby(\n",
    "            ['contest_id', 'date', 'style', 'type', 'link', 'entries']\n",
    "        ).agg(\n",
    "            {'team_abbr': set,\n",
    "             'title': common_title,\n",
    "             'top_score': lambda score: score.mean(),\n",
    "             'last_winning_score': lambda score: score.mean()}\n",
    "        )\n",
    "    ).reset_index()\n",
    "    tc_df = tc_df.rename(columns={'team_abbr': 'teams'})\n",
    "    tc_df['draft_team_count'] = tc_df.teams.map(len)\n",
    "    return tc_df\n",
    "\n",
    "\n",
    "# teams_contest_df = create_teams_contest_df(team_contest_df)\n",
    "# display(f\"{len(teams_contest_df)} team sets\")\n",
    "# display(teams_contest_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3d846-dec9-4f92-bf99-0b1534b9d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load slate data from db\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_slate_df(db_filename, service, style, min_date, max_date) -> Optional[pd.DataFrame]:\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    sql = f\"\"\"\n",
    "    select distinct daily_fantasy_slate.id as slate_id, date, \n",
    "        daily_fantasy_slate.name as slate_name, style as contest_style, abbr\n",
    "    from daily_fantasy_slate \n",
    "        join daily_fantasy_cost on daily_fantasy_slate.id = daily_fantasy_cost.daily_fantasy_slate_id\n",
    "        join team on team_id = team.id\n",
    "    where service = '{service}' and date between '{min_date}' and date('{max_date}', '-1 days')\n",
    "    \"\"\"\n",
    "\n",
    "    if style is not None:\n",
    "        sql += f\" and style = '{style.name}'\"\n",
    "\n",
    "    # print(sql)\n",
    "    db_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    # with pd.option_context('max_rows', 100):\n",
    "    #     display(db_df)\n",
    "    conn.close()\n",
    "    if len(db_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # get team sets\n",
    "    slate_db_df = pd.DataFrame(\n",
    "        db_df.groupby(\n",
    "            ['slate_id', 'date', 'slate_name', 'contest_style']\n",
    "        ).agg(\n",
    "            {'abbr': set}\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    try:\n",
    "        slate_db_df = slate_db_df.set_index('date') \\\n",
    "                                 .rename(columns={'abbr': 'teams'})\n",
    "    except Exception as ex:\n",
    "        raise ValueError(\"Error processing slate db df\", slate_db_df) from ex\n",
    "\n",
    "    slate_db_df['team_count'] = slate_db_df.teams.map(len)\n",
    "    return slate_db_df\n",
    "\n",
    "\n",
    "# slate_db_df = get_slate_df(DB_FILENAME, SERVICE, STYLE, MIN_DATE, MAX_DATE)\n",
    "# with pd.option_context('max_rows', 100):\n",
    "#     display(slate_db_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e21f0-df36-41a9-9417-253ea5d800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "NO_SLATE_ID_FOUND = pd.Series({'slate_id': None, 'team_count': None})\n",
    "\n",
    "def get_slate_id(contest_row, slate_db_df) -> pd.Series:\n",
    "    \"\"\" \n",
    "    guesses the db slate id contest_row\n",
    "    returns - series of (slate_id, number of teams playing in slate)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_slates = slate_db_df.loc[[\n",
    "            contest_row.date]].sort_values('team_count')\n",
    "    except KeyError as ke:\n",
    "        print(f\"get_slate_id:: Key error/No slates found for {contest_row.date}\")\n",
    "        return NO_SLATE_ID_FOUND\n",
    "    try:\n",
    "        slates = date_slates.query(\"@contest_row.teams <= teams\")\n",
    "    except Exception as e:\n",
    "        print(f\"get_slate_id:: Unhandled exception querying for teams date {contest_row.date}: {e}\")\n",
    "        return NO_SLATE_ID_FOUND\n",
    "\n",
    "    slates_found = len(slates)\n",
    "    if slates_found == 0:\n",
    "        with pd.option_context('display.max_colwidth', 100):\n",
    "            display(f\"No slates found for {contest_row.date} that matches teams {contest_row.teams}. date_slates_df=\",\n",
    "                    date_slates)\n",
    "        return NO_SLATE_ID_FOUND\n",
    "\n",
    "    return slates.iloc[0][['slate_id', 'team_count']]\n",
    "\n",
    "# slate_ids_df = teams_contest_df.apply(get_slate_id, axis=1)\n",
    "# display(slate_ids_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1781066-a71e-4332-8864-c2b5339434db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slate game score info\n",
    "\n",
    "def create_team_score_df(db_filename, slate_ids_str, top_player_percentile) -> Optional[pd.DataFrame]:\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    sql = f\"\"\"\n",
    "    select distinct daily_fantasy_slate.id as slate_id, game.id as game_id, \n",
    "           game.score_home, game.score_away\n",
    "    from daily_fantasy_slate\n",
    "        join daily_fantasy_cost on daily_fantasy_slate.id = daily_fantasy_cost.daily_fantasy_slate_id\n",
    "        join game on ((game.date = daily_fantasy_slate.date or \n",
    "\t\t               game.dt between daily_fantasy_slate.date and datetime(daily_fantasy_slate.date, '+1 days', '+6 hours')) and\n",
    "                      game.season = daily_fantasy_slate.season and \n",
    "                      (daily_fantasy_cost.team_id in (game.away_team_id, game.home_team_id)))\n",
    "    where daily_fantasy_slate.id in ({slate_ids_str})\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"team score sql\\n\", sql)\n",
    "    db_team_score_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    conn.close()\n",
    "    # display(\"team score df\", db_team_score_df)\n",
    "    if len(db_team_score_df) == 0:\n",
    "        return None\n",
    "\n",
    "    team_score_df = db_team_score_df.melt(id_vars=['slate_id', 'game_id'], value_vars=['score_home', 'score_away']) \\\n",
    "        .groupby(['slate_id']) \\\n",
    "        .agg({'value': ['median', lambda x: np.percentile(x, top_player_percentile * 100)]})\n",
    "    team_score_df.columns = ['team-med',\n",
    "                             f'team-{top_player_percentile * 100}th_pctl']\n",
    "    return team_score_df\n",
    "\n",
    "\n",
    "# for mlb double headers this will cause inaccuracy for players that played in both games\n",
    "# slate_ids_str = ','.join(map(str, slate_ids_df.slate_id.dropna()))\n",
    "# team_score_df = create_team_score_df(DB_FILENAME, slate_ids_str, TOP_PLAYER_PERCENTILE)\n",
    "# display(team_score_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0644384-abe0-421d-aaae-7479cc227f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get position scores\n",
    "\n",
    "def get_exploded_pos_df(db_filename, sport, service_abbr, slate_ids_str,\n",
    "                        cost_pos_drop: Optional[set], cost_pos_rename: Optional[dict]) -> Optional[pd.DataFrame]:\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    stat_names = get_stat_names(sport, service_abbr, as_str=True)\n",
    "\n",
    "    # for mlb double headers this query will cause inaccuracy for players that played in both games\n",
    "    # games have a date equal to the slate date or must have a datetime starting prior to 6am on the following date\n",
    "    sql = f\"\"\"\n",
    "    select daily_fantasy_slate.id as slate_id, positions as cost_positions, \n",
    "        player_position.abbr as stat_position, \n",
    "        value as score, daily_fantasy_cost.team_id, daily_fantasy_cost.player_id\n",
    "    from daily_fantasy_slate\n",
    "        join daily_fantasy_cost on \n",
    "           daily_fantasy_slate.id = daily_fantasy_cost.daily_fantasy_slate_id\n",
    "        join game on (\n",
    "           (game.date = daily_fantasy_slate.date or \n",
    "\t\t    game.dt between daily_fantasy_slate.date and datetime(daily_fantasy_slate.date, '+1 days', '+6 hours')) and\n",
    "           game.season = daily_fantasy_slate.season and \n",
    "           (daily_fantasy_cost.team_id in (game.away_team_id, game.home_team_id))\n",
    "        )\n",
    "        join calculation_datum on (\n",
    "            calculation_datum.game_id = game.id and \n",
    "            calculation_datum.player_id is daily_fantasy_cost.player_id and\n",
    "            calculation_datum.team_id = daily_fantasy_cost.team_id\n",
    "        )\n",
    "        join statistic on calculation_datum.statistic_id = statistic.id\n",
    "        join player on daily_fantasy_cost.player_id = player.id\n",
    "        join player_position on player.player_position_id = player_position.id\n",
    "    where daily_fantasy_slate.id in ({slate_ids_str}) and\n",
    "        statistic.name in ({stat_names})\n",
    "    \"\"\"\n",
    "    # print(\"Exploded POS data:\\n\", sql)\n",
    "\n",
    "    db_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    conn.close()\n",
    "\n",
    "    if len(db_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # TODO: only need to test for 'Unknown' so long as it is still stored in DB as a cost position value\n",
    "    def apply_func(row): \n",
    "        return row.stat_position if row.cost_positions is None else row.cost_positions\n",
    "    db_df['position'] = db_df.apply(\n",
    "        apply_func,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    db_exploded_pos_df = db_df.assign(position=db_df.position.str.split('/')) \\\n",
    "                              .explode('position')\n",
    "\n",
    "    if cost_pos_drop is not None:\n",
    "        db_exploded_pos_df = db_exploded_pos_df.query(\n",
    "            'position not in @cost_pos_drop')\n",
    "    if cost_pos_rename is not None:\n",
    "        for old_pos, new_pos in cost_pos_rename.items():\n",
    "            db_exploded_pos_df.loc[db_exploded_pos_df.position ==\n",
    "                                   old_pos, 'position'] = new_pos\n",
    "    return db_exploded_pos_df\n",
    "\n",
    "\n",
    "def get_position_scores(db_exploded_pos_df, top_player_percentile):\n",
    "    db_pos_scores_df = db_exploded_pos_df[['slate_id', 'position', 'score']] \\\n",
    "        .groupby(['slate_id', 'position']) \\\n",
    "        .agg(['median', lambda x: np.percentile(x, top_player_percentile * 100)])\n",
    "    db_pos_scores_df.columns = ['med-dfs',\n",
    "                                f'{top_player_percentile * 100}th-pctl-dfs']\n",
    "    db_pos_scores_df = db_pos_scores_df.reset_index(level='position') \\\n",
    "        .pivot(columns='position', values=['med-dfs', f'{top_player_percentile * 100}th-pctl-dfs'])\n",
    "    return db_pos_scores_df\n",
    "\n",
    "\n",
    "# SPORT = 'lol'\n",
    "# SERVICE = 'draftkings'\n",
    "\n",
    "# db_exploded_pos_df = get_exploded_pos_df(DB_FILENAME, SPORT, SERVICE_ABBR[SERVICE], slate_ids_str)\n",
    "# display(db_exploded_pos_df)\n",
    "# db_pos_scores_df = get_position_scores(db_exploded_pos_df, TOP_PLAYER_PERCENTILE)\n",
    "# display(db_pos_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651cfb6-f6ec-4df3-816f-fa69c680aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_scores(db_filename, db_exploded_pos_df,\n",
    "                      sport, service_abbr, top_player_days, min_date, max_date):\n",
    "    \"\"\" Get top player scores (e.g. players that are likely to be highly drafted) \"\"\"\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "    stat_names = get_stat_names(sport, service_abbr, as_str=True)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    select game.date, calculation_datum.player_id, calculation_datum.team_id, calculation_datum.value as score \n",
    "    from game\n",
    "        join calculation_datum on calculation_datum.game_id = game.id\n",
    "        join statistic on calculation_datum.statistic_id = statistic.id\n",
    "    where statistic.name in ({stat_names}) \n",
    "        and date between date('{min_date}', '-{top_player_days} days') and date('{max_date}', '-1 days')\n",
    "    \"\"\"\n",
    "    # print(sql)\n",
    "    db_df = pd.read_sql_query(sql, conn, parse_dates=['date'])\n",
    "    conn.close()\n",
    "    # display(db_df)\n",
    "\n",
    "    db_filtered_df = db_df.query(\n",
    "        '(player_id in @db_exploded_pos_df.player_id) '\n",
    "        'or (player_id.isnull() and team_id in @db_exploded_pos_df.team_id)'\n",
    "    )\n",
    "    return db_filtered_df\n",
    "\n",
    "\n",
    "# db_filtered_df = get_player_scores(DB_FILENAME, SPORT, SERVICE_ABBR[SERVICE], TOP_PLAYER_DAYS, MIN_DATE, MAX_DATE)\n",
    "# display(db_filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba062b9-2e3c-49aa-a2a8-af4bf313cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_df(teams_contest_df, slate_ids_df, team_score_df, db_pos_scores_df, top_lineup_scores) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    join contest, slate id, team score and player position scores\n",
    "    \"\"\"\n",
    "\n",
    "    dfs = [\n",
    "        teams_contest_df[['date', 'style', 'type',\n",
    "                          'top_score', 'last_winning_score', 'link']],\n",
    "        top_lineup_scores,\n",
    "        slate_ids_df,\n",
    "    ]\n",
    "    predict_df = pd.concat(dfs, axis='columns') \\\n",
    "                   .join(team_score_df, on='slate_id') \\\n",
    "                   .join(db_pos_scores_df, on='slate_id')\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "# predict_df = create_predict_df(teams_contest_df, slate_ids_df, team_score_df, db_pos_scores_df)\n",
    "# with pd.option_context('max_columns', 100):\n",
    "#     display(predict_df)\n",
    "\n",
    "\n",
    "# filename = f\"{SPORT}-{SERVICE}-{STYLE.name}-{CONTEST_TYPE.NAME}.csv\"\n",
    "# print(f\"Writing data to file '{filename}'\")\n",
    "# predict_df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b12c30-f03e-46bb-a79e-8f55d10b21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from best_possible_lineup_score import (\n",
    "    TopScoreCacheMode, best_possible_lineup_score, best_score_cache\n",
    ")\n",
    "\n",
    "\n",
    "def generate_dataset(\n",
    "    sport, cfg, service, style, contest_type,\n",
    "    min_date=None, max_date=None, max_count: Optional[int] = None,\n",
    "    top_score_cache_mode: TopScoreCacheMode = 'default',\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    max_count - maximum number of slates to process\n",
    "    min_date - includsive\n",
    "    max_date - not inclusive\n",
    "    top_score_cache_mode - \n",
    "        'default'=load and use the cache, \n",
    "        'overwrite'=overwrite all existing cache data if any exists\n",
    "        'missing'=use all existing valid cache data, any cached failures will be rerun\n",
    "    \"\"\"\n",
    "    assert (min_date is None) or (max_date is None) or min_date < max_date, \\\n",
    "        \"invalidate date range. max_date must be greater than min_date. Or one must be None\"\n",
    "    filename = f\"{sport}-{service}-{style.name}-{contest_type.NAME}.csv\"\n",
    "    # print(f\"Creating data for file '{filename}'\")\n",
    "\n",
    "    db_filename = cfg['db_filename']\n",
    "    if min_date is None:\n",
    "        min_date = cfg['min_date']\n",
    "    if max_date is None:\n",
    "        max_date = cfg['max_date']\n",
    "\n",
    "    contest_df = get_contest_df(\n",
    "        service, sport, style, contest_type, min_date, max_date)\n",
    "    if contest_df is not None:\n",
    "        contest_df = contest_df.head(max_count)\n",
    "\n",
    "    draft_df = get_draft_df(service, sport, style, min_date, max_date)\n",
    "    # display(draft_df)\n",
    "\n",
    "    team_contest_df = create_team_contest_df(\n",
    "        contest_df, draft_df, service, sport)\n",
    "    # display(f\"{len(team_contest_df.contest_id.unique())} contests\", team_contest_df)\n",
    "\n",
    "    teams_contest_df = create_teams_contest_df(team_contest_df)\n",
    "    # with pd.option_context('display.max_rows', 100, 'display.max_colwidth', None):\n",
    "    #     display(f\"{len(teams_contest_df)} slate team sets in team_contest_df\",\n",
    "    #              teams_contest_df)\n",
    "\n",
    "    slate_db_df = get_slate_df(db_filename, service, style, min_date, max_date)\n",
    "    if slate_db_df is None:\n",
    "        raise ValueError(\"No slates found for\", service,\n",
    "                         style, min_date, max_date)\n",
    "    # with pd.option_context('display.max_rows', 100, 'display.max_colwidth', None):\n",
    "    #     display(\"Slate db df\", slate_db_df)\n",
    "\n",
    "    slate_ids_df = teams_contest_df.apply(\n",
    "        get_slate_id, axis=1, args=(slate_db_df, ))\n",
    "    # display(slate_ids_df)\n",
    "\n",
    "    if len(slate_ids_df) == 0:\n",
    "        raise ValueError(\"No slates ids found (based on teams contest df)\")\n",
    "\n",
    "    try:\n",
    "        # need this for subsequent sql queries\n",
    "        slate_ids_str = ','.join(\n",
    "            map(str, slate_ids_df.slate_id.dropna().astype(int)))\n",
    "    except Exception as ex:\n",
    "        raise ValueError(\"Something wrong with slate_ids_df\",\n",
    "                         slate_ids_df) from ex\n",
    "\n",
    "    if len(slate_ids_str) == 0:\n",
    "        raise ValueError(\"No slate ids found after removing Nones\")\n",
    "    team_score_df = create_team_score_df(\n",
    "        db_filename, slate_ids_str, TOP_PLAYER_PERCENTILE)\n",
    "    if team_score_df is None:\n",
    "        raise ValueError(\"Empty team score df\")\n",
    "    # display(\"team score df\", team_score_df)\n",
    "\n",
    "    db_exploded_pos_df = get_exploded_pos_df(\n",
    "        db_filename, sport, SERVICE_ABBR[service], slate_ids_str,\n",
    "        cfg.get('cost_pos_drop'), cfg.get('cost_pos_rename'),\n",
    "    )\n",
    "\n",
    "    if db_exploded_pos_df is None:\n",
    "        raise ValueError(\"No exploded positional data returned!\")\n",
    "    # display(db_exploded_pos_df)\n",
    "\n",
    "    db_pos_scores_df = get_position_scores(\n",
    "        db_exploded_pos_df, TOP_PLAYER_PERCENTILE)\n",
    "    # display(db_pos_scores_df)\n",
    "\n",
    "    # db_filtered_df = get_player_scores(\n",
    "    #     db_filename, db_exploded_pos_df,\n",
    "    #     sport, SERVICE_ABBR[service], TOP_PLAYER_DAYS, min_date, max_date\n",
    "    # )\n",
    "    # display(db_filtered_df)\n",
    "\n",
    "    # cache for top scores\n",
    "    with best_score_cache(sport, top_score_cache_mode) as top_score_dict:\n",
    "        best_possible_lineup_score_part = partial(best_possible_lineup_score,\n",
    "                                                  db_filename,\n",
    "                                                  SERVICE_ABBR[service],\n",
    "                                                  sport=sport,\n",
    "                                                  best_score_cache=top_score_dict)\n",
    "\n",
    "        top_lineup_scores = slate_ids_df.slate_id.map(\n",
    "            best_possible_lineup_score_part\n",
    "        )\n",
    "\n",
    "    top_lineup_scores.name = 'best-possible-score'\n",
    "    predict_df = create_predict_df(\n",
    "        teams_contest_df, slate_ids_df, team_score_df, db_pos_scores_df, top_lineup_scores)\n",
    "    # with pd.option_context('max_columns', 100):\n",
    "    #     display(\"predict df\", predict_df)\n",
    "\n",
    "    filename = f\"{sport}-{service}-{style.name}-{contest_type.NAME}.csv\"\n",
    "    print(f\"Writing data to file '{filename}'\")\n",
    "    predict_df.to_csv(filename, index=False)\n",
    "    return predict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a965c2-3f9a-4e8c-8770-35b707456d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_SCORE_CACHE_MODE: TopScoreCacheMode = 'default'\n",
    "\n",
    "for sport in SPORT_CFGS:\n",
    "    cfg_min_date = SPORT_CFGS[sport]['min_date']\n",
    "    cfg_max_date = SPORT_CFGS[sport]['max_date']\n",
    "    for service in SPORT_CFGS[sport].get('services', SERVICES):\n",
    "        min_date = cfg_min_date.get(service, cfg_min_date.get(None)) \\\n",
    "            if isinstance(cfg_min_date, dict) else cfg_min_date\n",
    "        max_date = cfg_max_date.get(service, cfg_max_date.get(None)) \\\n",
    "            if isinstance(cfg_max_date, dict) else cfg_max_date\n",
    "        for style in STYLES:\n",
    "            for contest_type in CONTEST_TYPES:\n",
    "                print(\n",
    "                    f\"Processing {sport}, {service}, {style}, {contest_type.NAME}\")\n",
    "                try:\n",
    "                    df = generate_dataset(sport, SPORT_CFGS[sport], service, style, contest_type,\n",
    "                                          min_date=min_date, max_date=max_date,\n",
    "                                          top_score_cache_mode=TOP_SCORE_CACHE_MODE)\n",
    "                    with pd.option_context('display.max_rows', 1000, 'display.max_columns', 100):\n",
    "                        display(df)\n",
    "                except ValueError as ex:\n",
    "                    failure = ex\n",
    "                    print(\n",
    "                        f\"********************* Error for {sport}, {service}, {style}, {contest_type.NAME}: {ex}\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "006d5deb8e6cdcd4312641bdf15f3bc20f0769a7305d81173599a7b40f33b4a2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

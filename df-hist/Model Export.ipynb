{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582d980a-dbab-46e8-a1e4-b52d005c9f4d",
   "metadata": {},
   "source": [
    "# Serialize/export models to ONNX\n",
    "Read the contents of results.txt and serialize all the top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f80e63-4f7b-4b54-bb3d-933559f86769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from serialize import SerializeFailure, COL_SEP\n",
    "\n",
    "\n",
    "ONNX_FAILS: list[SerializeFailure] = []\n",
    "\n",
    "# load the results\n",
    "df = pd.read_csv(\n",
    "    \"results.tsv\", \n",
    "    index_col=False, \n",
    "    sep=COL_SEP,\n",
    "    usecols=['Sport', 'Service', 'Style', 'Type', 'y', 'ModelType', 'R2', 'Date', 'Params'],\n",
    ")\n",
    "\n",
    "# drop everything after the seperator\n",
    "seperator_idx = np.where(df['Sport'].str.startswith('*'))[0][0]\n",
    "df = df.iloc[:seperator_idx]\n",
    "\n",
    "# df = df.query('ModelType == \"tpot\"')\n",
    "\n",
    "with pd.option_context('display.max_rows', 1000, 'display.max_colwidth', 1000):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b6f65-a306-4b5b-81bf-f56983e25089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from fantasy_py import ContestStyle, CLSRegistry, CONTEST_DOMAIN, lineup\n",
    "\n",
    "from automl import create_automl_model, error_report\n",
    "from serialize import serialize_model, SerializeFailure, SUPPORTED_EXPORT_MODELS\n",
    "from generate_train_test import generate_train_test, load_csv\n",
    "\n",
    "\n",
    "DEFAULT_PCA_COMPONENTS = 5\n",
    "\n",
    "\n",
    "def train_export(\n",
    "    sport, service, style: ContestStyle,\n",
    "    contest_type: str, model_type: str,\n",
    "    y_type,\n",
    "    model_def_: dict,\n",
    "    skip_fit=False,\n",
    "    datapath=\".\",\n",
    "    modelpath=\".\",\n",
    "    overwrite=True,\n",
    "):\n",
    "    if not os.path.isdir(modelpath):\n",
    "        print(f\"Creating model path '{modelpath}'\")\n",
    "        os.makedirs(modelpath)\n",
    "\n",
    "    contest_style = ContestStyle[style.upper()]\n",
    "    full_model_name = f'{sport}_{service}_{contest_style}_{contest_type}_{model_type}_{y_type}'\n",
    "    model_filepath = os.path.join(modelpath, full_model_name + \".onnx\")\n",
    "\n",
    "    if os.path.isfile(model_filepath) and not overwrite:\n",
    "        print(f\"Model '{model_filepath}' already exists, skipping\")\n",
    "        return\n",
    "    print(f\"Exporting model to '{model_filepath=}'\")\n",
    "\n",
    "    contest_type_cls = CLSRegistry.get_class(CONTEST_DOMAIN, contest_type)\n",
    "    data_df = load_csv(sport, service, contest_style,\n",
    "                       contest_type_cls, data_folder=datapath)\n",
    "    assert len(data_df) > 0, \"CSV load returned no data\"\n",
    "\n",
    "    model_def = dict(model_def_)\n",
    "    random_state = model_def.pop(\"random_state\", None)\n",
    "    model_cols = model_def.pop(\n",
    "        'model_cols'\n",
    "    ) if 'model_cols' in model_def else None\n",
    "    train_test_data = generate_train_test(\n",
    "        data_df,\n",
    "        model_cols=model_cols,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    if train_test_data is None:\n",
    "        display(\"Failed to generate a train/test data set from...\", data_df)\n",
    "    (X_train, X_test, y_top_train, y_top_test,\n",
    "     y_last_win_train, y_last_win_test) = train_test_data\n",
    "\n",
    "    create_model_params = {\n",
    "        'random_state': random_state,\n",
    "    }\n",
    "    if model_type.endswith('-pca'):\n",
    "        create_model_params['pca_components'] = (\n",
    "            model_def.pop('n_components')\n",
    "            if 'n_components' in model_def else\n",
    "            DEFAULT_PCA_COMPONENTS\n",
    "        )\n",
    "\n",
    "    if model_type.startswith('skautoml'):\n",
    "        create_model_params.update({\n",
    "            'framework': 'skautoml',\n",
    "        })\n",
    "    elif model_type.startswith('tpot'):\n",
    "        create_model_params = {\n",
    "            'framework': 'tpot',\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Don't know how to process model type {model_type}\")\n",
    "\n",
    "    if y_type == 'top':\n",
    "        y_train = y_top_train\n",
    "        y_test = y_top_test\n",
    "    elif y_type == 'last':\n",
    "        y_train = y_last_win_train\n",
    "        y_test = y_last_win_test\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected y of {y_type}\")\n",
    "\n",
    "    # add all remaining\n",
    "    create_model_params.update(model_def)\n",
    "    model, fit_params = create_automl_model(\n",
    "        full_model_name,\n",
    "        **create_model_params,\n",
    "    )\n",
    "    if skip_fit:\n",
    "        print(\"Skipping fit...\")\n",
    "        return\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train, **fit_params)\n",
    "    error_report(model, X_test, y_test,\n",
    "                 f\"{full_model_name}: model_cols={model_def.get('model_cols')}\")\n",
    "    serialize_model(model, model_type, X_train, y_train,\n",
    "                    full_model_name, model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "OVERWRITE = False\n",
    "# skip fit and serialize... dryrun\n",
    "DRYRUN = False\n",
    "\n",
    "PARAM_OVERRIDES = {\n",
    "    # 'generations': 10, \n",
    "    # 'early_stop': 1, \n",
    "    # 'max_train_time': 60\n",
    "}\n",
    "\n",
    "pbar = tqdm(df.iterrows(), total=len(df))\n",
    "for _, row in pbar:\n",
    "    model_desc = f\"sport={row.Sport} service={row.Service} style={row.Style} type={row.Type} y={row.y}\"\n",
    "    pbar.set_postfix_str(model_desc)\n",
    "    if row.ModelType not in SUPPORTED_EXPORT_MODELS:\n",
    "        display(\n",
    "            f\"Failed to train+export model of type {row.ModelType=}. Export of this type is not supported.\"\n",
    "        )\n",
    "        continue\n",
    "    \n",
    "    if pd.isna(row.ModelType):\n",
    "        print(\n",
    "            f\"Skipping row with no model type... {model_desc}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model_def: dict = ast.literal_eval(row.Params)\n",
    "    except Exception:\n",
    "        print(\"Failed to parse params\", row.Params)\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        model_def.update(PARAM_OVERRIDES)\n",
    "        train_export(row.Sport, row.Service, row.Style,\n",
    "                     row.Type, row.ModelType, row.y,\n",
    "                     model_def, \n",
    "                     skip_fit=DRYRUN, overwrite=OVERWRITE,\n",
    "                     datapath=\"data\", modelpath=\"models\")\n",
    "    except SerializeFailure as se:\n",
    "        ONNX_FAILS.append(se)\n",
    "        display(\n",
    "            f\"Failed to serialize: {model_desc} {row.ModelType=} {row.Params=}\"\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        display(\n",
    "            f\"Failed to train+export: {model_desc} {row.ModelType=} {row.Params=}\"\n",
    "        )\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f06308",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ONNX_FAILS):\n",
    "    try:\n",
    "        print(\"###### attempting to serialize last failed model!!! ####\")\n",
    "        serialize_model(\n",
    "            ONNX_FAILS[-1]['model'],\n",
    "            'tpot',\n",
    "            ONNX_FAILS[-1]['X'],\n",
    "            ONNX_FAILS[-1]['y'],\n",
    "            ONNX_FAILS[-1]['name']\n",
    "        )\n",
    "        print(\"#### serialization successful! ###\")\n",
    "    except Exception as ex:\n",
    "        print(\"#### serializeation failed!!!\", ex)\n",
    "        raise\n",
    "        # export_data_df = pd.read_csv('/tmp/tpot-data.csv', sep=COL_SEP, dtype=np.float64)\n",
    "        # display(\"export df\", export_data_df)\n",
    "        # display(\"exported pipeline\", ONNX_FAILS[-1].get('exported_pipeline'))\n",
    "        # display(\"ONNX_FAILS[-1]\", ONNX_FAILS[-1])\n",
    "else:\n",
    "    print(\"no previous errors found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "006d5deb8e6cdcd4312641bdf15f3bc20f0769a7305d81173599a7b40f33b4a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582d980a-dbab-46e8-a1e4-b52d005c9f4d",
   "metadata": {},
   "source": [
    "# Use this notebook to serialize/export models to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f80e63-4f7b-4b54-bb3d-933559f86769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "COL_SEP = '\\t'\n",
    "ONNX_FAILS: list[dict] = []\n",
    "\n",
    "# load the results\n",
    "df = pd.read_csv(\n",
    "    \"results.tsv\", \n",
    "    # quotechar=\"'\",\n",
    "    index_col=False, \n",
    "    sep=COL_SEP,\n",
    "    usecols=['Sport', 'Service', 'Style', 'Type', 'y', 'ModelType', 'Params'],\n",
    ")\n",
    "\n",
    "# drop everything after the seperator\n",
    "seperator_idx = np.where(df['Sport'].str.startswith('*'))[0][0]\n",
    "df = df.iloc[:seperator_idx]\n",
    "\n",
    "with pd.option_context('display.max_rows', 1000, 'display.max_colwidth', 1000):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b6f65-a306-4b5b-81bf-f56983e25089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from skl2onnx import to_onnx\n",
    "import numpy as np\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "from fantasy_py import ContestStyle, CLSRegistry, CONTEST_DOMAIN, lineup\n",
    "\n",
    "from automl import create_automl_model, error_report\n",
    "from generate_train_test import generate_train_test, load_csv\n",
    "\n",
    "\n",
    "DEFAULT_PCA_COMPONENTS = 5\n",
    "\n",
    "\n",
    "def serialize_model(\n",
    "    model, model_type, X_train: pd.DataFrame, y: pd.Series, \n",
    "    full_model_name, tmp_path=None\n",
    "):\n",
    "    print(f\"Serializing {full_model_name=}\")\n",
    "    try:\n",
    "        export_code = None\n",
    "        print(model_type)\n",
    "        if model_type.startswith('tpot'):\n",
    "            df = X_train.copy()\n",
    "            df['target'] = y\n",
    "            tpot_data_file = os.path.join(\n",
    "                tmp_path or tempfile.gettempdir(),\n",
    "                'tpot-data.csv'\n",
    "            )\n",
    "            df.to_csv(tpot_data_file, index=False, sep=COL_SEP)\n",
    "\n",
    "            # TODO: this is messy af, but exported_pipeline is getting dropped from locals for some reason, so need to assign to another variable in the exec code\n",
    "            export_code = model.export(data_file_path=tpot_data_file) \\\n",
    "                .replace(\"COLUMN_SEPARATOR\", COL_SEP) + \"\"\"\n",
    "exported_model = exported_pipeline\n",
    "print(\"Finished execution of export code!!!\")\n",
    "\"\"\"\n",
    "            print(\"###### EXPORT CODE ######\")\n",
    "            print(export_code)\n",
    "            print(\"#########################\")\n",
    "            print(\"running exported code...\")\n",
    "\n",
    "            # following code should add exported_pipeline to locals\n",
    "            exec(export_code)\n",
    "\n",
    "            print(f\"!!!{sorted(locals().keys())=} {sorted(globals().keys())=}\")\n",
    "            if 'exported_model' not in locals():\n",
    "                raise ValueError(f\"exported_model not defined in locals... {locals().keys()}\")\n",
    "            if not (locals()['exported_model']):\n",
    "                raise ValueError(\"exported_model is None\")\n",
    "            exported_pipeline = locals()['exported_model']\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        print(f\"Converting to ONNX... {exported_pipeline=}\")\n",
    "        onnx_model = to_onnx(exported_pipeline, X=X_train, \n",
    "                             name=full_model_name,\n",
    "                             final_types=[('variable1', FloatTensorType([1, 1]))])\n",
    "        with open(full_model_name + \".onnx\", \"wb\") as f:\n",
    "            print(f\"Exporting model to {full_model_name}.onnx\")\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "            print(f\"Exported model to {full_model_name}.onnx\")\n",
    "    except Exception as ex:\n",
    "        global LAST_ONNX_EX, LAST_ONNX_ARGS\n",
    "        ONNX_FAILS.append({\n",
    "            'ex': ex,\n",
    "            'model': model, \n",
    "            'exported_pipeline': locals().get('exported_pipeline'),\n",
    "            'name': full_model_name, \n",
    "            'X': X_train, \n",
    "            'y': y,\n",
    "            'final_types': [('variable1', FloatTensorType([1, 1]))],\n",
    "            'export_code': export_code,\n",
    "        })\n",
    "        raise\n",
    "\n",
    "\n",
    "def train_export(\n",
    "    sport, service, style: ContestStyle,\n",
    "    contest_type: str, model_type: str,\n",
    "    y_type, model_def: dict,\n",
    "    skip_fit=False,\n",
    "):\n",
    "    contest_style = ContestStyle[style.upper()]\n",
    "    contest_type_cls = CLSRegistry.get_class(CONTEST_DOMAIN, contest_type)\n",
    "    full_model_name = f'{sport}_{service}_{contest_style}_{contest_type}_{model_type}_{y_type}'\n",
    "    print(f\"Exporting model '{full_model_name}'\")\n",
    "\n",
    "    data_df = load_csv(sport, service, contest_style, contest_type_cls)\n",
    "    assert len(data_df) > 0, \"CSV load returned no data\"\n",
    "\n",
    "    model_cols = model_def.pop(\n",
    "        'model_cols') if 'model_cols' in model_def else None\n",
    "    train_test_data = generate_train_test(\n",
    "        data_df,\n",
    "        model_cols=model_cols,\n",
    "        random_state=5,\n",
    "    )\n",
    "    if train_test_data is None:\n",
    "        display(\"Failed to generate a train/test data set from...\", data_df)\n",
    "    (X_train, X_test, y_top_train, y_top_test,\n",
    "     y_last_win_train, y_last_win_test) = train_test_data\n",
    "\n",
    "    create_model_params = {}\n",
    "    if model_type.endswith('-pca'):\n",
    "        create_model_params['pca_components'] = (\n",
    "            model_def.pop('n_components')\n",
    "            if 'n_components' in model_def else\n",
    "            DEFAULT_PCA_COMPONENTS\n",
    "        )\n",
    "\n",
    "    if model_type.startswith('skautoml'):\n",
    "        create_model_params.update({\n",
    "            'framework': 'skautoml',\n",
    "            # 'overwrite': True,\n",
    "        })\n",
    "    elif model_type.startswith('tpot'):\n",
    "        create_model_params = {\n",
    "            'framework': 'tpot',\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Don't know how to process model type {model_type}\")\n",
    "\n",
    "    if y_type == 'top':\n",
    "        y_train = y_top_train\n",
    "        y_test = y_top_test\n",
    "    elif y_type == 'last':\n",
    "        y_train = y_last_win_train\n",
    "        y_test = y_last_win_test\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected y of {y_type}\")\n",
    "\n",
    "    # add all remaining\n",
    "    create_model_params.update(model_def)\n",
    "    model, fit_params = create_automl_model(\n",
    "        full_model_name,\n",
    "        seed=1,\n",
    "        **create_model_params,\n",
    "    )\n",
    "    if not skip_fit:\n",
    "        print(\"Training model...\")\n",
    "        model.fit(X_train, y_train, **fit_params)\n",
    "        error_report(model, X_test, y_test,\n",
    "                    f\"{full_model_name}: model_cols={model_def.get('model_cols')}\")\n",
    "    else:\n",
    "        print(\"Skipping fit...\")\n",
    "\n",
    "    serialize_model(model, model_type, X_train, y_train, full_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "SKIP_FIT = False\n",
    "row = None\n",
    "models_df = df.query(\"Type == 'GPP' and Sport == 'nhl' and Service == 'draftkings' and ModelType == 'tpot'\")\n",
    "with pd.option_context('display.max_rows', 1000, 'display.max_colwidth', 1000):\n",
    "    display(models_df)\n",
    "# models = df.iterrows()\n",
    "# models_dict = {\n",
    "#     'Sport': 'nhl', \n",
    "#     'Service': 'fanduel',\n",
    "#     'Style': 'classic',\n",
    "#     'Type': 'GPP', \n",
    "#     'ModelType': 'tpot', \n",
    "#     'y': 'top',\n",
    "#     'Params': '{\"generations\": 100, \"early_stop\": 10, \"population_size\": 100, \"n_jobs\": 3}'\n",
    "# }\n",
    "# models = [\n",
    "#     (None, namedtuple(\"test_model\", models_dict.keys())(*models_dict.values()))\n",
    "# ]\n",
    "PARAM_OVERRIDES = {} # {'generations': 10, 'early_stop': 1}\n",
    "\n",
    "for _, row in models_df.iterrows():\n",
    "    try:\n",
    "        model_def: dict = ast.literal_eval(row.Params)\n",
    "    except Exception:\n",
    "        print(\"Failed to parse params\", row.Params)\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        model_def.update(PARAM_OVERRIDES)\n",
    "        train_export(row.Sport, row.Service, row.Style,\n",
    "                    row.Type, row.ModelType, row.y,\n",
    "                    model_def, skip_fit=SKIP_FIT)\n",
    "        break\n",
    "    except Exception:\n",
    "        display(f\"Failed to train+export: {row.Sport=} {row.Service=} {row.Style=} {row.Type=} {row.ModelType=} {row.y=} {row.Params=}\")\n",
    "        raise\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f06308",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ONNX_FAILS):\n",
    "    try:\n",
    "        print(\"###### attempting to serialize last failed model!!! ####\")\n",
    "        serialize_model(\n",
    "            ONNX_FAILS[-1]['model'],\n",
    "            'tpot',\n",
    "            ONNX_FAILS[-1]['X'],\n",
    "            ONNX_FAILS[-1]['y'],\n",
    "            ONNX_FAILS[-1]['name']\n",
    "        )\n",
    "        print(\"#### serialization successful! ###\")\n",
    "    except Exception as ex:\n",
    "        print(\"#### serializeation failed!!!\", ex)\n",
    "        raise\n",
    "        # export_data_df = pd.read_csv('/tmp/tpot-data.csv', sep=COL_SEP, dtype=np.float64)\n",
    "        # display(\"export df\", export_data_df)\n",
    "        # display(\"exported pipeline\", ONNX_FAILS[-1].get('exported_pipeline'))\n",
    "        # display(\"ONNX_FAILS[-1]\", ONNX_FAILS[-1])\n",
    "else:\n",
    "    print(\"no previous errors found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "006d5deb8e6cdcd4312641bdf15f3bc20f0769a7305d81173599a7b40f33b4a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

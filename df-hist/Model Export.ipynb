{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582d980a-dbab-46e8-a1e4-b52d005c9f4d",
   "metadata": {},
   "source": [
    "# Serialize/export models to ONNX\n",
    "Read the contents of results.txt and serialize all the top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f80e63-4f7b-4b54-bb3d-933559f86769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from serialize import SerializeFailure, COL_SEP\n",
    "import log\n",
    "\n",
    "log.setup()\n",
    "\n",
    "LOGGER = logging.getLogger('Model.Export')\n",
    "LOGGER.info(\"logger ready\")\n",
    "\n",
    "\n",
    "ONNX_FAILS: list[SerializeFailure] = []\n",
    "\n",
    "# load the results\n",
    "df = pd.read_csv(\n",
    "    \"results.tsv\", \n",
    "    index_col=False, \n",
    "    sep=COL_SEP,\n",
    "    usecols=['Sport', 'Service', 'Style', 'Type', 'Target', 'ModelType', 'R2', 'Date', 'Params'],\n",
    ")\n",
    "\n",
    "# drop everything after the seperator\n",
    "seperator_idx = np.where(df['Sport'].str.startswith('*'))[0][0]\n",
    "df = df.iloc[:seperator_idx]\n",
    "\n",
    "# df = df.query('ModelType == \"tpot\"')\n",
    "\n",
    "with pd.option_context('display.max_rows', 1000, 'display.max_colwidth', 1000):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b6f65-a306-4b5b-81bf-f56983e25089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from fantasy_py import ContestStyle, CLSRegistry, CONTEST_DOMAIN, lineup\n",
    "\n",
    "from automl import create_automl_model, error_report\n",
    "from serialize import serialize_model, SerializeFailure, SUPPORTED_EXPORT_MODELS, get_serialized_file_path\n",
    "from generate_train_test import generate_train_test, load_csv\n",
    "\n",
    "\n",
    "DEFAULT_PCA_COMPONENTS = 5\n",
    "\n",
    "\n",
    "def train_export(\n",
    "    sport, service, style: ContestStyle,\n",
    "    contest_type: str, model_type: str,\n",
    "    target,\n",
    "    model_def_: dict,\n",
    "    skip_fit=False,\n",
    "    datapath=\".\",\n",
    "    modelpath=\".\",\n",
    "    overwrite=True,\n",
    "    description_path=None,\n",
    "):\n",
    "    if not os.path.isdir(modelpath):\n",
    "        LOGGER.info(f\"Creating model path '{modelpath}'\")\n",
    "        os.makedirs(modelpath)\n",
    "    if description_path and not os.path.isdir(description_path):\n",
    "        LOGGER.info(f\"Creating model description path '{description_path}'\")\n",
    "        os.makedirs(description_path)\n",
    "\n",
    "    contest_style = ContestStyle[style.upper()]\n",
    "    full_model_name = f'{sport}_{service}_{contest_style}_{contest_type}_{model_type}_{target}'\n",
    "    LOGGER.info(\"Running train_export for %s\", full_model_name)\n",
    "    model_filepath = get_serialized_file_path(full_model_name, modelpath)\n",
    "\n",
    "    if os.path.isfile(model_filepath) and not overwrite:\n",
    "        LOGGER.info(f\"Model '{model_filepath}' already exists, skipping\")\n",
    "        return\n",
    "\n",
    "    contest_type_cls = CLSRegistry.get_class(CONTEST_DOMAIN, contest_type)\n",
    "    data_df = load_csv(sport, service, contest_style,\n",
    "                       contest_type_cls, data_folder=datapath)\n",
    "    assert len(data_df) > 0, \"CSV load returned no data\"\n",
    "\n",
    "    model_def = dict(model_def_)\n",
    "    random_state = model_def.pop(\"random_state\", None)\n",
    "    model_cols = model_def.pop(\n",
    "        'model_cols'\n",
    "    ) if 'model_cols' in model_def else None\n",
    "    train_test_data = generate_train_test(\n",
    "        data_df,\n",
    "        model_cols=model_cols,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    if train_test_data is None:\n",
    "        LOGGER.error(\"Failed to generate a train/test data set from data: %s\", data_df)\n",
    "    (X_train, X_test, y_top_train, y_top_test,\n",
    "     y_last_win_train, y_last_win_test) = train_test_data\n",
    "\n",
    "    create_model_params = {\n",
    "        'random_state': random_state,\n",
    "    }\n",
    "    if model_type.endswith('-pca'):\n",
    "        create_model_params['pca_components'] = (\n",
    "            model_def.pop('n_components')\n",
    "            if 'n_components' in model_def else\n",
    "            DEFAULT_PCA_COMPONENTS\n",
    "        )\n",
    "\n",
    "    if model_type.startswith('skautoml'):\n",
    "        create_model_params.update({\n",
    "            'framework': 'skautoml',\n",
    "        })\n",
    "    elif model_type.startswith('tpot'):\n",
    "        create_model_params = {\n",
    "            'framework': 'tpot',\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Don't know how to process model type {model_type}\")\n",
    "\n",
    "    if target == 'top':\n",
    "        y_train = y_top_train\n",
    "        y_test = y_top_test\n",
    "    elif target == 'last':\n",
    "        y_train = y_last_win_train\n",
    "        y_test = y_last_win_test\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected y of {target}\")\n",
    "\n",
    "    # add all remaining\n",
    "    create_model_params.update(model_def)\n",
    "    if not skip_fit:\n",
    "        create_model_params['X_train'] = X_train\n",
    "        create_model_params['y_train'] = y_train\n",
    "    cam_result = create_automl_model(\n",
    "        target,\n",
    "        model_desc=full_model_name,\n",
    "        X_test=X_test, y_test=y_test,\n",
    "        **create_model_params,\n",
    "    )\n",
    "\n",
    "    if skip_fit:\n",
    "        return\n",
    "\n",
    "    if description_path:\n",
    "        result_filepath = os.path.join(description_path, f\"{full_model_name}.score.json\")\n",
    "        with open(result_filepath, 'w') as fp:\n",
    "            json.dump(cam_result['eval_result'], fp)        \n",
    "\n",
    "    serialize_model(cam_result['model'], model_type, X_train, y_train,\n",
    "                    full_model_name, \n",
    "                    model_folder=modelpath,\n",
    "                    model_desc_folder=description_path)\n",
    "    LOGGER.info(\"Model %s successfully exported\", full_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "OVERWRITE = False\n",
    "# skip fit and serialize... dryrun\n",
    "DRYRUN = False\n",
    "\n",
    "PARAM_OVERRIDES = {\n",
    "    'generations': 5, \n",
    "    # 'early_stop': 1, \n",
    "    # 'max_train_time': 60\n",
    "}\n",
    "\n",
    "pbar = tqdm(df.iterrows(), total=len(df))\n",
    "for _, row in pbar:\n",
    "    model_desc = f\"sport={row.Sport} service={row.Service} style={row.Style} type={row.Type} y={row.Target}\"\n",
    "    pbar.set_postfix_str(model_desc)\n",
    "    if row.ModelType not in SUPPORTED_EXPORT_MODELS:\n",
    "        LOGGER.error(\n",
    "            f\"Failed to train+export model {model_desc} of type {row.ModelType=}. Export of this type is not supported.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model_def: dict = ast.literal_eval(row.Params)\n",
    "    except Exception as ex:\n",
    "        LOGGER.exception(\"Failed to parse params: %s\", row.Params, exc_info=ex)\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        model_def.update(PARAM_OVERRIDES)\n",
    "        train_export(row.Sport, row.Service, row.Style,\n",
    "                     row.Type, row.ModelType, row.Target,\n",
    "                     model_def, \n",
    "                     skip_fit=DRYRUN, overwrite=OVERWRITE,\n",
    "                     datapath=\"data\", modelpath=\"models\", description_path=\"eval_results\")\n",
    "    except SerializeFailure as se:\n",
    "        LOGGER.exception(\n",
    "            f\"Failed to serialize: {model_desc} {row.ModelType=} {row.Params=}\"\n",
    "        , exc_info=se)\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "    except Exception as ex:\n",
    "        LOGGER.exception(\n",
    "            f\"Failed to train+export: {model_desc} {row.ModelType=} {row.Params=}\", exc_info=ex\n",
    "        )\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "006d5deb8e6cdcd4312641bdf15f3bc20f0769a7305d81173599a7b40f33b4a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

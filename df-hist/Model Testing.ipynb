{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585d8aeb-9ef2-471c-a683-fb65c12007d9",
   "metadata": {},
   "source": [
    "# Model Testing for Daily Fantasy Scores\n",
    "Predict for the minimum and maximum winning scores for a slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8bc26dc-30e5-4275-a396-58b670633d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fantasy_py import ContestStyle\n",
    "from fantasy_py.lineup.strategy import GeneralPrizePool, FiftyFifty\n",
    "\n",
    "# normal test run\n",
    "# TRAIN_TIME = 600\n",
    "# PER_RUN_TIME_LIMIT = 120\n",
    "# STYLE = ContestStyle.CLASSIC\n",
    "\n",
    "# short test run\n",
    "# TRAIN_TIME = 120\n",
    "# PER_RUN_TIME_LIMIT = 30\n",
    "\n",
    "\n",
    "# model_cols = {'best-possible-score'}\n",
    "# SPORT = 'mlb'\n",
    "# SERVICE = 'fanduel'\n",
    "# CONTEST_TYPE = GeneralPrizePool\n",
    "\n",
    "def load_csv(sport, service, style: ContestStyle, contest_type) -> pd.DataFrame:\n",
    "    filename = f\"{sport}-{service}-{style.name}-{contest_type.NAME}.csv\"\n",
    "    print(f\"loading {filename=}\")\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    print(f\"{len(df)} rows of data loaded\")\n",
    "    nan_slate_rows = len(df.query('slate_id.isnull()'))\n",
    "    nan_best_score_rows = len(df.query('`best-possible-score`.isnull()'))\n",
    "    if nan_slate_rows > 0 or nan_best_score_rows > 0:\n",
    "        print(f\"dropping {nan_slate_rows + nan_best_score_rows} rows due to {nan_slate_rows=} {nan_best_score_rows=}\")\n",
    "        df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# df = load_csv(SPORT, SERVICE, STYLE, CONTEST_TYPE)\n",
    "# with pd.option_context('max_rows', 1000, 'max_columns', 100):\n",
    "#     print(f\"{len(df)} rows\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12d13cfb-f5a7-4ee6-8361-468c1666038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "COLS_TO_IGNORE = {\n",
    "    'date', 'style', 'type', 'link', 'entries', 'slate_id', \n",
    "    'top_score', 'last_winning_score',\n",
    "}\n",
    "\n",
    "\n",
    "def generate_train_test(df, train_size: float = .5, \n",
    "                        random_state: Optional[int] = None,\n",
    "                        model_cols: Optional[set[str]] = None) -> Optional[tuple]:\n",
    "    \"\"\" \n",
    "    create regression train test data \n",
    "    model_cols - if none then use all available columns\n",
    "    return (X-train, X-test y-top-train, y-top-test, y-last-win-train, y-last-win-test)\n",
    "    \"\"\"\n",
    "    x_cols = []\n",
    "    assert (model_cols is None) or model_cols <= set(df.columns), \\\n",
    "        \"Requested model columns not a subset of available data columns\"\n",
    "    for col in df.columns:\n",
    "        if col in COLS_TO_IGNORE:\n",
    "            continue\n",
    "        assert col[0] == '(' or col.startswith('team') or col == 'best-possible-score', \\\n",
    "            f\"Unexpected data column named '{col}'\"\n",
    "        \n",
    "        if (model_cols is None) or col in model_cols:\n",
    "            x_cols.append(col)\n",
    "\n",
    "    X = df[x_cols]\n",
    "    if len(X) == 0:\n",
    "        return None\n",
    "    # display(X)\n",
    "    y_top = df.top_score\n",
    "    # display(y_top)\n",
    "    y_last_win = df.last_winning_score\n",
    "    # display(y_last_win)\n",
    "    \n",
    "    return train_test_split(X, y_top, y_last_win, \n",
    "                            random_state=random_state,\n",
    "                            train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43a741f0-58f8-4315-a093-4506dcb18317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import autosklearn.regression\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def automl(X_train, y_train, X_test, y_test, model_name, \n",
    "           train_time=60, per_run_time_limit=10,\n",
    "           overwrite: bool = False,\n",
    "           error_graph=False,\n",
    "           seed=1):\n",
    "    \"\"\" \n",
    "    overwrite - overwrite the output folder \n",
    "    error_graph - if true then graph the errors\n",
    "    \n",
    "    return the model\n",
    "    \"\"\"\n",
    "    output_folder = '/tmp/autosklearn_regression_' + model_name\n",
    "    if overwrite and os.path.isdir(output_folder):\n",
    "        shutil.rmtree(output_folder)\n",
    "    automl_model = autosklearn.regression.AutoSklearnRegressor(\n",
    "        time_left_for_this_task=train_time,\n",
    "        per_run_time_limit=per_run_time_limit,\n",
    "        output_folder=output_folder,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    automl_model.fit(X_train, y_train, dataset_name=model_name)\n",
    "    return automl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a785d68d-64c4-497d-b03b-0e9e090c8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, X_test, y_top_train, y_top_test,\n",
    "#  y_last_win_train, y_last_win_test) =  generate_train_test(\n",
    "#     df,\n",
    "#     model_cols=model_cols,\n",
    "#     random_state=5,\n",
    "# )\n",
    "\n",
    "# with pd.option_context('max_rows', 1000, 'max_columns', 100, 'max_colwidth', 9999):\n",
    "    #     display(\n",
    "    #         # train and test input data\n",
    "    #         'x-train', X_train, \n",
    "    #         'x-test', X_test, \n",
    "    #         # answers for top score train/test\n",
    "    #         'y-top-train', y_top_train, \n",
    "    #         'y-top-test', y_top_test,\n",
    "    #         # answers for min winning score train/test\n",
    "    #         'y-last-win-train', y_last_win_train, \n",
    "    #         'y-last-win-test', y_last_win_test\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e70dfffd-608f-4791-b431-958e026a4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def error_report(model, X_test, y_test, desc: str):\n",
    "    print(desc)\n",
    "    # print(model.show_models())\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "    print(\"RMSE score:\", sqrt(sklearn.metrics.mean_squared_error(y_test, predictions)))\n",
    "    print(\"MAE score:\", sqrt(sklearn.metrics.mean_absolute_error(y_test, predictions)))\n",
    "\n",
    "    plot_data = pd.DataFrame({\n",
    "        'truth': y_test,\n",
    "        'prediction': predictions\n",
    "    })\n",
    "    plot_data['error'] = plot_data.prediction - plot_data.truth\n",
    "    # display(plot_data)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize=(10, 5))\n",
    "    fig.suptitle(desc)\n",
    "    for ax in axs:\n",
    "        ax.axis('equal')\n",
    "    \n",
    "    min_v = min(plot_data.truth.min(), plot_data.prediction.min())\n",
    "    max_v = max(plot_data.truth.max(), plot_data.prediction.max())\n",
    "\n",
    "    axs[0].plot((min_v, max_v), \n",
    "                (min_v, max_v), \n",
    "                '-g', linewidth=1) \n",
    "    plot_data.plot(kind='scatter', x='truth', y='prediction', ax=axs[0])\n",
    "\n",
    "    axs[1].yaxis.set_label_position(\"right\")\n",
    "    axs[1].plot((min_v, max_v), \n",
    "                (0, 0), \n",
    "                '-g', linewidth=1) \n",
    "    plot_data.plot(kind='scatter', x='truth', y='error', ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c2e978d-6647-4398-ae99-ad30ec6121d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'top-score'\n",
    "\n",
    "# model_top = automl(\n",
    "#     X_train, y_top_train, X_test, y_top_test, model_name, \n",
    "#     train_time=TRAIN_TIME,\n",
    "#     per_run_time_limit=PER_RUN_TIME_LIMIT,\n",
    "#     seed=1,\n",
    "#     overwrite=True\n",
    "# )\n",
    "# error_report(model_top, X_test, y_top_test, \n",
    "#              f\"{SPORT}-{SERVICE}-{STYLE.name}-{CONTEST_TYPE.NAME}-{model_name}: {model_cols=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0638dc4b-7dfc-40aa-b396-aec020908cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'last-win-score'\n",
    "\n",
    "# model_last_win = automl(\n",
    "#     X_train, y_last_win_train, X_test, y_last_win_test, model_name, \n",
    "#     train_time=TRAIN_TIME,\n",
    "#     per_run_time_limit=PER_RUN_TIME_LIMIT,\n",
    "#     seed=1,\n",
    "#     overwrite=True\n",
    "# )\n",
    "# error_report(model_last_win, X_test, y_last_win_test, \n",
    "#              f\"{SPORT}-{SERVICE}-{STYLE.name}-{CONTEST_TYPE.NAME}-{model_name}: {model_cols=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f0a64af-f4a9-4c38-bbc5-8caa449362b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_data(X_train, X_test) -> tuple[pd.DataFrame, pd.DataFrame]: \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    print(f\"Explained variance = {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Singular varlues = {pca.singular_values_}\")\n",
    "\n",
    "    # print(\"Original X:\")\n",
    "    # display(X_train)\n",
    "\n",
    "    # print(\"Transformed Xs\")\n",
    "    X_train_pca = pd.DataFrame(pca.transform(X_train))\n",
    "    # display(X_train_pca)\n",
    "    X_test_pca = pd.DataFrame(pca.transform(X_test))\n",
    "    # display(X_test_pca)\n",
    "    \n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "004c0bcb-e442-40c9-9cd7-c0e847de8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'top-score-pca'\n",
    "# model_top_pca = automl(\n",
    "#     X_train_pca, y_top_train, X_test_pca, y_top_test, model_name, \n",
    "#     train_time=TRAIN_TIME,\n",
    "#     per_run_time_limit=PER_RUN_TIME_LIMIT,\n",
    "#     seed=1,\n",
    "#     overwrite=True\n",
    "# )\n",
    "# error_report(model_top_pca, X_test_pca, y_top_test, \n",
    "#              f\"{SPORT}-{SERVICE}-{STYLE.name}-{CONTEST_TYPE.NAME}-{model_name}: {model_cols=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dfb3989-4e3c-4b30-ac00-f8863f9d942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'last-win-score-pca'\n",
    "# model_last_win_pca = automl(\n",
    "#     X_train_pca, y_last_win_train, X_test_pca, y_last_win_test, model_name, \n",
    "#     train_time=TRAIN_TIME,\n",
    "#     per_run_time_limit=PER_RUN_TIME_LIMIT,\n",
    "#     seed=1,\n",
    "#     overwrite=True\n",
    "# )\n",
    "# error_report(model_last_win_pca, X_test_pca, y_last_win_test, \n",
    "#              f\"{SPORT}-{SERVICE}-{STYLE.name}-{CONTEST_TYPE.NAME}-{model_name}: {model_cols=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20794400-8eed-4153-814a-bd03ae63ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading filename='nba-fanduel-CLASSIC-GPP.csv'\n",
      "38 rows of data loaded\n",
      "38 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>style</th>\n",
       "      <th>type</th>\n",
       "      <th>top_score</th>\n",
       "      <th>last_winning_score</th>\n",
       "      <th>link</th>\n",
       "      <th>best-possible-score</th>\n",
       "      <th>slate_id</th>\n",
       "      <th>team_count</th>\n",
       "      <th>team-med</th>\n",
       "      <th>...</th>\n",
       "      <th>('med-dfs', 'C')</th>\n",
       "      <th>('med-dfs', 'PF')</th>\n",
       "      <th>('med-dfs', 'PG')</th>\n",
       "      <th>('med-dfs', 'SF')</th>\n",
       "      <th>('med-dfs', 'SG')</th>\n",
       "      <th>('70.0th-pctl-dfs', 'C')</th>\n",
       "      <th>('70.0th-pctl-dfs', 'PF')</th>\n",
       "      <th>('70.0th-pctl-dfs', 'PG')</th>\n",
       "      <th>('70.0th-pctl-dfs', 'SF')</th>\n",
       "      <th>('70.0th-pctl-dfs', 'SG')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>333.8</td>\n",
       "      <td>256.0</td>\n",
       "      <td>https://www.fanduel.com/entry/ACCBQBZGM</td>\n",
       "      <td>357.25</td>\n",
       "      <td>6719</td>\n",
       "      <td>6</td>\n",
       "      <td>107.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.40</td>\n",
       "      <td>26.50</td>\n",
       "      <td>19.90</td>\n",
       "      <td>14.60</td>\n",
       "      <td>16.10</td>\n",
       "      <td>23.45</td>\n",
       "      <td>35.18</td>\n",
       "      <td>24.64</td>\n",
       "      <td>21.06</td>\n",
       "      <td>23.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>405.4</td>\n",
       "      <td>320.2</td>\n",
       "      <td>https://www.fanduel.com/entry/AEFRESUNV</td>\n",
       "      <td>411.00</td>\n",
       "      <td>6712</td>\n",
       "      <td>8</td>\n",
       "      <td>119.5</td>\n",
       "      <td>...</td>\n",
       "      <td>21.05</td>\n",
       "      <td>19.70</td>\n",
       "      <td>25.80</td>\n",
       "      <td>18.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>30.98</td>\n",
       "      <td>27.50</td>\n",
       "      <td>35.70</td>\n",
       "      <td>23.14</td>\n",
       "      <td>21.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>402.7</td>\n",
       "      <td>318.9</td>\n",
       "      <td>https://www.fanduel.com/entry/AFWXUUGOG</td>\n",
       "      <td>453.00</td>\n",
       "      <td>6860</td>\n",
       "      <td>18</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.80</td>\n",
       "      <td>22.20</td>\n",
       "      <td>16.10</td>\n",
       "      <td>17.35</td>\n",
       "      <td>16.85</td>\n",
       "      <td>27.60</td>\n",
       "      <td>27.99</td>\n",
       "      <td>22.70</td>\n",
       "      <td>28.30</td>\n",
       "      <td>25.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>383.9</td>\n",
       "      <td>383.9</td>\n",
       "      <td>https://www.fanduel.com/entry/AHMNEMODE</td>\n",
       "      <td>389.00</td>\n",
       "      <td>6782</td>\n",
       "      <td>8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.80</td>\n",
       "      <td>29.55</td>\n",
       "      <td>12.00</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.45</td>\n",
       "      <td>31.56</td>\n",
       "      <td>36.27</td>\n",
       "      <td>17.21</td>\n",
       "      <td>31.78</td>\n",
       "      <td>32.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-28</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>393.1</td>\n",
       "      <td>307.8</td>\n",
       "      <td>https://www.fanduel.com/entry/AMUDHQRDI</td>\n",
       "      <td>439.00</td>\n",
       "      <td>6716</td>\n",
       "      <td>22</td>\n",
       "      <td>104.5</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>17.30</td>\n",
       "      <td>17.10</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.70</td>\n",
       "      <td>34.44</td>\n",
       "      <td>24.43</td>\n",
       "      <td>25.32</td>\n",
       "      <td>25.69</td>\n",
       "      <td>27.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>402.2</td>\n",
       "      <td>318.4</td>\n",
       "      <td>https://www.fanduel.com/entry/AQAWZWZZJ</td>\n",
       "      <td>430.25</td>\n",
       "      <td>6757</td>\n",
       "      <td>14</td>\n",
       "      <td>112.5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.55</td>\n",
       "      <td>14.20</td>\n",
       "      <td>23.40</td>\n",
       "      <td>15.70</td>\n",
       "      <td>18.70</td>\n",
       "      <td>33.78</td>\n",
       "      <td>16.80</td>\n",
       "      <td>30.48</td>\n",
       "      <td>23.92</td>\n",
       "      <td>25.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>392.1</td>\n",
       "      <td>293.8</td>\n",
       "      <td>https://www.fanduel.com/entry/AUURIZHRE</td>\n",
       "      <td>400.50</td>\n",
       "      <td>6738</td>\n",
       "      <td>12</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.20</td>\n",
       "      <td>22.30</td>\n",
       "      <td>18.80</td>\n",
       "      <td>17.95</td>\n",
       "      <td>19.70</td>\n",
       "      <td>30.60</td>\n",
       "      <td>28.52</td>\n",
       "      <td>24.24</td>\n",
       "      <td>22.49</td>\n",
       "      <td>22.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>380.6</td>\n",
       "      <td>380.6</td>\n",
       "      <td>https://www.fanduel.com/entry/AWZVCNOYW</td>\n",
       "      <td>430.50</td>\n",
       "      <td>6882</td>\n",
       "      <td>20</td>\n",
       "      <td>111.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.40</td>\n",
       "      <td>18.30</td>\n",
       "      <td>18.40</td>\n",
       "      <td>15.40</td>\n",
       "      <td>28.85</td>\n",
       "      <td>27.30</td>\n",
       "      <td>26.00</td>\n",
       "      <td>24.28</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>454.3</td>\n",
       "      <td>345.2</td>\n",
       "      <td>https://www.fanduel.com/entry/AXNJTEEKL</td>\n",
       "      <td>452.25</td>\n",
       "      <td>6987</td>\n",
       "      <td>18</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>23.20</td>\n",
       "      <td>17.75</td>\n",
       "      <td>17.65</td>\n",
       "      <td>16.80</td>\n",
       "      <td>18.30</td>\n",
       "      <td>30.12</td>\n",
       "      <td>26.67</td>\n",
       "      <td>31.06</td>\n",
       "      <td>27.45</td>\n",
       "      <td>28.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>389.3</td>\n",
       "      <td>389.3</td>\n",
       "      <td>https://www.fanduel.com/entry/BAFDQLUNA</td>\n",
       "      <td>439.25</td>\n",
       "      <td>6784</td>\n",
       "      <td>22</td>\n",
       "      <td>104.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22.20</td>\n",
       "      <td>19.10</td>\n",
       "      <td>21.25</td>\n",
       "      <td>17.70</td>\n",
       "      <td>19.25</td>\n",
       "      <td>25.90</td>\n",
       "      <td>31.43</td>\n",
       "      <td>25.23</td>\n",
       "      <td>23.60</td>\n",
       "      <td>25.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>419.0</td>\n",
       "      <td>322.1</td>\n",
       "      <td>https://www.fanduel.com/entry/BCWSUZQKZ</td>\n",
       "      <td>452.25</td>\n",
       "      <td>6847</td>\n",
       "      <td>8</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22.55</td>\n",
       "      <td>24.45</td>\n",
       "      <td>21.60</td>\n",
       "      <td>11.85</td>\n",
       "      <td>16.10</td>\n",
       "      <td>26.71</td>\n",
       "      <td>32.05</td>\n",
       "      <td>35.30</td>\n",
       "      <td>21.48</td>\n",
       "      <td>26.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>407.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>https://www.fanduel.com/entry/BNNHOXXWX</td>\n",
       "      <td>411.00</td>\n",
       "      <td>6712</td>\n",
       "      <td>8</td>\n",
       "      <td>119.5</td>\n",
       "      <td>...</td>\n",
       "      <td>21.05</td>\n",
       "      <td>19.70</td>\n",
       "      <td>25.80</td>\n",
       "      <td>18.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>30.98</td>\n",
       "      <td>27.50</td>\n",
       "      <td>35.70</td>\n",
       "      <td>23.14</td>\n",
       "      <td>21.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>432.1</td>\n",
       "      <td>432.1</td>\n",
       "      <td>https://www.fanduel.com/entry/BOPDEMEWV</td>\n",
       "      <td>453.75</td>\n",
       "      <td>6728</td>\n",
       "      <td>14</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>17.25</td>\n",
       "      <td>23.60</td>\n",
       "      <td>23.60</td>\n",
       "      <td>18.90</td>\n",
       "      <td>30.30</td>\n",
       "      <td>24.35</td>\n",
       "      <td>34.43</td>\n",
       "      <td>25.62</td>\n",
       "      <td>21.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>378.0</td>\n",
       "      <td>314.3</td>\n",
       "      <td>https://www.fanduel.com/entry/BPEJEINKO</td>\n",
       "      <td>394.00</td>\n",
       "      <td>6748</td>\n",
       "      <td>8</td>\n",
       "      <td>114.5</td>\n",
       "      <td>...</td>\n",
       "      <td>28.40</td>\n",
       "      <td>20.30</td>\n",
       "      <td>19.65</td>\n",
       "      <td>22.40</td>\n",
       "      <td>23.55</td>\n",
       "      <td>33.87</td>\n",
       "      <td>23.50</td>\n",
       "      <td>25.24</td>\n",
       "      <td>33.36</td>\n",
       "      <td>28.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>443.4</td>\n",
       "      <td>443.4</td>\n",
       "      <td>https://www.fanduel.com/entry/BRHVCMDFB</td>\n",
       "      <td>452.25</td>\n",
       "      <td>6987</td>\n",
       "      <td>18</td>\n",
       "      <td>115.5</td>\n",
       "      <td>...</td>\n",
       "      <td>23.20</td>\n",
       "      <td>17.75</td>\n",
       "      <td>17.65</td>\n",
       "      <td>16.80</td>\n",
       "      <td>18.30</td>\n",
       "      <td>30.12</td>\n",
       "      <td>26.67</td>\n",
       "      <td>31.06</td>\n",
       "      <td>27.45</td>\n",
       "      <td>28.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>415.7</td>\n",
       "      <td>334.7</td>\n",
       "      <td>https://www.fanduel.com/entry/BUNPHWIDC</td>\n",
       "      <td>431.25</td>\n",
       "      <td>6887</td>\n",
       "      <td>14</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>14.70</td>\n",
       "      <td>19.10</td>\n",
       "      <td>15.90</td>\n",
       "      <td>21.85</td>\n",
       "      <td>34.09</td>\n",
       "      <td>24.90</td>\n",
       "      <td>30.90</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>405.9</td>\n",
       "      <td>405.9</td>\n",
       "      <td>https://www.fanduel.com/entry/CAYBYOPAP</td>\n",
       "      <td>449.50</td>\n",
       "      <td>6980</td>\n",
       "      <td>20</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.35</td>\n",
       "      <td>19.90</td>\n",
       "      <td>20.20</td>\n",
       "      <td>23.90</td>\n",
       "      <td>19.70</td>\n",
       "      <td>27.75</td>\n",
       "      <td>27.08</td>\n",
       "      <td>30.94</td>\n",
       "      <td>31.20</td>\n",
       "      <td>25.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>381.4</td>\n",
       "      <td>381.4</td>\n",
       "      <td>https://www.fanduel.com/entry/CDPWYVKIR</td>\n",
       "      <td>392.00</td>\n",
       "      <td>6835</td>\n",
       "      <td>8</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>16.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>18.05</td>\n",
       "      <td>34.70</td>\n",
       "      <td>29.90</td>\n",
       "      <td>25.74</td>\n",
       "      <td>25.12</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>402.9</td>\n",
       "      <td>301.7</td>\n",
       "      <td>https://www.fanduel.com/entry/CNERQUOPA</td>\n",
       "      <td>471.25</td>\n",
       "      <td>6725</td>\n",
       "      <td>16</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.60</td>\n",
       "      <td>20.30</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>21.50</td>\n",
       "      <td>25.98</td>\n",
       "      <td>24.73</td>\n",
       "      <td>21.48</td>\n",
       "      <td>26.15</td>\n",
       "      <td>28.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>331.5</td>\n",
       "      <td>256.6</td>\n",
       "      <td>https://www.fanduel.com/entry/COGMDNIZQ</td>\n",
       "      <td>357.25</td>\n",
       "      <td>6719</td>\n",
       "      <td>6</td>\n",
       "      <td>107.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.40</td>\n",
       "      <td>26.50</td>\n",
       "      <td>19.90</td>\n",
       "      <td>14.60</td>\n",
       "      <td>16.10</td>\n",
       "      <td>23.45</td>\n",
       "      <td>35.18</td>\n",
       "      <td>24.64</td>\n",
       "      <td>21.06</td>\n",
       "      <td>23.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>414.9</td>\n",
       "      <td>350.3</td>\n",
       "      <td>https://www.fanduel.com/entry/CPXSQDING</td>\n",
       "      <td>431.25</td>\n",
       "      <td>6887</td>\n",
       "      <td>14</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>14.70</td>\n",
       "      <td>19.10</td>\n",
       "      <td>15.90</td>\n",
       "      <td>21.85</td>\n",
       "      <td>34.09</td>\n",
       "      <td>24.90</td>\n",
       "      <td>30.90</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-10-28</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>386.8</td>\n",
       "      <td>386.8</td>\n",
       "      <td>https://www.fanduel.com/entry/CTBPKRXDY</td>\n",
       "      <td>439.00</td>\n",
       "      <td>6716</td>\n",
       "      <td>22</td>\n",
       "      <td>104.5</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>17.30</td>\n",
       "      <td>17.10</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.70</td>\n",
       "      <td>34.44</td>\n",
       "      <td>24.43</td>\n",
       "      <td>25.32</td>\n",
       "      <td>25.69</td>\n",
       "      <td>27.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>324.8</td>\n",
       "      <td>324.8</td>\n",
       "      <td>https://www.fanduel.com/entry/CUDKRBNNU</td>\n",
       "      <td>357.25</td>\n",
       "      <td>6719</td>\n",
       "      <td>6</td>\n",
       "      <td>107.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.40</td>\n",
       "      <td>26.50</td>\n",
       "      <td>19.90</td>\n",
       "      <td>14.60</td>\n",
       "      <td>16.10</td>\n",
       "      <td>23.45</td>\n",
       "      <td>35.18</td>\n",
       "      <td>24.64</td>\n",
       "      <td>21.06</td>\n",
       "      <td>23.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>376.8</td>\n",
       "      <td>294.4</td>\n",
       "      <td>https://www.fanduel.com/entry/CVUMZZFYG</td>\n",
       "      <td>422.50</td>\n",
       "      <td>6760</td>\n",
       "      <td>16</td>\n",
       "      <td>112.5</td>\n",
       "      <td>...</td>\n",
       "      <td>24.10</td>\n",
       "      <td>21.00</td>\n",
       "      <td>23.65</td>\n",
       "      <td>15.75</td>\n",
       "      <td>17.50</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.72</td>\n",
       "      <td>30.08</td>\n",
       "      <td>22.02</td>\n",
       "      <td>25.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>405.1</td>\n",
       "      <td>405.1</td>\n",
       "      <td>https://www.fanduel.com/entry/CYMEDSFNE</td>\n",
       "      <td>453.00</td>\n",
       "      <td>6860</td>\n",
       "      <td>18</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.80</td>\n",
       "      <td>22.20</td>\n",
       "      <td>16.10</td>\n",
       "      <td>17.35</td>\n",
       "      <td>16.85</td>\n",
       "      <td>27.60</td>\n",
       "      <td>27.99</td>\n",
       "      <td>22.70</td>\n",
       "      <td>28.30</td>\n",
       "      <td>25.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>398.6</td>\n",
       "      <td>398.6</td>\n",
       "      <td>https://www.fanduel.com/entry/DCTKMOEQH</td>\n",
       "      <td>439.25</td>\n",
       "      <td>6852</td>\n",
       "      <td>8</td>\n",
       "      <td>112.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34.85</td>\n",
       "      <td>16.75</td>\n",
       "      <td>20.40</td>\n",
       "      <td>17.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>45.71</td>\n",
       "      <td>28.73</td>\n",
       "      <td>28.67</td>\n",
       "      <td>20.19</td>\n",
       "      <td>18.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>405.6</td>\n",
       "      <td>405.6</td>\n",
       "      <td>https://www.fanduel.com/entry/DIQGFYVFA</td>\n",
       "      <td>452.25</td>\n",
       "      <td>6847</td>\n",
       "      <td>8</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22.55</td>\n",
       "      <td>24.45</td>\n",
       "      <td>21.60</td>\n",
       "      <td>11.85</td>\n",
       "      <td>16.10</td>\n",
       "      <td>26.71</td>\n",
       "      <td>32.05</td>\n",
       "      <td>35.30</td>\n",
       "      <td>21.48</td>\n",
       "      <td>26.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>368.9</td>\n",
       "      <td>368.9</td>\n",
       "      <td>https://www.fanduel.com/entry/DKSLHBTZZ</td>\n",
       "      <td>345.00</td>\n",
       "      <td>6723</td>\n",
       "      <td>6</td>\n",
       "      <td>104.5</td>\n",
       "      <td>...</td>\n",
       "      <td>26.55</td>\n",
       "      <td>16.70</td>\n",
       "      <td>26.60</td>\n",
       "      <td>9.65</td>\n",
       "      <td>12.55</td>\n",
       "      <td>30.25</td>\n",
       "      <td>20.12</td>\n",
       "      <td>28.68</td>\n",
       "      <td>22.50</td>\n",
       "      <td>16.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>389.4</td>\n",
       "      <td>299.0</td>\n",
       "      <td>https://www.fanduel.com/entry/DRSQNBBEN</td>\n",
       "      <td>392.00</td>\n",
       "      <td>6835</td>\n",
       "      <td>8</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>16.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.50</td>\n",
       "      <td>18.05</td>\n",
       "      <td>34.70</td>\n",
       "      <td>29.90</td>\n",
       "      <td>25.74</td>\n",
       "      <td>25.12</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>432.1</td>\n",
       "      <td>331.6</td>\n",
       "      <td>https://www.fanduel.com/entry/DSSZBCGCV</td>\n",
       "      <td>453.75</td>\n",
       "      <td>6728</td>\n",
       "      <td>14</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>17.25</td>\n",
       "      <td>23.60</td>\n",
       "      <td>23.60</td>\n",
       "      <td>18.90</td>\n",
       "      <td>30.30</td>\n",
       "      <td>24.35</td>\n",
       "      <td>34.43</td>\n",
       "      <td>25.62</td>\n",
       "      <td>21.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>401.7</td>\n",
       "      <td>319.5</td>\n",
       "      <td>https://www.fanduel.com/entry/ECXCSUKYP</td>\n",
       "      <td>411.00</td>\n",
       "      <td>6712</td>\n",
       "      <td>8</td>\n",
       "      <td>119.5</td>\n",
       "      <td>...</td>\n",
       "      <td>21.05</td>\n",
       "      <td>19.70</td>\n",
       "      <td>25.80</td>\n",
       "      <td>18.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>30.98</td>\n",
       "      <td>27.50</td>\n",
       "      <td>35.70</td>\n",
       "      <td>23.14</td>\n",
       "      <td>21.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>403.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>https://www.fanduel.com/entry/ENBHXQOQW</td>\n",
       "      <td>471.25</td>\n",
       "      <td>6725</td>\n",
       "      <td>16</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.60</td>\n",
       "      <td>20.30</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>21.50</td>\n",
       "      <td>25.98</td>\n",
       "      <td>24.73</td>\n",
       "      <td>21.48</td>\n",
       "      <td>26.15</td>\n",
       "      <td>28.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>387.0</td>\n",
       "      <td>320.3</td>\n",
       "      <td>https://www.fanduel.com/entry/ENCSBZUFA</td>\n",
       "      <td>389.00</td>\n",
       "      <td>6782</td>\n",
       "      <td>8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.80</td>\n",
       "      <td>29.55</td>\n",
       "      <td>12.00</td>\n",
       "      <td>24.20</td>\n",
       "      <td>18.45</td>\n",
       "      <td>31.56</td>\n",
       "      <td>36.27</td>\n",
       "      <td>17.21</td>\n",
       "      <td>31.78</td>\n",
       "      <td>32.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>425.9</td>\n",
       "      <td>425.9</td>\n",
       "      <td>https://www.fanduel.com/entry/ENCVRBSZG</td>\n",
       "      <td>431.25</td>\n",
       "      <td>6887</td>\n",
       "      <td>14</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>14.70</td>\n",
       "      <td>19.10</td>\n",
       "      <td>15.90</td>\n",
       "      <td>21.85</td>\n",
       "      <td>34.09</td>\n",
       "      <td>24.90</td>\n",
       "      <td>30.90</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>390.3</td>\n",
       "      <td>297.9</td>\n",
       "      <td>https://www.fanduel.com/entry/EPEWVBYLM</td>\n",
       "      <td>400.50</td>\n",
       "      <td>6738</td>\n",
       "      <td>12</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.20</td>\n",
       "      <td>22.30</td>\n",
       "      <td>18.80</td>\n",
       "      <td>17.95</td>\n",
       "      <td>19.70</td>\n",
       "      <td>30.60</td>\n",
       "      <td>28.52</td>\n",
       "      <td>24.24</td>\n",
       "      <td>22.49</td>\n",
       "      <td>22.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>396.5</td>\n",
       "      <td>309.7</td>\n",
       "      <td>https://www.fanduel.com/entry/ESLWMUFFR</td>\n",
       "      <td>439.25</td>\n",
       "      <td>6852</td>\n",
       "      <td>8</td>\n",
       "      <td>112.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34.85</td>\n",
       "      <td>16.75</td>\n",
       "      <td>20.40</td>\n",
       "      <td>17.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>45.71</td>\n",
       "      <td>28.73</td>\n",
       "      <td>28.67</td>\n",
       "      <td>20.19</td>\n",
       "      <td>18.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>389.3</td>\n",
       "      <td>307.8</td>\n",
       "      <td>https://www.fanduel.com/entry/FAMHHQPZE</td>\n",
       "      <td>439.25</td>\n",
       "      <td>6784</td>\n",
       "      <td>22</td>\n",
       "      <td>104.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22.20</td>\n",
       "      <td>19.10</td>\n",
       "      <td>21.25</td>\n",
       "      <td>17.70</td>\n",
       "      <td>19.25</td>\n",
       "      <td>25.90</td>\n",
       "      <td>31.43</td>\n",
       "      <td>25.23</td>\n",
       "      <td>23.60</td>\n",
       "      <td>25.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>classic</td>\n",
       "      <td>GPP</td>\n",
       "      <td>400.2</td>\n",
       "      <td>294.9</td>\n",
       "      <td>https://www.fanduel.com/entry/FEFSJEPVY</td>\n",
       "      <td>430.50</td>\n",
       "      <td>6882</td>\n",
       "      <td>20</td>\n",
       "      <td>111.5</td>\n",
       "      <td>...</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.40</td>\n",
       "      <td>18.30</td>\n",
       "      <td>18.40</td>\n",
       "      <td>15.40</td>\n",
       "      <td>28.85</td>\n",
       "      <td>27.30</td>\n",
       "      <td>26.00</td>\n",
       "      <td>24.28</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    style type  top_score  last_winning_score  \\\n",
       "0   2019-10-29  classic  GPP      333.8               256.0   \n",
       "1   2019-10-27  classic  GPP      405.4               320.2   \n",
       "2   2019-12-13  classic  GPP      402.7               318.9   \n",
       "3   2019-11-19  classic  GPP      383.9               383.9   \n",
       "4   2019-10-28  classic  GPP      393.1               307.8   \n",
       "5   2019-11-10  classic  GPP      402.2               318.4   \n",
       "6   2019-11-05  classic  GPP      392.1               293.8   \n",
       "7   2019-12-20  classic  GPP      380.6               380.6   \n",
       "8   2020-01-18  classic  GPP      454.3               345.2   \n",
       "9   2019-11-20  classic  GPP      389.3               389.3   \n",
       "10  2019-12-10  classic  GPP      419.0               322.1   \n",
       "11  2019-10-27  classic  GPP      407.0               407.0   \n",
       "12  2019-11-02  classic  GPP      432.1               432.1   \n",
       "13  2019-11-09  classic  GPP      378.0               314.3   \n",
       "14  2020-01-18  classic  GPP      443.4               443.4   \n",
       "15  2019-12-21  classic  GPP      415.7               334.7   \n",
       "16  2020-01-15  classic  GPP      405.9               405.9   \n",
       "17  2019-12-07  classic  GPP      381.4               381.4   \n",
       "18  2019-11-01  classic  GPP      402.9               301.7   \n",
       "19  2019-10-29  classic  GPP      331.5               256.6   \n",
       "20  2019-12-21  classic  GPP      414.9               350.3   \n",
       "21  2019-10-28  classic  GPP      386.8               386.8   \n",
       "22  2019-10-29  classic  GPP      324.8               324.8   \n",
       "23  2019-11-12  classic  GPP      376.8               294.4   \n",
       "24  2019-12-13  classic  GPP      405.1               405.1   \n",
       "25  2019-12-12  classic  GPP      398.6               398.6   \n",
       "26  2019-12-10  classic  GPP      405.6               405.6   \n",
       "27  2019-10-31  classic  GPP      368.9               368.9   \n",
       "28  2019-12-07  classic  GPP      389.4               299.0   \n",
       "29  2019-11-02  classic  GPP      432.1               331.6   \n",
       "30  2019-10-27  classic  GPP      401.7               319.5   \n",
       "31  2019-11-01  classic  GPP      403.0               403.0   \n",
       "32  2019-11-19  classic  GPP      387.0               320.3   \n",
       "33  2019-12-21  classic  GPP      425.9               425.9   \n",
       "34  2019-11-05  classic  GPP      390.3               297.9   \n",
       "35  2019-12-12  classic  GPP      396.5               309.7   \n",
       "36  2019-11-20  classic  GPP      389.3               307.8   \n",
       "37  2019-12-20  classic  GPP      400.2               294.9   \n",
       "\n",
       "                                       link  best-possible-score  slate_id  \\\n",
       "0   https://www.fanduel.com/entry/ACCBQBZGM               357.25      6719   \n",
       "1   https://www.fanduel.com/entry/AEFRESUNV               411.00      6712   \n",
       "2   https://www.fanduel.com/entry/AFWXUUGOG               453.00      6860   \n",
       "3   https://www.fanduel.com/entry/AHMNEMODE               389.00      6782   \n",
       "4   https://www.fanduel.com/entry/AMUDHQRDI               439.00      6716   \n",
       "5   https://www.fanduel.com/entry/AQAWZWZZJ               430.25      6757   \n",
       "6   https://www.fanduel.com/entry/AUURIZHRE               400.50      6738   \n",
       "7   https://www.fanduel.com/entry/AWZVCNOYW               430.50      6882   \n",
       "8   https://www.fanduel.com/entry/AXNJTEEKL               452.25      6987   \n",
       "9   https://www.fanduel.com/entry/BAFDQLUNA               439.25      6784   \n",
       "10  https://www.fanduel.com/entry/BCWSUZQKZ               452.25      6847   \n",
       "11  https://www.fanduel.com/entry/BNNHOXXWX               411.00      6712   \n",
       "12  https://www.fanduel.com/entry/BOPDEMEWV               453.75      6728   \n",
       "13  https://www.fanduel.com/entry/BPEJEINKO               394.00      6748   \n",
       "14  https://www.fanduel.com/entry/BRHVCMDFB               452.25      6987   \n",
       "15  https://www.fanduel.com/entry/BUNPHWIDC               431.25      6887   \n",
       "16  https://www.fanduel.com/entry/CAYBYOPAP               449.50      6980   \n",
       "17  https://www.fanduel.com/entry/CDPWYVKIR               392.00      6835   \n",
       "18  https://www.fanduel.com/entry/CNERQUOPA               471.25      6725   \n",
       "19  https://www.fanduel.com/entry/COGMDNIZQ               357.25      6719   \n",
       "20  https://www.fanduel.com/entry/CPXSQDING               431.25      6887   \n",
       "21  https://www.fanduel.com/entry/CTBPKRXDY               439.00      6716   \n",
       "22  https://www.fanduel.com/entry/CUDKRBNNU               357.25      6719   \n",
       "23  https://www.fanduel.com/entry/CVUMZZFYG               422.50      6760   \n",
       "24  https://www.fanduel.com/entry/CYMEDSFNE               453.00      6860   \n",
       "25  https://www.fanduel.com/entry/DCTKMOEQH               439.25      6852   \n",
       "26  https://www.fanduel.com/entry/DIQGFYVFA               452.25      6847   \n",
       "27  https://www.fanduel.com/entry/DKSLHBTZZ               345.00      6723   \n",
       "28  https://www.fanduel.com/entry/DRSQNBBEN               392.00      6835   \n",
       "29  https://www.fanduel.com/entry/DSSZBCGCV               453.75      6728   \n",
       "30  https://www.fanduel.com/entry/ECXCSUKYP               411.00      6712   \n",
       "31  https://www.fanduel.com/entry/ENBHXQOQW               471.25      6725   \n",
       "32  https://www.fanduel.com/entry/ENCSBZUFA               389.00      6782   \n",
       "33  https://www.fanduel.com/entry/ENCVRBSZG               431.25      6887   \n",
       "34  https://www.fanduel.com/entry/EPEWVBYLM               400.50      6738   \n",
       "35  https://www.fanduel.com/entry/ESLWMUFFR               439.25      6852   \n",
       "36  https://www.fanduel.com/entry/FAMHHQPZE               439.25      6784   \n",
       "37  https://www.fanduel.com/entry/FEFSJEPVY               430.50      6882   \n",
       "\n",
       "    team_count  team-med  ...  ('med-dfs', 'C')  ('med-dfs', 'PF')  \\\n",
       "0            6     107.5  ...             20.40              26.50   \n",
       "1            8     119.5  ...             21.05              19.70   \n",
       "2           18     110.0  ...             18.80              22.20   \n",
       "3            8     113.0  ...             29.80              29.55   \n",
       "4           22     104.5  ...             26.50              17.30   \n",
       "5           14     112.5  ...             25.55              14.20   \n",
       "6           12     110.5  ...             25.20              22.30   \n",
       "7           20     111.5  ...             22.05              21.40   \n",
       "8           18     115.5  ...             23.20              17.75   \n",
       "9           22     104.5  ...             22.20              19.10   \n",
       "10           8     110.5  ...             22.55              24.45   \n",
       "11           8     119.5  ...             21.05              19.70   \n",
       "12          14     109.0  ...             26.00              17.25   \n",
       "13           8     114.5  ...             28.40              20.30   \n",
       "14          18     115.5  ...             23.20              17.75   \n",
       "15          14     117.0  ...             25.00              14.70   \n",
       "16          20     111.0  ...             22.35              19.90   \n",
       "17           8     110.5  ...             20.20              16.10   \n",
       "18          16     108.0  ...             18.60              20.30   \n",
       "19           6     107.5  ...             20.40              26.50   \n",
       "20          14     117.0  ...             25.00              14.70   \n",
       "21          22     104.5  ...             26.50              17.30   \n",
       "22           6     107.5  ...             20.40              26.50   \n",
       "23          16     112.5  ...             24.10              21.00   \n",
       "24          18     110.0  ...             18.80              22.20   \n",
       "25           8     112.5  ...             34.85              16.75   \n",
       "26           8     110.5  ...             22.55              24.45   \n",
       "27           6     104.5  ...             26.55              16.70   \n",
       "28           8     110.5  ...             20.20              16.10   \n",
       "29          14     109.0  ...             26.00              17.25   \n",
       "30           8     119.5  ...             21.05              19.70   \n",
       "31          16     108.0  ...             18.60              20.30   \n",
       "32           8     113.0  ...             29.80              29.55   \n",
       "33          14     117.0  ...             25.00              14.70   \n",
       "34          12     110.5  ...             25.20              22.30   \n",
       "35           8     112.5  ...             34.85              16.75   \n",
       "36          22     104.5  ...             22.20              19.10   \n",
       "37          20     111.5  ...             22.05              21.40   \n",
       "\n",
       "    ('med-dfs', 'PG')  ('med-dfs', 'SF')  ('med-dfs', 'SG')  \\\n",
       "0               19.90              14.60              16.10   \n",
       "1               25.80              18.00              12.80   \n",
       "2               16.10              17.35              16.85   \n",
       "3               12.00              24.20              18.45   \n",
       "4               17.10              20.75              20.70   \n",
       "5               23.40              15.70              18.70   \n",
       "6               18.80              17.95              19.70   \n",
       "7               18.30              18.40              15.40   \n",
       "8               17.65              16.80              18.30   \n",
       "9               21.25              17.70              19.25   \n",
       "10              21.60              11.85              16.10   \n",
       "11              25.80              18.00              12.80   \n",
       "12              23.60              23.60              18.90   \n",
       "13              19.65              22.40              23.55   \n",
       "14              17.65              16.80              18.30   \n",
       "15              19.10              15.90              21.85   \n",
       "16              20.20              23.90              19.70   \n",
       "17              22.10              21.50              18.05   \n",
       "18              12.00              18.80              21.50   \n",
       "19              19.90              14.60              16.10   \n",
       "20              19.10              15.90              21.85   \n",
       "21              17.10              20.75              20.70   \n",
       "22              19.90              14.60              16.10   \n",
       "23              23.65              15.75              17.50   \n",
       "24              16.10              17.35              16.85   \n",
       "25              20.40              17.00              10.60   \n",
       "26              21.60              11.85              16.10   \n",
       "27              26.60               9.65              12.55   \n",
       "28              22.10              21.50              18.05   \n",
       "29              23.60              23.60              18.90   \n",
       "30              25.80              18.00              12.80   \n",
       "31              12.00              18.80              21.50   \n",
       "32              12.00              24.20              18.45   \n",
       "33              19.10              15.90              21.85   \n",
       "34              18.80              17.95              19.70   \n",
       "35              20.40              17.00              10.60   \n",
       "36              21.25              17.70              19.25   \n",
       "37              18.30              18.40              15.40   \n",
       "\n",
       "    ('70.0th-pctl-dfs', 'C')  ('70.0th-pctl-dfs', 'PF')  \\\n",
       "0                      23.45                      35.18   \n",
       "1                      30.98                      27.50   \n",
       "2                      27.60                      27.99   \n",
       "3                      31.56                      36.27   \n",
       "4                      34.44                      24.43   \n",
       "5                      33.78                      16.80   \n",
       "6                      30.60                      28.52   \n",
       "7                      28.85                      27.30   \n",
       "8                      30.12                      26.67   \n",
       "9                      25.90                      31.43   \n",
       "10                     26.71                      32.05   \n",
       "11                     30.98                      27.50   \n",
       "12                     30.30                      24.35   \n",
       "13                     33.87                      23.50   \n",
       "14                     30.12                      26.67   \n",
       "15                     34.09                      24.90   \n",
       "16                     27.75                      27.08   \n",
       "17                     34.70                      29.90   \n",
       "18                     25.98                      24.73   \n",
       "19                     23.45                      35.18   \n",
       "20                     34.09                      24.90   \n",
       "21                     34.44                      24.43   \n",
       "22                     23.45                      35.18   \n",
       "23                     31.10                      31.72   \n",
       "24                     27.60                      27.99   \n",
       "25                     45.71                      28.73   \n",
       "26                     26.71                      32.05   \n",
       "27                     30.25                      20.12   \n",
       "28                     34.70                      29.90   \n",
       "29                     30.30                      24.35   \n",
       "30                     30.98                      27.50   \n",
       "31                     25.98                      24.73   \n",
       "32                     31.56                      36.27   \n",
       "33                     34.09                      24.90   \n",
       "34                     30.60                      28.52   \n",
       "35                     45.71                      28.73   \n",
       "36                     25.90                      31.43   \n",
       "37                     28.85                      27.30   \n",
       "\n",
       "    ('70.0th-pctl-dfs', 'PG')  ('70.0th-pctl-dfs', 'SF')  \\\n",
       "0                       24.64                      21.06   \n",
       "1                       35.70                      23.14   \n",
       "2                       22.70                      28.30   \n",
       "3                       17.21                      31.78   \n",
       "4                       25.32                      25.69   \n",
       "5                       30.48                      23.92   \n",
       "6                       24.24                      22.49   \n",
       "7                       26.00                      24.28   \n",
       "8                       31.06                      27.45   \n",
       "9                       25.23                      23.60   \n",
       "10                      35.30                      21.48   \n",
       "11                      35.70                      23.14   \n",
       "12                      34.43                      25.62   \n",
       "13                      25.24                      33.36   \n",
       "14                      31.06                      27.45   \n",
       "15                      30.90                      25.00   \n",
       "16                      30.94                      31.20   \n",
       "17                      25.74                      25.12   \n",
       "18                      21.48                      26.15   \n",
       "19                      24.64                      21.06   \n",
       "20                      30.90                      25.00   \n",
       "21                      25.32                      25.69   \n",
       "22                      24.64                      21.06   \n",
       "23                      30.08                      22.02   \n",
       "24                      22.70                      28.30   \n",
       "25                      28.67                      20.19   \n",
       "26                      35.30                      21.48   \n",
       "27                      28.68                      22.50   \n",
       "28                      25.74                      25.12   \n",
       "29                      34.43                      25.62   \n",
       "30                      35.70                      23.14   \n",
       "31                      21.48                      26.15   \n",
       "32                      17.21                      31.78   \n",
       "33                      30.90                      25.00   \n",
       "34                      24.24                      22.49   \n",
       "35                      28.67                      20.19   \n",
       "36                      25.23                      23.60   \n",
       "37                      26.00                      24.28   \n",
       "\n",
       "    ('70.0th-pctl-dfs', 'SG')  \n",
       "0                       23.34  \n",
       "1                       21.72  \n",
       "2                       25.66  \n",
       "3                       32.15  \n",
       "4                       27.80  \n",
       "5                       25.10  \n",
       "6                       22.32  \n",
       "7                       25.00  \n",
       "8                       28.34  \n",
       "9                       25.82  \n",
       "10                      26.90  \n",
       "11                      21.72  \n",
       "12                      21.70  \n",
       "13                      28.59  \n",
       "14                      28.34  \n",
       "15                      28.58  \n",
       "16                      25.60  \n",
       "17                      22.95  \n",
       "18                      28.82  \n",
       "19                      23.34  \n",
       "20                      28.58  \n",
       "21                      27.80  \n",
       "22                      23.34  \n",
       "23                      25.60  \n",
       "24                      25.66  \n",
       "25                      18.04  \n",
       "26                      26.90  \n",
       "27                      16.95  \n",
       "28                      22.95  \n",
       "29                      21.70  \n",
       "30                      21.72  \n",
       "31                      28.82  \n",
       "32                      32.15  \n",
       "33                      28.58  \n",
       "34                      22.32  \n",
       "35                      18.04  \n",
       "36                      25.82  \n",
       "37                      25.00  \n",
       "\n",
       "[38 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training model_name='top-score' model_cols=None\n",
      "nba-fanduel-CLASSIC-GPP-top-score: model_cols=None\n",
      "R2 score: 0.2932414157168677\n",
      "RMSE score: 23.667681668712376\n",
      "MAE score: 3.8275693135691706\n",
      "\n",
      "training model_name='last-win-score' model_cols=None\n",
      "[WARNING] [2021-08-08 22:27:34,405:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 1. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:35,311:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 2. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:36,238:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 3. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:37,180:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 4. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:38,147:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 5. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:39,008:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 6. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:40,068:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 7. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:27:41,055:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 8. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:42,305:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 8. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:43,199:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 8. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:44,073:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 8. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:45,040:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 9. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:45,860:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 10. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:46,435:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 10. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:47,034:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 11. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:47,552:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 11. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:48,746:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 12. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:49,269:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 12. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:50,133:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 13. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:50,711:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 13. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:51,559:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 14. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:52,385:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 15. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:52,948:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 16. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:53,536:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 16. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:54,735:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 17. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:29:55,267:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 17. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:00,263:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:04,549:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:05,164:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:09,835:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:14,361:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:15,007:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:20,221:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 18. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:30:21,132:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 19. Number of dummy models: 1\n",
      "nba-fanduel-CLASSIC-GPP-last-win-score: model_cols=None\n",
      "R2 score: -0.7406924577566956\n",
      "RMSE score: 64.39086447914765\n",
      "MAE score: 7.678269512966548\n",
      "Explained variance = [0.8407337  0.05341273 0.03425763 0.02664039 0.01444173]\n",
      "Singular varlues = [135.17553643  34.07149935  27.28648083  24.06241054  17.71652299]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PCA data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.769518</td>\n",
       "      <td>-11.549619</td>\n",
       "      <td>-7.475629</td>\n",
       "      <td>-5.616018</td>\n",
       "      <td>-2.533813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.116680</td>\n",
       "      <td>6.724840</td>\n",
       "      <td>-6.625561</td>\n",
       "      <td>1.641092</td>\n",
       "      <td>9.451388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.120447</td>\n",
       "      <td>19.798526</td>\n",
       "      <td>-9.752971</td>\n",
       "      <td>6.138447</td>\n",
       "      <td>-2.604215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-28.380708</td>\n",
       "      <td>-6.511024</td>\n",
       "      <td>3.536096</td>\n",
       "      <td>1.595921</td>\n",
       "      <td>6.161089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.607584</td>\n",
       "      <td>0.593502</td>\n",
       "      <td>-0.009515</td>\n",
       "      <td>0.227469</td>\n",
       "      <td>0.924329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-14.875859</td>\n",
       "      <td>6.415105</td>\n",
       "      <td>8.290096</td>\n",
       "      <td>4.296557</td>\n",
       "      <td>2.259364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.607584</td>\n",
       "      <td>0.593502</td>\n",
       "      <td>-0.009515</td>\n",
       "      <td>0.227469</td>\n",
       "      <td>0.924329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-6.676256</td>\n",
       "      <td>-3.080116</td>\n",
       "      <td>-6.843391</td>\n",
       "      <td>-1.622420</td>\n",
       "      <td>1.485448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-28.380708</td>\n",
       "      <td>-6.511024</td>\n",
       "      <td>3.536096</td>\n",
       "      <td>1.595921</td>\n",
       "      <td>6.161089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-6.211125</td>\n",
       "      <td>3.113754</td>\n",
       "      <td>1.741940</td>\n",
       "      <td>-3.391269</td>\n",
       "      <td>-5.458839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-46.512970</td>\n",
       "      <td>9.305605</td>\n",
       "      <td>3.658049</td>\n",
       "      <td>-0.793069</td>\n",
       "      <td>-1.663827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.769518</td>\n",
       "      <td>-11.549619</td>\n",
       "      <td>-7.475629</td>\n",
       "      <td>-5.616018</td>\n",
       "      <td>-2.533813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-6.211125</td>\n",
       "      <td>3.113754</td>\n",
       "      <td>1.741940</td>\n",
       "      <td>-3.391269</td>\n",
       "      <td>-5.458839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>81.368804</td>\n",
       "      <td>-5.784080</td>\n",
       "      <td>14.461412</td>\n",
       "      <td>-1.687530</td>\n",
       "      <td>-0.188349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-27.847070</td>\n",
       "      <td>-0.625638</td>\n",
       "      <td>-3.595467</td>\n",
       "      <td>-2.841395</td>\n",
       "      <td>-1.133516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-14.970510</td>\n",
       "      <td>5.835039</td>\n",
       "      <td>9.862633</td>\n",
       "      <td>-3.080859</td>\n",
       "      <td>-3.843407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-25.424974</td>\n",
       "      <td>2.569704</td>\n",
       "      <td>-0.251017</td>\n",
       "      <td>-4.300455</td>\n",
       "      <td>4.059698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-27.847070</td>\n",
       "      <td>-0.625638</td>\n",
       "      <td>-3.595467</td>\n",
       "      <td>-2.841395</td>\n",
       "      <td>-1.133516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-12.021760</td>\n",
       "      <td>-11.826573</td>\n",
       "      <td>-1.194102</td>\n",
       "      <td>19.458821</td>\n",
       "      <td>-4.874601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4\n",
       "0   14.769518 -11.549619  -7.475629  -5.616018 -2.533813\n",
       "1   31.116680   6.724840  -6.625561   1.641092  9.451388\n",
       "2   36.120447  19.798526  -9.752971   6.138447 -2.604215\n",
       "3  -28.380708  -6.511024   3.536096   1.595921  6.161089\n",
       "4   33.607584   0.593502  -0.009515   0.227469  0.924329\n",
       "5  -14.875859   6.415105   8.290096   4.296557  2.259364\n",
       "6   33.607584   0.593502  -0.009515   0.227469  0.924329\n",
       "7   -6.676256  -3.080116  -6.843391  -1.622420  1.485448\n",
       "8  -28.380708  -6.511024   3.536096   1.595921  6.161089\n",
       "9   -6.211125   3.113754   1.741940  -3.391269 -5.458839\n",
       "10 -46.512970   9.305605   3.658049  -0.793069 -1.663827\n",
       "11  14.769518 -11.549619  -7.475629  -5.616018 -2.533813\n",
       "12  -6.211125   3.113754   1.741940  -3.391269 -5.458839\n",
       "13  81.368804  -5.784080  14.461412  -1.687530 -0.188349\n",
       "14 -27.847070  -0.625638  -3.595467  -2.841395 -1.133516\n",
       "15 -14.970510   5.835039   9.862633  -3.080859 -3.843407\n",
       "16 -25.424974   2.569704  -0.251017  -4.300455  4.059698\n",
       "17 -27.847070  -0.625638  -3.595467  -2.841395 -1.133516\n",
       "18 -12.021760 -11.826573  -1.194102  19.458821 -4.874601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.120447</td>\n",
       "      <td>19.798526</td>\n",
       "      <td>-9.752971</td>\n",
       "      <td>6.138447</td>\n",
       "      <td>-2.604215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28.182723</td>\n",
       "      <td>6.774693</td>\n",
       "      <td>2.851398</td>\n",
       "      <td>-2.089087</td>\n",
       "      <td>-4.906184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.676256</td>\n",
       "      <td>-3.080116</td>\n",
       "      <td>-6.843391</td>\n",
       "      <td>-1.622420</td>\n",
       "      <td>1.485448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.021760</td>\n",
       "      <td>-11.826573</td>\n",
       "      <td>-1.194102</td>\n",
       "      <td>19.458821</td>\n",
       "      <td>-4.874601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.875859</td>\n",
       "      <td>6.415105</td>\n",
       "      <td>8.290096</td>\n",
       "      <td>4.296557</td>\n",
       "      <td>2.259364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.624491</td>\n",
       "      <td>3.768904</td>\n",
       "      <td>0.906789</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>-3.006185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6.676256</td>\n",
       "      <td>-3.080116</td>\n",
       "      <td>-6.843391</td>\n",
       "      <td>-1.622420</td>\n",
       "      <td>1.485448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68.307209</td>\n",
       "      <td>7.731451</td>\n",
       "      <td>4.179065</td>\n",
       "      <td>-6.567364</td>\n",
       "      <td>-8.371033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.955950</td>\n",
       "      <td>-6.798816</td>\n",
       "      <td>3.969407</td>\n",
       "      <td>0.206886</td>\n",
       "      <td>4.368332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68.307209</td>\n",
       "      <td>7.731451</td>\n",
       "      <td>4.179065</td>\n",
       "      <td>-6.567364</td>\n",
       "      <td>-8.371033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.417769</td>\n",
       "      <td>-1.930354</td>\n",
       "      <td>-0.732568</td>\n",
       "      <td>-2.334542</td>\n",
       "      <td>-5.021231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-28.182723</td>\n",
       "      <td>6.774693</td>\n",
       "      <td>2.851398</td>\n",
       "      <td>-2.089087</td>\n",
       "      <td>-4.906184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-46.512970</td>\n",
       "      <td>9.305605</td>\n",
       "      <td>3.658049</td>\n",
       "      <td>-0.793069</td>\n",
       "      <td>-1.663827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-14.970510</td>\n",
       "      <td>5.835039</td>\n",
       "      <td>9.862633</td>\n",
       "      <td>-3.080859</td>\n",
       "      <td>-3.843407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.307209</td>\n",
       "      <td>7.731451</td>\n",
       "      <td>4.179065</td>\n",
       "      <td>-6.567364</td>\n",
       "      <td>-8.371033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-26.074433</td>\n",
       "      <td>-5.618493</td>\n",
       "      <td>-0.557620</td>\n",
       "      <td>-1.622835</td>\n",
       "      <td>-5.985752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24.624491</td>\n",
       "      <td>3.768904</td>\n",
       "      <td>0.906789</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>-3.006185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-26.074433</td>\n",
       "      <td>-5.618493</td>\n",
       "      <td>-0.557620</td>\n",
       "      <td>-1.622835</td>\n",
       "      <td>-5.985752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.769518</td>\n",
       "      <td>-11.549619</td>\n",
       "      <td>-7.475629</td>\n",
       "      <td>-5.616018</td>\n",
       "      <td>-2.533813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2          3         4\n",
       "0   36.120447  19.798526 -9.752971   6.138447 -2.604215\n",
       "1  -28.182723   6.774693  2.851398  -2.089087 -4.906184\n",
       "2   -6.676256  -3.080116 -6.843391  -1.622420  1.485448\n",
       "3  -12.021760 -11.826573 -1.194102  19.458821 -4.874601\n",
       "4  -14.875859   6.415105  8.290096   4.296557  2.259364\n",
       "5   24.624491   3.768904  0.906789   0.194624 -3.006185\n",
       "6   -6.676256  -3.080116 -6.843391  -1.622420  1.485448\n",
       "7   68.307209   7.731451  4.179065  -6.567364 -8.371033\n",
       "8   -4.955950  -6.798816  3.969407   0.206886  4.368332\n",
       "9   68.307209   7.731451  4.179065  -6.567364 -8.371033\n",
       "10   2.417769  -1.930354 -0.732568  -2.334542 -5.021231\n",
       "11 -28.182723   6.774693  2.851398  -2.089087 -4.906184\n",
       "12 -46.512970   9.305605  3.658049  -0.793069 -1.663827\n",
       "13 -14.970510   5.835039  9.862633  -3.080859 -3.843407\n",
       "14  68.307209   7.731451  4.179065  -6.567364 -8.371033\n",
       "15 -26.074433  -5.618493 -0.557620  -1.622835 -5.985752\n",
       "16  24.624491   3.768904  0.906789   0.194624 -3.006185\n",
       "17 -26.074433  -5.618493 -0.557620  -1.622835 -5.985752\n",
       "18  14.769518 -11.549619 -7.475629  -5.616018 -2.533813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model_name='top-score-pca' model_cols=None\n",
      "nba-fanduel-CLASSIC-GPP-top-score-pca: model_cols=None\n",
      "R2 score: 0.34804979239564315\n",
      "RMSE score: 22.731462968816587\n",
      "MAE score: 3.7191737909118063\n",
      "training model_name='last-win-score-pca' model_cols=None\n",
      "[WARNING] [2021-08-08 22:47:28,244:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 1. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:28,902:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 2. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:29,444:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 3. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:30,056:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 4. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:30,611:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 5. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:31,200:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 6. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:31,833:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 7. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:32,368:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 8. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:32,894:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 8. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:33,546:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 9. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:34,124:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 9. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:35,060:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 10. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:35,778:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 11. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:36,358:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 12. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:36,967:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 13. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:37,545:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 13. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:38,112:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 13. Number of dummy models: 1\n",
      "[WARNING] [2021-08-08 22:47:38,630:Client-EnsembleBuilder] No models better than random - using Dummy loss!Number of models besides current dummy model: 13. Number of dummy models: 1\n",
      "nba-fanduel-CLASSIC-GPP-last-win-score-pca: model_cols=None\n",
      "R2 score: -1.0282135700365211\n",
      "RMSE score: 69.50564438297941\n",
      "MAE score: 7.929751690304831\n",
      "\n",
      "training model_name='top-score' model_cols={'best-possible-score'}\n"
     ]
    }
   ],
   "source": [
    "# normal test run\n",
    "TRAIN_TIME = 600\n",
    "PER_RUN_TIME_LIMIT = 120\n",
    "STYLE = ContestStyle.CLASSIC\n",
    "\n",
    "SPORT = 'nba'\n",
    "SERVICE = 'fanduel'\n",
    "\n",
    "models = {}\n",
    "\n",
    "for contest_type in [GeneralPrizePool, FiftyFifty]:\n",
    "    df = load_csv(SPORT, SERVICE, STYLE, contest_type)\n",
    "    with pd.option_context('max_rows', 1000, 'max_columns', 100):\n",
    "        print(f\"{len(df)} rows\")\n",
    "    display(df)        \n",
    "\n",
    "    # generate 6 models, top and last winning score models \n",
    "    # using 1) all data columns, 2) pca reduction of all data and 3) just the best possible score\n",
    "    for model_cols in [None, {'best-possible-score'}]:\n",
    "        model_data = generate_train_test(\n",
    "            df,\n",
    "            model_cols=model_cols,\n",
    "            random_state=5,\n",
    "        )\n",
    "        \n",
    "        if model_data is None or len(model_data[0]) < 5:\n",
    "            print(\"Not enough training data available!\")\n",
    "            continue\n",
    "            \n",
    "        (X_train, X_test, y_top_train, y_top_test,\n",
    "         y_last_win_train, y_last_win_test) = model_data\n",
    "        \n",
    "        model_ys = [\n",
    "            ('top-score', y_top_train, y_top_test), \n",
    "            ('last-win-score', y_last_win_train, y_last_win_test), \n",
    "        ]\n",
    "        # models for top and last winning score\n",
    "        for model_name, y_train, y_test in model_ys:\n",
    "            print()\n",
    "            print(f\"training {model_name=} {model_cols=}\")\n",
    "            model = automl(\n",
    "                X_train, y_train, X_test, y_test, model_name, \n",
    "                train_time=TRAIN_TIME,\n",
    "                per_run_time_limit=PER_RUN_TIME_LIMIT,\n",
    "                seed=1,\n",
    "                overwrite=True\n",
    "            )\n",
    "            model_desc = f\"{SPORT}-{SERVICE}-{STYLE.name}-{contest_type.NAME}-{model_name}: {model_cols=}\"\n",
    "            error_report(model, X_test, y_test, model_desc)\n",
    "            models[model_desc] = model\n",
    "            \n",
    "        # only pca models for when using all input data columns\n",
    "        if model_cols == {'best-possible-score'}:\n",
    "            continue\n",
    "                \n",
    "        X_train_pca, X_test_pca = pca_data(X_train, X_test)\n",
    "        display(\"PCA data\", X_train_pca, X_test_pca)    \n",
    "        \n",
    "        for model_name, y_train, y_test in model_ys:\n",
    "            model_name += '-pca'\n",
    "            print(f\"training {model_name=} {model_cols=}\")\n",
    "            model = automl(\n",
    "                X_train_pca, y_train, X_test_pca, y_test, model_name, \n",
    "                train_time=TRAIN_TIME,\n",
    "                per_run_time_limit=PER_RUN_TIME_LIMIT,\n",
    "                seed=1,\n",
    "                overwrite=True\n",
    "            )\n",
    "            model_desc = f\"{SPORT}-{SERVICE}-{STYLE.name}-{contest_type.NAME}-{model_name}: {model_cols=}\"\n",
    "            error_report(model, X_test_pca, y_test, model_desc)\n",
    "            models[model_desc] = model\n",
    "            \n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

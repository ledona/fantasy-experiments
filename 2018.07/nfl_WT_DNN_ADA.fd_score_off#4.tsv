{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xpt", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds"], "extra_stats": [], "model_player_stat": "fd_score_off#4", "model_team_stat": null, "player_stats": ["fumbles_lost", "receiving_rec", "receiving_tds", "receiving_twoptm", "receiving_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["passing_yds", "pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "/Users/delano/working/fantasy/MODELS_keras", "normalize": true, "player_pos": ["TE", "WR"]}, "datetime_utc": "20180725 074437", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.28.3-31-g1679bfa5", "filename_prefix": "nfl_WT_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 9000, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 523336406, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-4.6822881	0.1428582	tanh	0.5414340407	none	2	adagrad	2099	75	3	300	53
-4.5496236	0.1668936	tanh	0.5290569312	none	2	adagrad	6289	50	2	200	66
-5.0803972	-0.0921858	relu	0.4075805816	none	1	adadelta	8691	125	5	900	45
-4.4894809	0.1112571	sigmoid	0.39299395	none	4	adadelta	5594	125	5	1000	60
-4.604178	0.1202136	sigmoid	0.5077237159	none	3	adadelta	4168	25	1	100	59
-4.4112191	0.192644	sigmoid	0.6009791356	none	4	adagrad	7997	175	7	700	81
-4.4286416	0.1449455	tanh	0.5872777744	none	3	adadelta	6034	50	2	200	57
-4.5504863	0.0949897	tanh	0.7	none	5	adadelta	9000	25	1	100	100
-4.5494061	0.158931	sigmoid	0.6595269582	none	5	adadelta	9000	175	7	1000	38
-4.5771893	0.1133537	sigmoid	0.3847066534	none	5	adamax	9000	125	5	800	58
-4.4786859	0.2059662	linear	0.3226785208	none	1	adadelta	6285	175	7	700	29
-4.6008855	0.1541673	sigmoid	0.7	none	4	adagrad	9000	175	7	1000	20
-4.6394592	0.081779	sigmoid	0.3	none	5	adadelta	7981	175	7	1000	56
-4.4321109	0.2114684	linear	0.7	none	1	adam	6842	175	7	100	100
-4.4055508	0.2175813	linear	0.7	none	1	nadam	6588	175	7	400	100
-4.5764563	0.1777422	linear	0.7	none	1	adagrad	1510	175	7	1000	100
-4.8161776	-0.278589	relu	0.7	none	3	nadam	100	150	6	700	100
-4.9206471	-0.2575046	sigmoid	0.4988702926	none	5	adagrad	215	175	7	900	100
-4.6653775	0.1012435	tanh	0.6530646491	none	5	nadam	5687	25	1	1000	100
-4.5936473	0.1234071	linear	0.7	none	1	adadelta	9000	25	1	100	100
-4.4284026	0.2165292	linear	0.7	none	1	adamax	5571	175	7	1000	82
-4.4147035	0.2150821	sigmoid	0.7	none	1	adamax	5604	175	7	100	100
-4.5857062	0.1364503	tanh	0.6765231348	none	4	adagrad	7536	75	3	500	100
-4.5392287	0.1946678	sigmoid	0.7	none	1	nadam	5584	175	7	100	100
-4.5834292	0.1533225	tanh	0.3907104548	none	1	adamax	9000	175	7	100	95
-4.4613587	0.2136391	linear	0.3	none	1	adam	5499	175	7	1000	20
-4.6068476	0.1249869	linear	0.6437783218	none	1	adadelta	5379	25	1	800	25
-4.4786947	0.2087464	linear	0.7	none	2	adam	6341	175	7	100	100
-4.4409148	0.1999961	linear	0.7	none	2	adamax	6293	175	7	100	20
-4.720986	0.0668242	tanh	0.3	none	2	adadelta	6315	175	7	1000	100
-4.5179547	0.1653757	sigmoid	0.7	none	5	adagrad	7030	175	7	100	100
-4.3987952	0.2080303	linear	0.5922763898	none	1	adadelta	6411	175	7	100	56
-4.4754596	0.1983064	linear	0.584838646	none	1	adadelta	6349	175	7	100	55
-4.3644844	0.2164062	linear	0.7	none	1	adagrad	9000	175	7	100	100
-4.4313057	0.2172369	linear	0.7	none	1	adamax	8795	175	7	800	82
-4.4864767	0.1938019	tanh	0.7	none	1	adadelta	3144	175	7	1000	20
-4.4744707	0.1963852	tanh	0.7	none	1	adadelta	6577	175	7	100	63
-4.4312006	0.2167647	linear	0.4857325027	none	1	adamax	5663	175	7	100	20
-4.549242	0.1308009	tanh	0.3	none	1	adamax	5727	25	1	100	20
-4.5877799	0.1586259	sigmoid	0.4882233455	none	5	adadelta	5280	175	7	100	20
-4.4280326	0.2147319	linear	0.7	none	3	adamax	9000	175	7	100	74
-4.4348533	0.212751	sigmoid	0.7	none	1	adamax	9000	175	7	100	67
-4.473888	0.2012883	linear	0.7	none	3	adam	6492	175	7	100	62
-4.5089624	0.1825996	tanh	0.4200649199	none	1	adam	9000	175	7	100	20
-5.2751774	-0.0337271	relu	0.3	none	5	adagrad	100	25	1	1000	20
-4.4146161	0.2172358	linear	0.7	none	1	adamax	9000	175	7	500	100
-4.438671	0.2130754	linear	0.7	none	1	adadelta	9000	175	7	1000	100
-4.4123996	0.2172635	linear	0.7	none	1	adamax	9000	175	7	600	100
-4.4093148	0.2175986	linear	0.7	none	1	adamax	9000	175	7	900	100
-4.4135502	0.217019	linear	0.7	none	1	adamax	9000	175	7	700	100
-4.3738563	0.2157793	linear	0.7	none	1	adagrad	8863	175	7	200	91
-4.7025394	0.1051103	linear	0.7	none	5	adadelta	9000	25	1	100	20
-4.4172375	0.2155959	sigmoid	0.7	none	1	adagrad	9000	175	7	800	98
-4.4229668	0.2167376	linear	0.7	none	1	adamax	9000	175	7	100	20
-4.381375	0.2130632	linear	0.6262816568	none	1	adagrad	8799	175	7	100	100
-4.5082605	0.191906	sigmoid	0.5804067944	none	1	adamax	8173	175	7	500	100
-4.4157075	0.1962433	linear	0.7	none	1	adamax	7015	100	4	100	54
-4.3798756	0.2114593	linear	0.7	none	1	adagrad	8832	175	7	100	85
-4.4185846	0.2087019	linear	0.7	none	1	adamax	9000	100	4	1000	55
-4.4087072	0.2016234	linear	0.7	none	1	adadelta	7456	100	4	100	53
-4.3637693	0.2154046	linear	0.7	none	1	adagrad	9000	175	7	100	86
-4.4000098	0.1991092	linear	0.7	none	1	adadelta	7491	100	4	100	54
-4.3803846	0.2008147	linear	0.7	none	1	adamax	7514	100	4	100	54
-4.3658927	0.2161411	linear	0.7	none	1	adagrad	8733	175	7	100	86
-4.3746013	0.218638	linear	0.7	none	1	adagrad	8728	175	7	100	87
-4.4247776	0.2177069	linear	0.7	none	1	adamax	9000	175	7	400	90
-4.4230515	0.2179007	linear	0.7	none	1	adamax	9000	175	7	400	91
-4.4229668	0.2167376	linear	0.7	none	1	adamax	9000	175	7	100	20
-4.3724527	0.2158393	linear	0.7	none	1	adagrad	9000	175	7	100	95
-4.3745283	0.2161623	linear	0.7	none	1	adagrad	9000	175	7	100	94

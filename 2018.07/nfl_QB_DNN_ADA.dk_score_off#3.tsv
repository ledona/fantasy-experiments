{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_block_fg", "def_block_punt", "def_block_xpt", "def_fumble_recov", "def_fumble_recov_tds", "def_int", "def_int_tds", "def_sacks", "def_safety", "def_tds", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds", "pts", "turnovers", "yds"], "extra_stats": [], "model_player_stat": "dk_score_off#3", "model_team_stat": null, "player_stats": ["fumbles_lost", "passing_att", "passing_cmp", "passing_ints", "passing_tds", "passing_twoptm", "passing_yds", "rushing_att", "rushing_tds", "rushing_twoptm", "rushing_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["pts", "rushing_yds", "turnovers"]}, "impute": true, "models_path": "/Users/delano/working/fantasy/MODELS_keras", "normalize": true, "player_pos": ["QB"]}, "datetime_utc": "20180801 010145", "db_id": 1, "db_path": "nfl.db", "fantasy_version": "v0.28.6-135-g9582cc6f", "filename_prefix": "nfl_QB_DNN_ADA", "folds": 2, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 1750, "increment": 1, "low": 100, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 136104835, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-7.1764254	-0.0080332	relu	0.4123412568	none	2	nadam	697	198	6	700	95
-6.8916256	0.0725927	linear	0.4226879938	none	3	adam	989	198	6	200	80
-6.6189651	0.1793692	linear	0.3093468048	none	4	adam	1575	99	3	800	74
-7.2243736	-0.0033863	relu	0.5509403895	none	4	adadelta	1736	132	4	100	23
-6.9120181	0.0920535	sigmoid	0.3170784657	none	4	adamax	1598	66	2	700	85
-7.9872173	-0.2813694	relu	0.4160080282	none	4	adagrad	568	198	6	600	89
-6.7588569	0.1325542	sigmoid	0.6635179164	none	2	adagrad	943	198	6	900	39
-6.7900991	0.1639304	linear	0.3	none	5	adam	1750	33	1	1000	37
-6.7049491	0.1576727	tanh	0.3550079001	none	5	adagrad	1575	33	1	300	78
-6.786868	0.1423927	tanh	0.3	none	5	adagrad	1750	33	1	1000	71
-6.5903502	0.1689974	tanh	0.7	none	1	adagrad	994	66	2	200	100
-6.9482428	0.1248383	tanh	0.400887803	none	4	adagrad	1132	66	2	100	100
-6.6922325	0.157164	tanh	0.7	none	1	adagrad	1750	33	1	1000	20
-6.7186895	0.1636663	linear	0.7	none	1	adagrad	1750	33	1	1000	20
-6.7186895	0.1636663	linear	0.7	none	1	adagrad	1750	33	1	1000	20
-6.5479139	0.20165	linear	0.3	none	4	adam	1750	99	3	1000	62
-7.249583	-0.0038288	tanh	0.396557429	none	4	adam	1750	99	3	1000	76
-6.5400515	0.1987029	linear	0.4992669014	none	3	adadelta	1750	99	3	1000	89
-6.6982168	0.1806234	sigmoid	0.7	none	1	adagrad	966	33	1	100	100
-6.6268712	0.158531	linear	0.3794740041	none	4	adam	1750	198	6	1000	65
-12.6609723	-1.7323934	tanh	0.5993953874	none	1	adagrad	100	231	7	1000	20
-7.0838481	0.1238109	tanh	0.7	none	3	adagrad	1033	33	1	100	100
-6.6950783	0.189928	linear	0.3	none	1	adagrad	1434	33	1	1000	100
-7.4919052	-0.0286021	sigmoid	0.3859975063	none	5	adagrad	100	33	1	500	32
-6.6837301	0.1423632	linear	0.5422450893	none	1	adagrad	1243	132	4	1000	100
-6.6309841	0.1267274	tanh	0.6712919899	none	1	adagrad	961	99	3	100	93
-6.6099658	0.1847302	linear	0.3	none	1	adam	1750	132	4	1000	100
-6.7185231	0.1682423	linear	0.3	none	3	adadelta	1750	33	1	900	73
-6.7521756	0.1302398	tanh	0.4032150405	none	1	adagrad	1163	99	3	100	88
-6.8153763	0.16657	tanh	0.6980910757	none	2	adagrad	982	66	2	300	98
-6.4730541	0.2134666	linear	0.552401496	none	4	adagrad	1741	132	4	900	82
-6.5111056	0.1837874	linear	0.5040590001	none	5	adagrad	1743	132	4	400	68
-6.4867989	0.2017901	linear	0.5690519549	none	4	adagrad	1731	132	4	1000	88
-7.042612	0.0884521	relu	0.3	none	1	adagrad	1307	33	1	100	20
-6.8397032	0.1309121	linear	0.3	none	1	adagrad	1070	66	2	300	100
-6.9690681	0.0778809	linear	0.7	none	1	adadelta	1194	231	7	400	42
-6.7120344	0.1559276	sigmoid	0.5961504544	none	1	adagrad	730	33	1	1000	100
-6.590613	0.1813492	linear	0.4012296497	none	4	adagrad	1750	132	4	700	100
-6.6852116	0.1754692	linear	0.7	none	4	adam	1750	132	4	1000	32
-6.522523	0.1810952	linear	0.7	none	3	adagrad	1734	132	4	600	76
-6.6811274	0.1283441	sigmoid	0.7	none	2	adadelta	1750	165	5	1000	77
-6.555098	0.1745664	linear	0.5578291689	none	4	adagrad	1673	231	7	600	100
-6.9467708	0.0593507	tanh	0.4648265684	none	1	adagrad	963	198	6	700	100
-6.5464757	0.2072534	sigmoid	0.7	none	1	adagrad	930	99	3	200	100
-6.6957685	0.1168032	linear	0.7	none	1	adagrad	1526	231	7	1000	100
-6.6371912	0.1394867	linear	0.3	none	1	adagrad	1750	231	7	100	100
-6.7487147	0.1720714	linear	0.5699101182	none	5	adagrad	1750	33	1	100	100
-6.7158844	0.1829815	sigmoid	0.7	none	1	adagrad	961	165	5	1000	100
-6.5956126	0.1932121	sigmoid	0.7	none	1	adagrad	884	99	3	100	80
-6.6000426	0.1968109	sigmoid	0.7	none	1	adagrad	892	99	3	100	100
-6.5677722	0.1666856	linear	0.3	none	4	adagrad	1750	231	7	1000	100
-6.5143112	0.1970595	linear	0.3	none	1	adagrad	1629	132	4	1000	95
-6.6353899	0.1667477	sigmoid	0.7	none	1	adagrad	889	99	3	100	100
-6.6688391	0.142114	linear	0.3	none	5	adagrad	1750	231	7	1000	100
-6.6190149	0.166509	sigmoid	0.7	none	1	adagrad	897	99	3	100	76
-6.741176	0.1557849	sigmoid	0.7	none	1	adagrad	898	99	3	700	92
-6.6371912	0.1394867	linear	0.3	none	1	adagrad	1750	231	7	100	100
-6.6371912	0.1394867	linear	0.3	none	1	adagrad	1750	231	7	100	100
-6.6840379	0.1486842	linear	0.3	none	1	adagrad	1743	231	7	100	100
-6.6590819	0.1420845	linear	0.3	none	1	adagrad	1742	231	7	100	100
-6.6959183	0.1442188	linear	0.3	none	1	adagrad	1729	231	7	100	100
-6.6232106	0.1621994	linear	0.3	none	1	adagrad	1741	231	7	100	100
-6.618235	0.145221	linear	0.3	none	1	adagrad	1733	231	7	100	100
-6.6772714	0.1322629	linear	0.3	none	1	adagrad	1722	231	7	100	100
-6.6248066	0.1341048	linear	0.3	none	1	adagrad	1725	231	7	100	100
-6.6540951	0.152174	linear	0.3	none	1	adagrad	1713	231	7	100	100
-6.8016483	0.1130037	linear	0.3	none	1	adagrad	1707	231	7	100	100
-6.6918074	0.1324852	linear	0.4539627659	none	3	adagrad	1675	231	7	1000	100
-6.9745884	0.075975	relu	0.7	none	1	nadam	909	132	4	100	100
-6.6371912	0.1394867	linear	0.3	none	1	adagrad	1750	231	7	100	100

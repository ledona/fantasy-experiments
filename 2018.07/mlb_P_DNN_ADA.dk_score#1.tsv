{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["off_1b", "off_2b", "off_3b", "off_ab", "off_bb", "off_hbp", "off_hit", "off_hr", "off_k", "off_pa", "off_rbi", "off_rbi_w2", "off_rlob", "off_runs", "off_sac", "off_sac_f", "off_sac_h", "off_sb", "off_sb_c"], "extra_stats": ["home_C", "opp_l_hit_%_C", "opp_l_hit_%_H", "opp_r_hit_%_C", "opp_r_hit_%_H", "player_home_H", "player_win", "starter_phand_C", "team_home_H", "team_win", "venue_C", "venue_H"], "model_player_stat": "dk_score#1", "model_team_stat": null, "player_stats": ["p_bb", "p_cg", "p_er", "p_hbp", "p_hits", "p_hold", "p_hr", "p_ibb", "p_ip", "p_k", "p_loss", "p_pc", "p_po", "p_qs", "p_runs", "p_save", "p_strikes", "p_win", "p_wp"], "prev_opp_team_stats": [], "team_stats": ["errors", "p_runs", "p_save", "p_win"]}, "impute": true, "models_path": "/home/delano/working/fantasy/MODELS_keras", "normalize": true, "player_pos": ["P"]}, "datetime_utc": "20180719 053156", "db_id": 3, "db_path": "mlb.db", "fantasy_version": "v0.28.1-23-g8963287", "filename_prefix": "mlb_P_DNN_ADA", "folds": 3, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPConstantDist", "name": "hist_agg", "value": "none"}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 10000, "increment": 1, "low": 500, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 735576632, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2017, 2016, 2015, 2014]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-8.9041365	0.0593341	sigmoid	0.6487353099	none	1	adamax	9383	250	5	200	95
-9.1376326	0.0293092	linear	0.6154706984	none	3	adamax	2520	54	1	900	57
-10.1276848	-0.2231042	relu	0.4586464593	none	2	adamax	6276	250	5	900	75
-10.1896825	-0.2672902	linear	0.594893786	none	1	nadam	1437	299	6	100	78
-9.3938272	-0.0274179	linear	0.3195152313	none	4	adadelta	1903	250	5	100	76
-10.8258699	-0.3539295	relu	0.6137459223	none	4	adagrad	6900	250	5	100	82
-8.8779738	0.0436485	sigmoid	0.6369950237	none	1	nadam	4015	54	1	600	37
-10.1940981	-0.1996579	relu	0.5444597853	none	4	adam	7330	201	4	200	74
-10.3602112	-0.2464389	relu	0.6894054572	none	5	adagrad	5884	152	3	500	85
-9.6468981	-0.0879892	relu	0.3878086445	none	4	adagrad	3236	103	2	500	32
-10.739966	-0.3268322	relu	0.7	none	5	adagrad	9112	299	6	100	97
-11.1914528	-0.4338444	relu	0.689283625	none	4	adagrad	7406	250	5	100	92
-9.9649531	-0.1342658	relu	0.7	none	3	adagrad	10000	299	6	100	68
-11.1736678	-0.4129696	relu	0.6396250691	none	4	adagrad	6398	250	5	100	94
-11.1996848	-0.4291083	relu	0.6684335176	none	4	adagrad	6935	250	5	100	92
-11.2298108	-0.4287127	relu	0.6168701507	none	4	adagrad	5580	250	5	100	92
-10.8038293	-0.3344899	relu	0.482981248	none	4	adagrad	2634	152	3	100	92
-11.1926032	-0.4577673	relu	0.3933859264	none	5	adagrad	2279	250	5	100	92
-10.6380505	-0.2923826	relu	0.3913475677	none	4	adagrad	2588	250	5	100	92
-10.8779999	-0.3213809	relu	0.6718494473	none	4	adamax	5452	299	6	100	91
-11.376592	-0.4765988	relu	0.6730263218	none	4	adagrad	6525	299	6	100	100
-11.605506	-0.5134601	relu	0.3	none	5	adagrad	7780	348	7	100	100
-11.5605252	-0.5116242	relu	0.3	none	5	adagrad	10000	348	7	100	100
-11.266416	-0.4425177	relu	0.3	none	5	adagrad	10000	348	7	300	100
-11.5605252	-0.5116242	relu	0.3	none	5	adagrad	10000	348	7	100	100
-11.4013784	-0.4669333	relu	0.3	none	5	adagrad	9408	348	7	100	100
-11.5941474	-0.5092158	relu	0.3	none	5	adagrad	8914	348	7	100	100
-11.5706643	-0.4782706	relu	0.3	none	5	adagrad	6574	348	7	100	100
-10.2730762	-0.2728505	relu	0.3	none	5	adagrad	500	348	7	100	100
-11.5021325	-0.4598876	relu	0.3761491335	none	5	adagrad	6592	152	3	100	100
-11.2817257	-0.4657198	relu	0.3	none	5	adagrad	7563	348	7	100	100
-10.1047877	-0.1844991	relu	0.3	none	5	adagrad	8818	54	1	100	100
-11.4538196	-0.4843089	relu	0.325457258	none	5	adagrad	5923	250	5	100	100
-11.5004496	-0.4749018	relu	0.3	none	5	adagrad	6912	299	6	100	100
-11.7810219	-0.5664351	relu	0.4233663164	none	5	adagrad	6033	250	5	100	100
-11.7685221	-0.588799	relu	0.4480924159	none	5	adagrad	6213	250	5	100	100
-11.7785465	-0.5731823	relu	0.4506686359	none	5	adagrad	6079	250	5	100	100
-11.7199562	-0.5721684	relu	0.4481430506	none	5	adagrad	6185	250	5	100	100
-11.6700923	-0.5546785	relu	0.4498062055	none	5	adagrad	5961	250	5	100	100
-11.7153903	-0.5568863	relu	0.4439617329	none	5	adagrad	6133	250	5	100	100
-11.7932073	-0.5571106	relu	0.4436276835	none	5	adagrad	6090	250	5	100	100
-11.6583088	-0.553809	relu	0.4401668775	none	5	adagrad	6189	250	5	100	100
-11.8076852	-0.5695032	relu	0.4503848175	none	5	adagrad	5847	250	5	100	100
-11.7765359	-0.5727205	relu	0.4594547045	none	5	adagrad	5558	250	5	100	100
-11.7571502	-0.5585739	relu	0.4646940612	none	5	adagrad	5361	250	5	100	100
-11.6379161	-0.533208	relu	0.4674984415	none	5	adagrad	5354	201	4	100	100
-11.7659439	-0.5558497	relu	0.441407177	none	5	adagrad	6070	250	5	100	100
-11.6262338	-0.5500042	relu	0.4390256252	none	5	adagrad	6108	250	5	100	100
-11.697023	-0.5537611	relu	0.4497924656	none	5	adagrad	5858	250	5	100	100
-11.8075351	-0.5511274	relu	0.4488079652	none	5	adagrad	5863	250	5	100	100
-11.8328031	-0.5658389	relu	0.4484598168	none	5	adagrad	5846	250	5	100	100
-11.7763898	-0.5526922	relu	0.4492498325	none	5	adagrad	5825	250	5	100	100
-11.9508114	-0.5977708	relu	0.4628621106	none	5	adagrad	5889	299	6	100	100
-11.8736046	-0.5691682	relu	0.460865909	none	5	adagrad	5884	348	7	100	100
-11.8837105	-0.5753939	relu	0.4585607219	none	5	adagrad	5908	348	7	100	100
-12.0090466	-0.5972305	relu	0.4588359997	none	5	adagrad	5850	348	7	100	100
-11.9274493	-0.5778303	relu	0.4587547973	none	5	adagrad	5740	348	7	100	100
-11.9141821	-0.5714247	relu	0.4584591839	none	5	adagrad	5706	348	7	100	100
-11.862065	-0.5576393	relu	0.458346144	none	5	adagrad	5706	348	7	100	100
-11.7550349	-0.5797975	relu	0.4577832138	none	5	adagrad	5813	348	7	100	100
-11.8616706	-0.595121	relu	0.4591118379	none	5	adagrad	5907	348	7	100	100
-11.9452212	-0.6014031	relu	0.4591535465	none	5	adagrad	5875	348	7	100	100
-11.9007492	-0.5740805	relu	0.4589506451	none	5	adagrad	5880	348	7	100	100
-11.9627843	-0.5886233	relu	0.4589468302	none	5	adagrad	5867	348	7	100	100
-11.9798118	-0.5815562	relu	0.4587354147	none	5	adagrad	5870	348	7	100	100
-11.9561766	-0.6110317	relu	0.4581408623	none	5	adagrad	5878	348	7	100	100
-11.8672018	-0.59007	relu	0.4578167007	none	5	adagrad	5888	348	7	100	100
-11.9925667	-0.6066428	relu	0.4584643242	none	5	adagrad	5861	348	7	100	100
-11.8041128	-0.5840251	relu	0.4580533473	none	5	adagrad	5863	348	7	100	100
-11.8873793	-0.5678322	relu	0.4587318636	none	5	adagrad	5868	348	7	100	100

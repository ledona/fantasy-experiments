{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports book online historic odds data aggregation\n",
    "Combine sports book archive CSV files and betiq data into a single CSV\n",
    "file with columns that match fantasy odds retrieval.\n",
    "\n",
    "Files csv files will be retrieved from the `fantasy-archive/SPORT/sportsbook-odds` folder.\n",
    "\n",
    "Output files will be written to the same location as the \n",
    "source data. The filename will be \"sportsbook-odds-[SPORT].[SEASON_MIN]-[SEASON_MAX].[EXT]\"\n",
    "\n",
    "Output data will have one row per game with columns: 'date', 'season', 'away-team', 'home-team', 'away-moneyline', 'home-moneyline', 'overunder', 'spread'.\n",
    "All odds are american style. Spread if for a home win (so positive means home scores the spread more then away, negative is home scores the spread less)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "TESTING_RUN = False\n",
    "EXT: None | Literal[\"csv\", \"parquet\"] = \"parquet\" if not TESTING_RUN else None\n",
    "\"\"\"the output file extention and format\"\"\"\n",
    "\n",
    "VALID_RANGE = {\n",
    "    \"mlb\": {\"spread\": (1.5, 1.5), \"overunder\": (3, 18)},\n",
    "    \"nhl\": {\"spread\": (1.5, 1.5), \"overunder\": (2.5, 15)},\n",
    "    \"nfl\": {\"spread\": (0, 35), \"overunder\": (20, 85)},\n",
    "    \"nba\": {\"spread\": (0, 25), \"overunder\": (150, 300)},\n",
    "}\n",
    "\"\"\"absolute min/max values for validating things by sport\"\"\"\n",
    "\n",
    "# SPORT = \"mlb\"\n",
    "# SPORT = \"nba\"\n",
    "# SPORT = \"nfl\"\n",
    "SPORT = \"nhl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from functools import cache\n",
    "\n",
    "path_to_csv_files = os.path.join(os.environ[\"FANTASY_DATA_ARCHIVE_DIR\"], \"odds-archive\", SPORT)\n",
    "assert os.path.isdir(path_to_csv_files), f\"Ensure that csv data file path exists {path_to_csv_files=}\"\n",
    "csv_files = glob.glob(os.path.join(path_to_csv_files, \"*Sheet*.csv\"))\n",
    "print(\"CSV files that will be processed:\")\n",
    "print(\"\\n\".join(csv_files))\n",
    "\n",
    "team_abbrs_filepath = os.path.join(os.getcwd(), \"team_abbrs.json\")\n",
    "with open(team_abbrs_filepath, \"r\") as f_:\n",
    "    teamname_remap = json.load(f_)[SPORT]\n",
    "print(f\"Loaded {len(teamname_remap)} team abbr remaps for {SPORT}\")\n",
    "\n",
    "\n",
    "@cache\n",
    "def get_team_abbr(archive_team_name: str, season: int):\n",
    "    \"\"\"return a team abbreviation for the team name\"\"\"\n",
    "    if SPORT == \"nba\":\n",
    "        if archive_team_name == \"NewOrleans\":\n",
    "            # hornets up to 20122013, then the pelicans\n",
    "            return \"NOH\" if season <= 20122013 else \"NOP\"\n",
    "        if archive_team_name == \"Charlotte\":\n",
    "            # bobcats till 20132014, then hornets\n",
    "            return \"CHB\" if season <= 20132014 else \"CHA\"\n",
    "    return teamname_remap.get(archive_team_name, archive_team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import cast\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from dateutil.parser import parse as du_parse\n",
    "from fantasy_py import SPORT_DB_MANAGER_DOMAIN, CLSRegistry, GameScheduleEpoch, NotSeasonDateError\n",
    "from fantasy_py.sport import SportDBManager\n",
    "\n",
    "db_manager = cast(SportDBManager, CLSRegistry.get_class(SPORT_DB_MANAGER_DOMAIN, SPORT))\n",
    "\n",
    "\n",
    "def _date_str(\n",
    "    date_str: str, min_year_in_file: int | None = None, min_epoch: GameScheduleEpoch | None = None\n",
    "):\n",
    "    \"\"\"figure out the game date (as a string)\"\"\"\n",
    "    orig_date_4_str = (\"0\" if int(date_str) < 1000 else \"\") + str(date_str)\n",
    "    if min_year_in_file is not None:\n",
    "        return str(min_year_in_file) + orig_date_4_str\n",
    "\n",
    "    assert min_epoch is not None\n",
    "    new_date_str = str(min_epoch.date.year) + orig_date_4_str\n",
    "    try:\n",
    "        if db_manager.epoch_for_date(du_parse(new_date_str).date()).season == min_epoch.season:\n",
    "            return new_date_str\n",
    "    except (NotSeasonDateError, ValueError):\n",
    "        pass\n",
    "\n",
    "    new_date_str = str(min_epoch.date.year + 1) + orig_date_4_str\n",
    "    assert db_manager.epoch_for_date(du_parse(new_date_str).date()).season == min_epoch.season\n",
    "    return new_date_str\n",
    "\n",
    "\n",
    "def _inspect_file(filepath: str):\n",
    "    \"\"\"returns (season, index-of-header-row)\"\"\"\n",
    "    if SPORT == \"mlb\":\n",
    "        start_year_matches = re.findall(\"mlb-odds-([0-9]+).xls.*\", filepath)\n",
    "        season = int(start_year_matches[0])\n",
    "        min_season_epoch = db_manager.epoch_for_game_number(season, 1)\n",
    "        return min_season_epoch, 0\n",
    "\n",
    "    with open(filepath, \"r\") as f_:\n",
    "        info_row_str = f_.readline()\n",
    "        f_.readline()\n",
    "        first_row_str = f_.readline()\n",
    "\n",
    "    first_date_str = first_row_str.split(\",\")[0]\n",
    "\n",
    "    # line should be of the form '{SPORT} {YEARS}' where YEARS is YYYY | YYYY-YY\n",
    "    file_info_str = info_row_str.split(\",\", 1)[0]\n",
    "    assert file_info_str.lower().startswith(\n",
    "        SPORT + \" \"\n",
    "    ), f\"Expected file info string to start with '{SPORT} '. {file_info_str=}\"\n",
    "    years_str = file_info_str.split(\" \", 1)[1]\n",
    "    assert years_str.startswith(\n",
    "        \"20\"\n",
    "    ), f\"Expected years str to start with '20'. {file_info_str=} {years_str=}\"\n",
    "\n",
    "    years_split = years_str.split(\"-\")\n",
    "\n",
    "    if SPORT == \"nfl\":\n",
    "        season = int(years_split[0])\n",
    "        min_season_epoch = db_manager.epoch_for_game_number(season, 1)\n",
    "        return min_season_epoch, 1\n",
    "\n",
    "    # NBA|NHL years are of the form YYYY or YYYY-YY or YYYY-YYYY\n",
    "    min_file_year_str = years_split[0]\n",
    "    assert len(min_file_year_str) == 4\n",
    "    min_file_year = int(min_file_year_str)\n",
    "    if len(years_split) == 1:\n",
    "        # if there is only 1 year then the first date must be in it\n",
    "        first_date = du_parse(_date_str(first_date_str, min_file_year))\n",
    "        epoch = db_manager.epoch_for_date(first_date)\n",
    "        return epoch, 1\n",
    "\n",
    "    assert len(years_split) == 2, \"expecting 2 years\"\n",
    "    if len(years_split[1]) == 2:\n",
    "        max_file_year_str = \"20\" + years_split[1]\n",
    "    else:\n",
    "        assert len(years_split[1]) == 4\n",
    "        max_file_year_str = years_split[1]\n",
    "    assert int(min_file_year_str) + 1 == int(max_file_year_str), \"years should be consecutive\"\n",
    "    season = int(min_file_year_str + max_file_year_str)\n",
    "\n",
    "    # date must be either in the first year or following year, try first year and test against epoch\n",
    "    first_date = du_parse(_date_str(first_date_str, min_file_year))\n",
    "    epoch = db_manager.epoch_for_date(first_date)\n",
    "    if epoch.season == season:\n",
    "        return epoch, 1\n",
    "\n",
    "    first_date = du_parse(_date_str(first_date_str, min_file_year + 1))\n",
    "    epoch = db_manager.epoch_for_date(first_date)\n",
    "    assert epoch.season == season, \"seasons should match\"\n",
    "    return epoch, 1\n",
    "\n",
    "\n",
    "def parse_csv(filepath: str):\n",
    "    ref_epoch, header_row = _inspect_file(filepath)\n",
    "    print(f\"'{filepath}' {ref_epoch=} {header_row=}\")\n",
    "\n",
    "    df = pd.read_csv(filepath, header=header_row)\n",
    "\n",
    "    if SPORT in (\"mlb\", \"nhl\"):\n",
    "        df.columns = list(df.columns[:-4]) + [\n",
    "            \"OpenOU\",\n",
    "            \"OpenOU Odds\",\n",
    "            \"CloseOU\",\n",
    "            \"CloseOU Odds\",\n",
    "        ]\n",
    "    df.index = pd.Index(\n",
    "        df.Date.map(lambda date_str: _date_str(date_str, min_epoch=ref_epoch)),\n",
    "        name=\"date\",\n",
    "    )\n",
    "    return df.drop(columns=\"Date\"), ref_epoch.season\n",
    "\n",
    "\n",
    "seasons_to_file: dict[int, str] = {}\n",
    "\"\"\"season to filepath\"\"\"\n",
    "dfs: dict[str, pd.DataFrame] = {}\n",
    "\"\"\"filepath to data\"\"\"\n",
    "\n",
    "# read each file to a dataframe, drop header lines until the first line that starts with \"Date\"\n",
    "for filepath in tqdm.tqdm(csv_files, desc=\"loading\"):\n",
    "    try:\n",
    "        df, season = parse_csv(filepath)\n",
    "    except NotSeasonDateError as ex:\n",
    "        print(f\"Skipping {filepath=} due to season not being supported. {ex=}\")\n",
    "        continue\n",
    "    assert (\n",
    "        season not in seasons_to_file\n",
    "    ), f\"Found multiple files for {season=}. '{filepath}' , '{seasons_to_file[season]}'\"\n",
    "    # print(f\"Loading '{filepath}' {df.index[0]}-{df.index[-1]}\")\n",
    "    assert len(df) % 2 == 0, \"there should be an even number of rows\"\n",
    "    # print(df)\n",
    "    # concat to other dataframe\n",
    "    dfs[filepath] = df\n",
    "    seasons_to_file[season] = filepath\n",
    "\n",
    "first_filepath = next(iter(dfs.keys()))\n",
    "display(f\"sample ... {first_filepath}\", dfs[first_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "from fantasy_py import NotSeasonDateError, HomeAwayIter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def _xform_rows_mlb_nhl(rows: pd.DataFrame, away_row: int, home_row: int):\n",
    "    # money line is in the Close column\n",
    "    assert len(rows.Close) == 2, \"assuming that there is a favorite\"\n",
    "    ml = [float(val) for val in rows.Close.values]\n",
    "    assert len(rows.CloseOU.unique()) == 1, \"both OU close values should match\"\n",
    "    overunder = rows.CloseOU.iloc[0]\n",
    "    if overunder == \"NL\":\n",
    "        return (None, None, None, None, None)\n",
    "\n",
    "    if isinstance(overunder, str):\n",
    "        overunder = float(overunder.replace(\"½\", \".5\"))\n",
    "    over_odds_val = rows[\"CloseOU Odds\"].iloc[0]\n",
    "    if isinstance(over_odds_val, str) and over_odds_val[0] == \"a\":\n",
    "        over_odds_val = over_odds_val[1:]\n",
    "    over_odds = int(over_odds_val) if not pd.isna(over_odds_val) else None\n",
    "    try:\n",
    "        under_odds = int(rows[\"CloseOU Odds\"].iloc[1])\n",
    "    except ValueError:\n",
    "        under_odds = None\n",
    "\n",
    "    spread = 1.5 * (1 if ml[away_row] > ml[home_row] else -1)\n",
    "    return ml, spread, overunder, over_odds, under_odds\n",
    "\n",
    "\n",
    "def _xform_rows_nba_nfl(rows: pd.DataFrame, away_row: int, home_row: int):\n",
    "    \"\"\"get odds data for away/home rows for nba or nfl\"\"\"\n",
    "    # for nfl and nba in 'Close' the favored row has spread\n",
    "    # the underdog has overunder\n",
    "\n",
    "    ml = [int(ml_str) for ml_str in rows.ML.values] if \"NL\" not in rows.ML.values else None\n",
    "    if \"pk\" in rows.Close.values or \"PK\" in rows.Close.values:\n",
    "        # toss-up, so no spread. but there should be an overunder\n",
    "        spread = 0\n",
    "        overunder = float(\n",
    "            rows.iloc[away_row].Close\n",
    "            if rows.iloc[home_row].Close == \"pk\"\n",
    "            else rows.iloc[home_row].Close\n",
    "        )\n",
    "    else:\n",
    "        close = [float(close_str) for close_str in rows.Close.values]\n",
    "        if close[away_row] > close[home_row]:\n",
    "            overunder = close[away_row]\n",
    "            spread = close[home_row]\n",
    "        elif close[0] < close[home_row]:\n",
    "            overunder = close[home_row]\n",
    "            spread = close[away_row]\n",
    "        else:\n",
    "            raise ValueError(\"Close values should not be the same\")\n",
    "        if spread < 0:\n",
    "            display(rows)\n",
    "            print(\"Negative spread found, using abs\")\n",
    "            spread = abs(spread)\n",
    "    return ml, spread, overunder, None, None\n",
    "\n",
    "\n",
    "ROWS_FUNCS = {\n",
    "    \"mlb\": _xform_rows_mlb_nhl,\n",
    "    \"nhl\": _xform_rows_mlb_nhl,\n",
    "    \"nfl\": _xform_rows_nba_nfl,\n",
    "    \"nba\": _xform_rows_nba_nfl,\n",
    "}\n",
    "\"\"\"mapping of sport to row processing func\"\"\"\n",
    "\n",
    "\n",
    "def game_xform(\n",
    "    rows_xformer: Callable,\n",
    "    rows: pd.DataFrame,\n",
    "):\n",
    "    \"\"\"\n",
    "    rows_xformer: function with args (game_rows, away_row_idx, home_row_idx) -> (ml-list, ou, spread).\\\n",
    "        Game_rows is a dataframe with 2 rows containing home and away odds data,\\\n",
    "        and the other args are the indices for which row is home/away.\\\n",
    "        The returned values are ml-list: a list or 2 flows with the money line for the game, home/away\\\n",
    "        money line will be at index matching [away|home]_row_idx. ou and spread floats\n",
    "    \"\"\"\n",
    "    game_date = du_parse(rows.index[0]).date()\n",
    "    try:\n",
    "        assert len(rows) == 2, \"expecting 2 rows\"\n",
    "        if set(rows.VH) not in ({\"N\"}, {\"V\", \"H\"}):\n",
    "            raise ValueError(\n",
    "                f\"For {game_date}, expected rows to be order visitor, home, instead {rows.VH=}\"\n",
    "            )\n",
    "        away_row, home_row = (\n",
    "            (0, 1) if rows.VH.to_list() == [\"V\", \"H\"] or set(rows.VH) == {\"N\"} else (1, 0)\n",
    "        )\n",
    "\n",
    "        if \"Close\" in rows.columns and rows.Close.hasnans or (\"ML\" in rows and rows.ML.hasnans):\n",
    "            display(rows)\n",
    "            print(f\"Skipping game on {game_date} with NaN for close or ml\")\n",
    "            return None\n",
    "        if len(rows.index.unique()) > 1:\n",
    "            display(rows)\n",
    "            print(\n",
    "                f\"WARNING: expected all rows on {game_date} to be for the same date, these do not!\"\n",
    "            )\n",
    "        if \"Rot\" in rows.columns and (rows.Rot.iloc[0] + 1) != rows.Rot.iloc[1]:\n",
    "            display(rows)\n",
    "            print(f\"WARNING: the rotation numbers on {game_date} were not consecutive\")\n",
    "\n",
    "        try:\n",
    "            epoch = db_manager.epoch_for_date(game_date)\n",
    "        except:\n",
    "            if SPORT == \"nfl\" and game_date.weekday() in (1, 2):\n",
    "                print(f\"Skipping NFL odds on {game_date} cause it is a TUES/WED\")\n",
    "                # for NFL skip tuesday and wednesday games\n",
    "                return None\n",
    "            raise\n",
    "\n",
    "        ml, spread, overunder, over_odds, under_odds = rows_xformer(rows, away_row, home_row)\n",
    "        if ml is None and overunder is None and spread is None:\n",
    "            return None\n",
    "\n",
    "        new_row = {\n",
    "            \"date\": game_date,\n",
    "            \"season\": epoch.season,\n",
    "            \"away-team\": rows.iloc[away_row].Team,\n",
    "            \"away-abbr\": get_team_abbr(rows.iloc[away_row].Team, epoch.season),\n",
    "            \"home-team\": rows.iloc[home_row].Team,\n",
    "            \"home-abbr\": get_team_abbr(rows.iloc[home_row].Team, epoch.season),\n",
    "            \"away-moneyline\": ml[away_row] if ml is not None else None,\n",
    "            \"home-moneyline\": ml[home_row] if ml is not None else None,\n",
    "            \"overunder\": overunder,\n",
    "            \"over-odds\": over_odds,\n",
    "            \"under-odds\": under_odds,\n",
    "            \"spread\": spread,\n",
    "        }\n",
    "        assert len(new_row[\"home-abbr\"]) <= 3 and len(new_row[\"away-abbr\"]) <= 3, (\n",
    "            f\"on {game_date} expected all team abbreviations to have length <= 3, \"\n",
    "            f\"one of the following is too long: '{new_row[\"home-abbr\"]}', '{new_row[\"away-abbr\"]}'\"\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        display(f\"failed. {ex=} on the following rows:\")\n",
    "        display(rows)\n",
    "        raise\n",
    "    return pd.Series(new_row)\n",
    "\n",
    "\n",
    "def valid_test(filepath, df: pd.DataFrame):\n",
    "    \"\"\"validation testing on odds data by dropping/setting to NA any value\n",
    "    outside of the valid range for a column\"\"\"\n",
    "\n",
    "    def _test_val(stat_name, valid_min, valid_max):\n",
    "        \"\"\"\n",
    "        test that the min and max of the stat_name columns\n",
    "        are within the valid range or is na. if all is well return None\n",
    "        otherwise return a new series with na for invalid values\n",
    "        \"\"\"\n",
    "        try:\n",
    "            min_val = abs(df[stat_name].dropna().min())\n",
    "            max_val = abs(df[stat_name].dropna().max())\n",
    "        except:\n",
    "            print(f\"Failed to get min/max for {stat_name=}\")\n",
    "            raise\n",
    "\n",
    "        assert pd.notna(\n",
    "            min_val\n",
    "        ), f\"failed on {stat_name}, {min_val=}, {df[stat_name].dropna().min()=}\"\n",
    "\n",
    "        if min_val >= valid_min and max_val <= valid_max:\n",
    "            return None\n",
    "\n",
    "        updates_df = pd.DataFrame(\n",
    "            df[stat_name]\n",
    "            .map(\n",
    "                lambda val: (\n",
    "                    [val, 0] if (pd.isna(val) or valid_min <= val <= valid_max) else [None, 1]\n",
    "                )\n",
    "            )\n",
    "            .tolist(),\n",
    "            columns=[stat_name, \"nulled\"],\n",
    "        )\n",
    "        nulled_vals = updates_df.nulled.sum()\n",
    "        print(\n",
    "            f\"In '{filepath}' {stat_name} has out of range values.\"\n",
    "            f\"abs(min, max) = [{float(min_val)} : {float(max_val)}] \"\n",
    "            f\"valid range = [{valid_min} : {valid_max}]. \"\n",
    "            f\"{nulled_vals} out of range values nulled\"\n",
    "        )\n",
    "\n",
    "        assert (\n",
    "            nulled_vals > 0\n",
    "        ), f\"Found values out of range for {filepath=} {stat_name=} but nothing was nulled!\"\n",
    "        return updates_df[stat_name]\n",
    "\n",
    "    for stat in [\"spread\", \"overunder\"]:\n",
    "        if (updates := _test_val(stat, *VALID_RANGE[SPORT][stat])) is not None:\n",
    "            df = df.assign(**{stat: updates})\n",
    "    for ha in HomeAwayIter:\n",
    "        if (updates := _test_val(f\"{ha}-moneyline\", 100, 15000)) is not None:\n",
    "            df = df.assign(**{f\"{ha}-moneyline\": updates})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dfs = []\n",
    "apply_func = partial(game_xform, ROWS_FUNCS[SPORT])\n",
    "for filepath, df in (progress := tqdm(dfs.items(), desc=\"files\", total=len(dfs))):\n",
    "    progress.set_postfix_str(filepath)\n",
    "    tqdm.pandas(desc=\"games\")\n",
    "    try:\n",
    "        group_by = df.groupby(np.arange(len(df)) // 2)\n",
    "        game_xformed_df = cast(\n",
    "            pd.DataFrame, group_by.progress_apply(apply_func).set_index(\"date\")\n",
    "        ).query(\"season.notna()\")\n",
    "        xformed_df = game_xformed_df.sort_index()\n",
    "        validated_df = valid_test(filepath, xformed_df)\n",
    "        odds_dfs.append(validated_df)\n",
    "    except NotSeasonDateError as ex:\n",
    "        display(f\"Skipping '{filepath}' data not in a fantasy season: {ex}\")\n",
    "        continue\n",
    "    except Exception as ex:\n",
    "        display(f\"Unhandled error for {filepath}... STOPPING EVERYTHING! {ex=}\")\n",
    "        raise\n",
    "\n",
    "    if TESTING_RUN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle nfl&mlb season 2022 data from betiq\n",
    "def _xform_betiq_rows(rows: pd.DataFrame, away_row: int, home_row: int):\n",
    "    \"\"\"get odds data for away/home rows betiq\"\"\"\n",
    "    assert {away_row, home_row} == {0, 1}\n",
    "    if [away_row, home_row] == [0, 1]:\n",
    "        ml = rows[\"Money Line\"]\n",
    "    else:\n",
    "        ml = rows.iloc[::-1][\"Money Line\"]\n",
    "    overunder, spread = rows.iloc[0][[\"Total (O/U)\", \"Spread\"]]\n",
    "    return list(ml), spread, overunder, None, None\n",
    "\n",
    "\n",
    "def _betiq_sortable_col(row: pd.Series):\n",
    "    \"\"\"\n",
    "    construct a column that betiq data can be sorted by to\n",
    "    ensure home/away rows are consecutive\n",
    "    \"\"\"\n",
    "    team_1 = row.Team if row.Team < row.Opponent else row.Opponent\n",
    "    score = row.Score if row.Team == team_1 else \"-\".join(reversed(row.Score.split(\"-\")))\n",
    "    return row.Date + \":\" + team_1 + \":\" + score\n",
    "\n",
    "\n",
    "if SPORT in (\"mlb\", \"nfl\"):\n",
    "    filepath = os.path.join(\n",
    "        os.environ[\"FANTASY_DATA_ARCHIVE_DIR\"], \"odds-archive\", SPORT, SPORT + \"-odds.betiq.tsv\"\n",
    "    )\n",
    "    betiq_df = pd.read_csv(filepath, sep=\"\\t\")\n",
    "    # display(\"betiq data from file\", betiq_df)\n",
    "\n",
    "    vh = betiq_df.Location.map(lambda ha: \"V\" if ha == \"Away\" else \"H\" if ha == \"Home\" else \"N\")\n",
    "    sortable_col = betiq_df.apply(_betiq_sortable_col, axis=1)\n",
    "    sortable_df = (\n",
    "        betiq_df.assign(VH=vh, sort_col=sortable_col).sort_values(\"sort_col\").set_index(\"Date\")\n",
    "    )\n",
    "    # display(\"sortable betiq data\", sortable_df)\n",
    "\n",
    "    group_by = sortable_df.groupby(np.arange(len(sortable_df)) // 2)\n",
    "    apply_func = partial(game_xform, _xform_betiq_rows)\n",
    "    xformed_df: pd.DataFrame = group_by.progress_apply(apply_func).set_index(\"date\").sort_index()\n",
    "    display(\"xformed df\", xformed_df)\n",
    "\n",
    "    validated_df = valid_test(filepath, xformed_df)\n",
    "    display(\n",
    "        f\"Validation dropped {len(xformed_df) - len(validated_df)} rows leaving {len(validated_df)} rows\"\n",
    "    )\n",
    "    display(\"clean betiq data\", validated_df)\n",
    "    odds_dfs.append(validated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df = pd.concat(odds_dfs)\n",
    "display(odds_df)\n",
    "print(\"------------------------ SUCCESS!!! -------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if EXT is not None:\n",
    "    sorted_df = odds_df.sort_index()\n",
    "    min_season = int(sorted_df.iloc[0].season)\n",
    "    max_season = int(sorted_df.iloc[-1].season)\n",
    "\n",
    "    dest_filepath = os.path.join(\n",
    "        os.environ[\"FANTASY_HOME\"], f\"{SPORT}.odds-archive.{min_season}-{max_season}.{EXT}\"\n",
    "    )\n",
    "    print(f\"writing data to '{dest_filepath}'\")\n",
    "    if EXT == \"parquet\":\n",
    "        odds_df.to_parquet(dest_filepath)\n",
    "    elif EXT == \"csv\":\n",
    "        odds_df.to_csv(dest_filepath)\n",
    "    else:\n",
    "        raise ValueError(f\"Don't know how to export to '{EXT}'\")\n",
    "else:\n",
    "    print(\"Not saving results...\")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports book online historic odds data aggregation\n",
    "Combine sports book online CSV files into a single CSV\n",
    "file with columns that match fantasy odds retrieval.\n",
    "\n",
    "Output files will be written to the same location as the \n",
    "source data. The filename will be \"sportsbook-odds-[SPORT].[SEASON_MIN]-[SEASON_MAX].[EXT]\"\n",
    "\n",
    "Output data will have one row per game with columns: 'date', 'season', 'away-team', 'home-team', 'away-moneyline', 'home-moneyline', 'overunder', 'spread'.\n",
    "All odds are american style. Spread if for a home win (so positive means home scores the spread more then away, negative is home scores the spread less)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "TESTING_RUN = False\n",
    "EXT: None | Literal[\"csv\", \"parquet\"] = \"parquet\" if not TESTING_RUN else None\n",
    "\"\"\"the output file extention and format\"\"\"\n",
    "\n",
    "VALID_RANGE = {\n",
    "    \"mlb\": {\"spread\": (1.5, 1.5), \"overunder\": (3, 15)},\n",
    "    \"nhl\": {\"spread\": (1.5, 1.5), \"overunder\": (2.5, 15)},\n",
    "    \"nfl\": {\"spread\": (0, 30), \"overunder\": (25, 85)},\n",
    "    \"nba\": {\"spread\": (0, 25), \"overunder\": (150, 275)},\n",
    "}\n",
    "# SPORT = \"mlb\"\n",
    "# SPORT = \"nba\"\n",
    "SPORT = \"nfl\"\n",
    "# SPORT = \"nhl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "path_to_csv_files = os.path.join(os.environ[\"FANTASY_ARCHIVE_BASE\"], SPORT, \"sportbook-odds\")\n",
    "assert os.path.isdir(path_to_csv_files)\n",
    "csv_files = glob.glob(os.path.join(path_to_csv_files, \"*Sheet*.csv\"))\n",
    "print(\"CSV files that will be processed:\")\n",
    "print(\"\\n\".join(csv_files))\n",
    "\n",
    "team_abbrs_filepath = os.path.join(os.getcwd(), \"team_abbrs.json\")\n",
    "with open(team_abbrs_filepath, \"r\") as f_:\n",
    "    teamname_remap = json.load(f_)[SPORT]\n",
    "print(f\"Loaded {len(teamname_remap)} team abbr remaps for {SPORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def _find_start_year(filepath: str):\n",
    "    if SPORT == \"mlb\":\n",
    "        start_year_matches = re.findall(\"mlb-odds-([0-9]+).xls.*\", filepath)\n",
    "        start_row = 0\n",
    "    else:\n",
    "        with open(filepath, \"r\") as f_:\n",
    "            l1 = f_.readline()\n",
    "        start_year_matches = re.findall(f\"{SPORT.upper()} (20..).*\", l1)\n",
    "        start_row = 1\n",
    "    assert len(start_year_matches) in (1, 2), f\"Find start-year for '{filepath}' in '{l1}'\"\n",
    "    return int(start_year_matches[0]), start_row\n",
    "\n",
    "\n",
    "def parse_csv(filepath: str):\n",
    "    start_year, start_row = _find_start_year(filepath)\n",
    "    df = pd.read_csv(filepath, header=start_row)\n",
    "\n",
    "    if SPORT in (\"mlb\", \"nhl\"):\n",
    "        df.columns = list(df.columns[:-4]) + [\n",
    "            \"OpenOU\",\n",
    "            \"OpenOU Odds\",\n",
    "            \"CloseOU\",\n",
    "            \"CloseOU Odds\",\n",
    "        ]\n",
    "\n",
    "    def _date(orig_date: str, first_date: str | None = None):\n",
    "        \"\"\"figure out the game date\"\"\"\n",
    "        orig_date_4 = (\"0\" if int(orig_date) < 1000 else \"\") + str(orig_date)\n",
    "        new_date = str(start_year) + orig_date_4\n",
    "        if first_date is None or (first_date is not None and new_date >= first_date):\n",
    "            return new_date\n",
    "        # the season calendar is in a new year, use the next year instead of start_year\n",
    "        return str(start_year + 1) + orig_date_4\n",
    "\n",
    "    row_1_date = _date(df.iloc[0].Date)\n",
    "    df.index = pd.Index(\n",
    "        df.Date.map(lambda date_str: _date(date_str, first_date=row_1_date)), name=\"date\"\n",
    "    )\n",
    "    return df.drop(columns=\"Date\")\n",
    "\n",
    "\n",
    "dfs: dict[str, pd.DataFrame] = {}\n",
    "# read each file to a dataframe, drop header lines until the first line that starts with \"Date\"\n",
    "for filepath in tqdm.tqdm(csv_files, desc=\"loading\"):\n",
    "    df = parse_csv(filepath)\n",
    "    # print(f\"Loading '{filepath}' {df.index[0]}-{df.index[-1]}\")\n",
    "    assert len(df) % 2 == 0, \"there should be an even number of rows\"\n",
    "    # print(df)\n",
    "\n",
    "    # concat to other dataframe\n",
    "    dfs[filepath] = df\n",
    "\n",
    "display(f\"sample ... {csv_files[0]}\", dfs[csv_files[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, cast\n",
    "\n",
    "import numpy as np\n",
    "from dateutil.parser import parse as du_parse\n",
    "from fantasy_py import SPORT_DB_MANAGER_DOMAIN, CLSRegistry, NotSeasonDateError\n",
    "from fantasy_py.sport import SportDBManager\n",
    "from tqdm import tqdm\n",
    "\n",
    "db_manager = cast(SportDBManager, CLSRegistry.get_class(SPORT_DB_MANAGER_DOMAIN, SPORT))\n",
    "\n",
    "\n",
    "def _xform_rows_mlb_nhl(rows: pd.DataFrame, away_row: int, home_row: int):\n",
    "    # money line is in the Close column\n",
    "    assert len(rows.Close) == 2, \"assuming that there is a favorite\"\n",
    "    ml = [float(val) for val in rows.Close.values]\n",
    "    assert len(rows.CloseOU.unique()) == 1, \"both OU close values should match\"\n",
    "    overunder = rows.CloseOU.iloc[0]\n",
    "    if isinstance(overunder, str):\n",
    "        overunder = float(overunder.replace(\"Â½\", \".5\"))\n",
    "    spread = 1.5 * (1 if ml[away_row] > ml[home_row] else -1)\n",
    "    return ml, overunder, spread\n",
    "\n",
    "\n",
    "def _xform_rows_nba_nfl(rows: pd.DataFrame, away_row: int, home_row: int):\n",
    "    \"\"\"get odds data for away/home rows for nba or nfl\"\"\"\n",
    "    # for nfl and nba in 'Close' the favored row has spread\n",
    "    # the underdog has overunder\n",
    "\n",
    "    ml = [int(ml_str) for ml_str in rows.ML.values] if \"NL\" not in rows.ML.values else None\n",
    "    if \"pk\" in rows.Close.values or \"PK\" in rows.Close.values:\n",
    "        # toss-up, so no spread. but there should be an overunder\n",
    "        spread = 0\n",
    "        overunder = float(\n",
    "            rows.iloc[away_row].Close\n",
    "            if rows.iloc[home_row].Close == \"pk\"\n",
    "            else rows.iloc[home_row].Close\n",
    "        )\n",
    "    else:\n",
    "        close = [float(close_str) for close_str in rows.Close.values]\n",
    "        if close[away_row] > close[home_row]:\n",
    "            overunder = close[away_row]\n",
    "            spread = close[home_row]\n",
    "        elif close[0] < close[home_row]:\n",
    "            overunder = close[home_row]\n",
    "            spread = close[away_row]\n",
    "        else:\n",
    "            raise ValueError(\"Close values should not be the same\")\n",
    "        if spread < 0:\n",
    "            display(rows)\n",
    "            print(\"Negative spread found, using abs\")\n",
    "            spread = abs(spread)\n",
    "    return ml, overunder, spread\n",
    "\n",
    "\n",
    "ROWS_FUNCS = {\n",
    "    \"mlb\": _xform_rows_mlb_nhl,\n",
    "    \"nhl\": _xform_rows_mlb_nhl,\n",
    "    \"nfl\": _xform_rows_nba_nfl,\n",
    "    \"nba\": _xform_rows_nba_nfl,\n",
    "}\n",
    "\"\"\"mapping of sport to row processing func\"\"\"\n",
    "\n",
    "\n",
    "def game_xform(\n",
    "    rows_xformer: Callable,\n",
    "    rows: pd.DataFrame,\n",
    "):\n",
    "    \"\"\"\n",
    "    rows_xformer: function with args (game_rows, away_row_idx, home_row_idx) -> (ml-list, ou, spread).\\\n",
    "        Game_rows is a dataframe with 2 rows containing home and away odds data,\\\n",
    "        and the other args are the indices for which row is home/away.\\\n",
    "        The returned values are ml-list: a list or 2 flows with the money line for the game, home/away\\\n",
    "        money line will be at index matching [away|home]_row_idx. ou and spread floats\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert len(rows) == 2, \"expecting 2 rows\"\n",
    "        if set(rows.VH) not in ({\"N\"}, {\"V\", \"H\"}):\n",
    "            raise ValueError(f\"expected rows to be order visitor, home, instead {rows.VH=}\")\n",
    "        away_row, home_row = (\n",
    "            (0, 1) if rows.VH.to_list() == [\"V\", \"H\"] or set(rows.VH) == {\"N\"} else (1, 0)\n",
    "        )\n",
    "\n",
    "        if \"Close\" in rows.columns and rows.Close.hasnans or (\"ML\" in rows and rows.ML.hasnans):\n",
    "            display(rows)\n",
    "            print(\"Skipping game with NaN for close or ml\")\n",
    "            return None\n",
    "        if len(rows.index.unique()) > 1:\n",
    "            display(rows)\n",
    "            print(\"WARNING: expected all rows to be for the same date, these do not!\")\n",
    "        if \"Rot\" in rows.columns and (rows.Rot.iloc[0] + 1) != rows.Rot.iloc[1]:\n",
    "            display(rows)\n",
    "            print(\"WARNING: expecting the rotation number to be ascending by 1, these do not\")\n",
    "\n",
    "        game_date = du_parse(rows.index[0]).date()\n",
    "\n",
    "        try:\n",
    "            epoch = db_manager.epoch_for_date(game_date)\n",
    "        except:\n",
    "            if SPORT == \"nfl\" and game_date.weekday() in (1, 2):\n",
    "                print(f\"Skipping NFL odds on {game_date} cause it is a TUES/WED\")\n",
    "                # for NFL skip tuesday and wednesday games\n",
    "                return None\n",
    "            raise\n",
    "\n",
    "        ml, overunder, spread = rows_xformer(rows, away_row, home_row)\n",
    "\n",
    "        new_row = {\n",
    "            \"date\": game_date,\n",
    "            \"season\": epoch.season,\n",
    "            \"away-team\": rows.iloc[away_row].Team,\n",
    "            \"away-abbr\": teamname_remap.get(rows.iloc[away_row].Team, rows.iloc[away_row].Team),\n",
    "            \"home-team\": rows.iloc[home_row].Team,\n",
    "            \"home-abbr\": teamname_remap.get(rows.iloc[home_row].Team, rows.iloc[home_row].Team),\n",
    "            \"away-moneyline\": ml[away_row] if ml is not None else None,\n",
    "            \"home-moneyline\": ml[home_row] if ml is not None else None,\n",
    "            \"overunder\": overunder,\n",
    "            \"spread\": spread,\n",
    "        }\n",
    "        assert len(new_row[\"home-abbr\"]) <= 3 and len(new_row[\"away-abbr\"]) <= 3, (\n",
    "            \"expecting all team abbreviations to have lenght <= 3, \"\n",
    "            f\"one of the following is too long: '{new_row[\"home-abbr\"]}', '{new_row[\"away-abbr\"]}'\"\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        display(f\"failed. {ex=} on the following rows:\")\n",
    "        display(rows)\n",
    "        raise\n",
    "    return pd.Series(new_row)\n",
    "\n",
    "\n",
    "def valid_test(filepath, df: pd.DataFrame):\n",
    "    \"\"\"validation testing on odds data\"\"\"\n",
    "\n",
    "    valid_df = df\n",
    "\n",
    "    def _test_val(stat_name, valid_min, valid_max):\n",
    "        \"\"\"\n",
    "        test that the min and max of the stat_name columne\n",
    "        are within the valid range\n",
    "        return a validated/filtered version of the DF\n",
    "        \"\"\"\n",
    "        min_val = abs(df[stat_name].min())\n",
    "        max_val = abs(df[stat_name].max())\n",
    "\n",
    "        if not (valid_min <= min_val <= valid_max and valid_min <= max_val <= valid_max):\n",
    "            print(\n",
    "                f\"In '{filepath}' {stat_name} is out of range in. abs(min) or abs(max) value was \"\n",
    "                f\"outside range. abs(min, max) = {sorted([min_val, max_val])} \"\n",
    "                f\"valid range = [{valid_min} : {valid_max}]\"\n",
    "            )\n",
    "            return f\"{valid_min} <= `{stat_name}` <= {valid_max}\"\n",
    "        return None\n",
    "\n",
    "    if filter_query := _test_val(\"spread\", *VALID_RANGE[SPORT][\"spread\"]):\n",
    "        valid_df = valid_df.query(filter_query)\n",
    "    if filter_query := _test_val(\"overunder\", *VALID_RANGE[SPORT][\"overunder\"]):\n",
    "        valid_df = valid_df.query(filter_query)\n",
    "    if filter_query := _test_val(\"home-moneyline\", 100, 15000):\n",
    "        valid_df = valid_df.query(filter_query)\n",
    "    if filter_query := _test_val(\"away-moneyline\", 100, 15000):\n",
    "        valid_df = valid_df.query(filter_query)\n",
    "    if (dropped_rows := len(df) - len(valid_df)) > 0:\n",
    "        print(f\"Validation dropped {dropped_rows} games from '{filepath}'\")\n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dfs = []\n",
    "apply_func = partial(game_xform, ROWS_FUNCS[SPORT])\n",
    "for filepath, df in (progress := tqdm(dfs.items(), desc=\"files\", total=len(dfs))):\n",
    "    progress.set_postfix_str(filepath)\n",
    "    tqdm.pandas(desc=\"games\")\n",
    "    try:\n",
    "        group_by = df.groupby(np.arange(len(df)) // 2)\n",
    "        xformed_df: pd.DataFrame = (\n",
    "            (group_by.progress_apply(apply_func).set_index(\"date\")).dropna().sort_index()\n",
    "        )\n",
    "\n",
    "        validated_df = valid_test(filepath, xformed_df)\n",
    "\n",
    "        odds_dfs.append(validated_df)\n",
    "    except NotSeasonDateError as ex:\n",
    "        display(f\"Skipping '{filepath}' data not in a fantasy season: {ex}\")\n",
    "        continue\n",
    "    except Exception as ex:\n",
    "        display(f\"Unhandled error for {filepath}... STOPPING EVERYTHING! {ex=}\")\n",
    "        raise\n",
    "\n",
    "    if TESTING_RUN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle nfl season 2022 data from betiq\n",
    "def _xform_betiq_nfl_rows(rows: pd.DataFrame, away_row: int, home_row: int):\n",
    "    \"\"\"get odds data for away/home rows betiq nfl\"\"\"\n",
    "    assert {away_row, home_row} == {0, 1}\n",
    "    if [away_row, home_row] == [0, 1]:\n",
    "        ml = rows[\"Money Line\"]\n",
    "    else:\n",
    "        ml = rows.iloc[::-1][\"Money Line\"]\n",
    "    overunder, spread = rows.iloc[0][[\"Total (O/U)\", \"Spread\"]]\n",
    "    return list(ml), overunder, spread\n",
    "\n",
    "\n",
    "if SPORT == \"nfl\":\n",
    "    betiq_df = pd.read_csv(\n",
    "        os.path.join(os.environ[\"FANTASY_ARCHIVE_BASE\"], \"nfl\", \"nfl-odds.betiq.2022.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "    )\n",
    "    betiq_df = betiq_df.assign(\n",
    "        VH=betiq_df.Location.map(lambda ha: \"V\" if ha == \"Away\" else \"H\" if ha == \"Home\" else \"N\")\n",
    "    ).set_index(\"Date\")\n",
    "    display(\"betiq data\", betiq_df)\n",
    "    group_by = betiq_df.groupby(np.arange(len(betiq_df)) // 2)\n",
    "    apply_func = partial(game_xform, _xform_betiq_nfl_rows)\n",
    "    xformed_df: pd.DataFrame = (group_by.progress_apply(apply_func).set_index(\"date\")).sort_index()\n",
    "    validated_df = valid_test(filepath, xformed_df)\n",
    "    display(\"clean betiq data\", validated_df)\n",
    "    odds_dfs.append(validated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df = pd.concat(odds_dfs)\n",
    "display(odds_df)\n",
    "print(\"------------------------ SUCCESS!!! -------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if EXT is not None:\n",
    "    sorted_df = odds_df.sort_index()\n",
    "    min_year = sorted_df.index[0].year\n",
    "    max_year = sorted_df.index[-1].year\n",
    "    dest_filepath = os.path.join(\n",
    "        os.environ['FANTASY_HOME'], f\"{SPORT}.odds-archive.{min_year}-{max_year}.{EXT}\"\n",
    "    )\n",
    "    print(f\"writing data to '{dest_filepath}'\")\n",
    "    if EXT == \"parquet\":\n",
    "        odds_df.to_parquet(dest_filepath)\n",
    "    elif EXT == \"csv\":\n",
    "        odds_df.to_csv(dest_filepath)\n",
    "    else:\n",
    "        raise ValueError(f\"Don't know how to export to '{EXT}'\")\n",
    "else:\n",
    "    print(\"Not saving results...\")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

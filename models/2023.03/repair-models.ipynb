{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repair initial models\n",
    "Do not run this top to bottom, each cell has a different fix for a\n",
    "different problems that occured during the development of the updated\n",
    "model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols: dict[str, list[str]] = {}\n",
    "\"\"\"previously infered data columns, model-filename->columns\"\"\"\n",
    "\n",
    "imputations: dict[str, dict[str, float]] = {}\n",
    "\"\"\"previously infered imputation values, model-filename->dict[col-name,impute-value]\"\"\"\n",
    "\n",
    "data_filenames: dict[tuple[str, str], str] = {\n",
    "    (\"mlb\", \"h\"): \"mlb_hitter.csv\",\n",
    "    (\"mlb\", \"p\"): \"mlb_pitcher.csv\",\n",
    "    (\"nba\", \"dk\"): \"nba_player.csv\",\n",
    "    (\"nfl\", \"def\"): \"nfl_team.csv\",\n",
    "    (\"nfl\", \"wrte\"): \"nfl_wrte.csv\",\n",
    "    (\"nfl\", \"qb\"): \"nfl_qb.csv\",\n",
    "    (\"nfl\", \"rb\"): \"nfl_rb.csv\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "from train_test import load_csv, infer_feature_cols, infer_imputes\n",
    "\n",
    "\"\"\"\n",
    "The original models did not include the input columns or impute values. \n",
    "This notebook will add 'input_col' to the 'data_def' and impute_values to \n",
    "trained_parameters for all existing models\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# iterate through all .model files\n",
    "for model_filepath in glob(\"*model\"):\n",
    "    print(f\"Adding cols to '{model_filepath}\")\n",
    "\n",
    "    # load model json\n",
    "    with open(model_filepath, \"r\") as f_:\n",
    "        model_json = json.load(f_)\n",
    "    include_position = (\n",
    "        model_json[\"training_data_def\"][\"include_pos\"]\n",
    "        if model_json[\"training_data_def\"][\"target\"][1] == \"P\"\n",
    "        else None\n",
    "    )\n",
    "    model_positions = model_json[\"training_data_def\"].get(\"training_pos\")\n",
    "    print(f\"{model_json['name']=} {include_position}\")\n",
    "\n",
    "    # load data used to create the model\n",
    "    sport: str\n",
    "    extra: str\n",
    "    sport, extra = model_json[\"name\"].lower().split(\"-\", 3)[:2]\n",
    "    data_filename = os.path.join(\n",
    "        os.environ[\"FANTASY_HOME\"],\n",
    "        data_filenames.get((sport, extra), f\"{sport}_{extra}.csv\"),\n",
    "    )\n",
    "\n",
    "    print(f\"Getting cols&imputation for {sport=} {extra=} in '{data_filename}'\")\n",
    "    if data_filename not in data_cols or data_filename not in imputations:\n",
    "        train_df = load_csv(\n",
    "            data_filename,\n",
    "            include_position=include_position,\n",
    "        )\n",
    "\n",
    "    if data_filename not in data_cols:\n",
    "        cols = train_df.columns.to_list()\n",
    "        data_cols[data_filename] = infer_feature_cols(cols, include_position)\n",
    "    feature_cols = data_cols[data_filename]\n",
    "\n",
    "    if data_filename not in imputations:\n",
    "        imputations[data_filename] = infer_imputes(train_df[feature_cols])\n",
    "    impute_values = imputations[data_filename]\n",
    "\n",
    "    print(f\"For '{data_filename}'\")\n",
    "    print(f\"\\t{len(feature_cols)} input columns\", feature_cols)\n",
    "    print(f\"\\t{len(impute_values)} imputation values\", impute_values)\n",
    "\n",
    "    # update model json with the column names\n",
    "    model_json[\"training_data_def\"][\"input_cols\"] = feature_cols\n",
    "    model_json[\"trained_parameters\"][\"impute_values\"] = impute_values\n",
    "\n",
    "    # save updated json\n",
    "    # with open(model_filepath, \"w\") as f_:\n",
    "    #     json.dump(model_json, f_, indent=\"\\t\")\n",
    "\n",
    "    # print(\"Wrote file\\n--------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "\n",
    "\n",
    "for model_filepath in glob(\"*model\"):\n",
    "    # load model json\n",
    "    with open(model_filepath, \"r\") as f_:\n",
    "        model_json = json.load(f_)\n",
    "    recent_games = model_json[\"training_data_def\"][\"recent_games\"]\n",
    "\n",
    "    new_imputes = {}\n",
    "    impute_sources = {}\n",
    "    no_impute = []\n",
    "\n",
    "    for col in model_json[\"training_data_def\"][\"input_cols\"]:\n",
    "        if not col.endswith(\":std-mean\"):\n",
    "            continue\n",
    "        feature = col.rsplit(\":\", 1)[0]\n",
    "        if (\n",
    "            impute_value := model_json[\"trained_parameters\"][\"impute_values\"].get(col)\n",
    "        ) is not None:\n",
    "            impute_sources[feature] = col\n",
    "            new_imputes[feature] = impute_value\n",
    "            continue\n",
    "\n",
    "        source = feature + \":recent-mean\"\n",
    "        if (\n",
    "            impute_value := model_json[\"trained_parameters\"][\"impute_values\"].get(\n",
    "                source\n",
    "            )\n",
    "        ) is not None:\n",
    "            impute_sources[feature] = source\n",
    "            new_imputes[feature] = impute_value\n",
    "            continue\n",
    "\n",
    "        for recent_i in range(1, recent_games + 1):\n",
    "            recent_key = feature + f\":recent-{recent_i}\"\n",
    "            if (\n",
    "                impute_value := model_json[\"trained_parameters\"][\"impute_values\"].get(\n",
    "                    recent_key\n",
    "                )\n",
    "            ) is None:\n",
    "                continue\n",
    "            impute_sources[feature] = source\n",
    "            new_imputes[feature] = impute_value\n",
    "            break\n",
    "        else:\n",
    "            no_impute.append(col)\n",
    "    print(f\"For '{model_filepath}':\\n\\t{no_impute=}\")\n",
    "    for k_, value in new_imputes.items():\n",
    "        print(f\"\\t{k_}\\t{impute_sources[k_]}\\t{value}\")\n",
    "    print()\n",
    "\n",
    "    model_json[\"trained_parameters\"][\"impute_values\"] = new_imputes\n",
    "\n",
    "    # save updated json\n",
    "    # with open(model_filepath, \"w\") as f_:\n",
    "    #     json.dump(model_json, f_, indent=\"\\t\")\n",
    "\n",
    "    # print(\"Wrote file\\n--------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006d5deb8e6cdcd4312641bdf15f3bc20f0769a7305d81173599a7b40f33b4a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

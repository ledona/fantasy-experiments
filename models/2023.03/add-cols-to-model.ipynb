{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Input Columns\n",
    "The original models did not include the input columns. This\n",
    "notebook will add 'input_col' to the data_def dict of all\n",
    "models previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols: dict[str, list[str]] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from train_test import load_csv, infer_feature_cols\n",
    "\n",
    "data_filenames: dict[tuple[str, str], str] = {\n",
    "    (\"mlb\", \"h\"): \"mlb_hitter.csv\",\n",
    "    (\"mlb\", \"p\"): \"mlb_pitcher.csv\",\n",
    "    (\"nba\", \"dk\"): \"nba_player.csv\",\n",
    "    (\"nfl\", \"def\"): \"nfl_team.csv\",\n",
    "    (\"nfl\", \"wrte\"): \"nfl_wrte.csv\",\n",
    "    (\"nfl\", \"qb\"): \"nfl_qb.csv\",\n",
    "    (\"nfl\", \"rb\"): \"nfl_rb.csv\",\n",
    "}\n",
    "\n",
    "# iterate through all .model files\n",
    "for model_filepath in glob(\"*model\"):\n",
    "    print(f\"Adding cols to '{model_filepath}\")\n",
    "\n",
    "    # load model json\n",
    "    with open(model_filepath, \"r\") as f_:\n",
    "        model_json = json.load(f_)\n",
    "    include_position = (\n",
    "        model_json[\"training_data_def\"][\"include_pos\"]\n",
    "        if model_json[\"training_data_def\"][\"target\"][1] == \"P\"\n",
    "        else None\n",
    "    )\n",
    "    print(f\"{model_json['name']=} {include_position}\")\n",
    "\n",
    "    # load data used to create the model\n",
    "    sport: str\n",
    "    extra: str\n",
    "    sport, extra = model_json[\"name\"].lower().split(\"-\", 3)[:2]\n",
    "    data_filename = os.path.join(\n",
    "        os.environ[\"FANTASY_HOME\"],\n",
    "        data_filenames.get((sport, extra), f\"{sport}_{extra}.csv\"),\n",
    "    )\n",
    "    print(f\"Getting cols for {sport=} {extra=} in '{data_filename}'\")\n",
    "    if data_filename not in data_cols:\n",
    "        df = load_csv(\n",
    "            data_filename,\n",
    "            include_position=include_position,\n",
    "        )\n",
    "\n",
    "        cols = df.columns.to_list()\n",
    "        data_cols[data_filename] = cols\n",
    "    else:\n",
    "        cols = data_cols[data_filename]\n",
    "    feature_cols = infer_feature_cols(cols, include_position)\n",
    "    print(f\"{len(feature_cols)} input columns for '{data_filename}'\", feature_cols)\n",
    "\n",
    "    # update model json with the column names\n",
    "    model_json[\"training_data_def\"][\"input_cols\"] = feature_cols\n",
    "\n",
    "    # save updated json\n",
    "    with open(model_filepath, \"w\") as f_:\n",
    "        json.dump(model_json, f_, indent=\"\\t\")\n",
    "\n",
    "    print(\"Wrote file\\n--------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43f6de4c73471de4f85bddb5a3a429607c6cc5f8b571a49e43215c51d355d639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

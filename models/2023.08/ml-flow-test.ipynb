{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Testing\n",
    "\n",
    "This notebook tests MLFlow model management.\n",
    "\n",
    "1. python -m venv venv\n",
    "2. venv/bin/pip install mlflow\n",
    "3. venv/bin/mlflow server --backend-store-uri sqlite:///mlflow.sqlite --default-artifact-root file://mlflow-artifacts --dev\n",
    "\n",
    "\n",
    "Hitting a roadblock for SFTP artifact storage from local server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from fantasy_py import log\n",
    "from fantasy_py.inference import Model\n",
    "\n",
    "\n",
    "_LOGGER = log.get_logger(__name__)\n",
    "_LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def archive_model(\n",
    "    model_filepath: str,\n",
    "    experiment_name: str,\n",
    "    experiment_description: None | str = None,\n",
    "    run_name: str | None = None,\n",
    "    run_description: str | None = None,\n",
    "    tracker_settings: dict | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Archive the model at the filepath, useful if the model already exists\n",
    "    For new training runs use do_training_run instead\n",
    "\n",
    "    model - if None the load the model object from the filepath,\n",
    "        if not None then assume this is the model for at the filepath\n",
    "    \"\"\"\n",
    "    _LOGGER.debug(\"archiving model at '%s'\", model_filepath)\n",
    "    model = Model.load(model_filepath)\n",
    "    model_name = model.name\n",
    "    sport, pos, service = model_name.split(\"-\")\n",
    "    pt = None\n",
    "    raise NotImplementedError(\"make sure that sport, pos, service are valid\")\n",
    "    raise NotImplementedError(\"parse pos into player/team\")\n",
    "\n",
    "    metrics = model.performance.copy()\n",
    "    run_tags = {\n",
    "        \"sport\": sport,\n",
    "        \"service\": service,\n",
    "        \"player-team\": pt,\n",
    "        \"target\": model.target,\n",
    "        \"metrics-seasons\": [metrics.pop(\"season\")],\n",
    "        \"framework\": \"tpot\",\n",
    "        **model.parameters,\n",
    "    }\n",
    "\n",
    "    return train_and_log(\n",
    "        experiment_name,\n",
    "        (lambda _: (model, model.name, metrics, model.artifacts, None)),\n",
    "        experiment_description=experiment_description,\n",
    "        run_name=run_name,\n",
    "        run_description=run_description,\n",
    "        tracker_settings=tracker_settings,\n",
    "        run_tags=run_tags,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from fantasy_py import get_git_desc\n",
    "\n",
    "\n",
    "EXP_NAME = \"2023.08-test\"\n",
    "EXP_DESC = \"test experiment description\"\n",
    "MODEL_FILEPATH = os.path.join(\n",
    "    \"..\", \"2023.03\", \"LOL-player-DK.dk_performance_score.tpot.model\"\n",
    ")\n",
    "MODEL_TAGS = {\n",
    "    \"framework\": \"tpot\",\n",
    "}\n",
    "archive_model(\n",
    "    MODEL_FILEPATH,\n",
    "    EXP_NAME,\n",
    "    experiment_description=EXP_DESC,\n",
    "    tracker_settings={\"mlf_tracking_uri\": \"http://localhost:5000\"},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"calc_name": "keras", "calc_params": {"calc_stats": {"cur_opp_team_stats": ["def_fumble_recov", "def_int", "def_sacks", "op_passing_yds", "op_pts", "op_rushing_yds", "op_turnovers", "op_yds", "pen_yds", "pens", "pts", "turnovers", "win", "yds"], "extra_stats": ["home_C", "modeled_stat_std_mean", "modeled_stat_trend", "player_home_H", "player_win"], "model_player_stat": "dk_score_off#2", "model_team_stat": null, "player_stats": ["fumbles_lost", "passing_att", "passing_cmp", "passing_ints", "passing_tds", "passing_twoptm", "passing_yds", "rushing_att", "rushing_tds", "rushing_twoptm", "rushing_yds", "tds"], "prev_opp_team_stats": [], "team_stats": ["def_fumble_recov", "def_int", "op_pts", "op_turnovers", "op_yds", "passing_yds", "pen_yds", "pens", "pts", "rushing_yds", "turnovers", "win", "yds"]}, "impute": true, "models_path": "./MODELS_keras", "normalize": true, "player_pos": ["QB"]}, "datetime_utc": "20191017 043813", "db_id": 1, "db_path": "nfl_hist_2009-2018.scored.db", "fantasy_version": "v2019.10.16", "filename_prefix": "nfl_dk_QB_DNN_ADA", "folds": 3, "hyper_dists": {"activation": {"cls": "HPCategoricalDist", "name": "activation", "values": ["linear", "relu", "tanh", "sigmoid"]}, "dropout": {"cls": "HPNumericDist", "dist_type": "float", "high": 0.7, "low": 0.3, "max_float_percision": 10, "name": "dropout"}, "hist_agg": {"cls": "HPCategoricalDist", "name": "hist_agg", "values": ["mean", "median", "none"]}, "layers": {"cls": "HPNumericDist", "dist_type": "int", "high": 5, "increment": 1, "low": 1, "name": "layers"}, "learning_method": {"cls": "HPCategoricalDist", "name": "learning_method", "values": ["adagrad", "adadelta", "adam", "adamax", "nadam"]}, "n_cases": {"cls": "HPNumericDist", "dist_type": "int", "high": 2200, "increment": 1, "low": 500, "name": "n_cases"}, "n_features": {"cls": "HPConstantDist", "name": "n_features", "value": null}, "n_games": {"cls": "HPNumericDist", "dist_type": "int", "high": 7, "increment": 1, "low": 1, "name": "n_games"}, "steps": {"cls": "HPNumericDist", "dist_type": "int", "high": 1000, "increment": 100, "low": 100, "name": "steps"}, "units": {"cls": "HPNumericDist", "dist_type": "int", "high": 100, "increment": 1, "low": 20, "name": "units"}}, "random_seed": 1467449986, "resume_datetimes": null, "scoring": ["mae", "r2"], "search": {"bayes_fail_fast": false, "bayes_init_pts": 7, "bayes_retry_cache": true, "iterations": 70, "method": "bayes", "pretend": false}, "search_bayes_scoring_method": "mae", "season_parts": ["REG"], "seasons": [2018, 2017, 2016, 2015, 2014, 2013, 2012]}
score_mae	score_r2	activation	dropout	hist_agg	layers	learning_method	n_cases	n_features	n_games	steps	units
-7.0514308	0.1263714	linear	0.3611543058	none	2	adam	1068	167	4	500	40
-6.4616419	0.211582	linear	0.3175131241	mean	4	adagrad	1378	44	5	100	77
-8.1315635	-0.1833536	relu	0.5391562092	none	5	adagrad	1693	85	2	800	45
-7.5408449	-0.024701	linear	0.4107216047	none	2	adadelta	1005	208	5	900	67
-7.3588167	0.0368139	sigmoid	0.5811443505	none	4	nadam	614	249	6	400	48
-6.9065081	0.1425464	tanh	0.5864221118	mean	5	adadelta	1242	44	1	700	68
-6.8194051	0.1231791	sigmoid	0.4594186874	median	5	adadelta	980	44	5	200	73
-6.6041072	0.1802806	sigmoid	0.3	median	2	adagrad	1579	44	7	100	77
-6.601021	0.181822	linear	0.3	mean	1	adagrad	2200	44	7	100	88
-6.7110576	0.1026867	linear	0.3	median	5	adagrad	500	44	7	100	100
-6.6038951	0.2113085	linear	0.3	mean	1	adagrad	2200	44	1	100	20
-6.5811356	0.1962202	linear	0.3	mean	5	adagrad	1335	44	7	100	100
-7.2095108	0.0689625	sigmoid	0.3496886414	mean	5	adagrad	500	44	7	700	100
-6.4236936	0.2063965	linear	0.3251207456	mean	5	adagrad	872	44	6	100	99
-6.5971507	0.1685487	linear	0.3328667808	mean	5	adagrad	500	44	7	100	100
-6.8937026	0.1062147	sigmoid	0.3	mean	5	adagrad	1044	44	6	100	100
-6.5749997	0.1620895	linear	0.5187713883	mean	5	adam	500	44	7	100	100
-6.929439	0.073141	linear	0.7	mean	5	adam	500	44	6	100	100
-6.4482187	0.205246	linear	0.3575763516	mean	3	adamax	1042	44	5	100	73
-6.6112625	0.175166	linear	0.3915404733	mean	5	adam	1878	44	5	100	84
-6.4850609	0.1611747	linear	0.334111166	mean	5	adamax	500	44	6	100	100
-6.7082324	0.1552811	linear	0.3	median	4	adadelta	1652	44	5	100	75
-7.4032431	0.0018946	linear	0.3	none	5	adamax	500	167	4	100	100
-6.6029845	0.1334787	linear	0.3	mean	5	adamax	500	44	5	100	94
-6.5921298	0.1315862	linear	0.4425444882	mean	5	adamax	500	44	5	100	100
-7.72908	-0.1557086	relu	0.3434833018	mean	5	adamax	500	44	7	100	100
-6.9201402	0.1712778	sigmoid	0.3	median	1	adam	500	44	7	100	100
-7.0226214	0.0117574	tanh	0.4618387886	mean	5	adagrad	500	44	7	100	20
-6.6375145	0.1429429	linear	0.3831238424	mean	5	adamax	500	44	7	100	100
-6.6380518	0.1407257	linear	0.3	mean	5	adamax	500	44	7	100	97
-6.5151778	0.1932027	linear	0.3145970465	mean	1	adagrad	820	44	2	100	78
-6.5649206	0.2065179	linear	0.3249419148	mean	1	adagrad	559	44	1	100	41
-6.6786756	0.2210776	linear	0.339203002	mean	1	adagrad	639	44	1	100	28
-6.6091343	0.1989055	linear	0.3	mean	1	adagrad	1836	44	5	100	99
-6.7357758	0.1275858	linear	0.3	mean	5	nadam	538	44	7	100	100
-6.6053474	0.2113945	linear	0.7	median	1	adam	2106	44	1	1000	44
-6.6223433	0.1688719	relu	0.3	median	1	adagrad	2200	44	6	1000	32
-6.5382816	0.1978172	linear	0.3	median	1	adagrad	1689	44	4	1000	20
-6.5605772	0.1975455	linear	0.3	median	2	nadam	2200	44	6	1000	48
-6.5866183	0.2023638	linear	0.3	median	1	adagrad	2200	44	2	1000	20
-6.6087936	0.1862566	linear	0.3	median	1	nadam	2046	44	7	1000	37
-6.5517086	0.2137558	linear	0.3	median	1	adagrad	2200	44	3	1000	38
-6.5866183	0.2023638	linear	0.3	median	1	adagrad	2200	44	2	1000	20
-6.5559886	0.2138028	linear	0.3	median	1	adagrad	2200	44	3	1000	69
-6.5177858	0.1943329	linear	0.3	median	1	adagrad	2200	44	5	1000	73
-6.5444129	0.1941296	linear	0.3	median	1	adagrad	2113	44	7	1000	100
-6.8645926	0.0989591	linear	0.3230376772	mean	4	adagrad	500	44	7	100	81
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.6085863	0.154454	linear	0.3	median	1	adagrad	500	44	7	1000	100
-6.5982089	0.183182	linear	0.3	median	1	adagrad	2200	44	7	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5940815	0.1962797	linear	0.3257985379	mean	5	nadam	1755	44	5	100	93
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5199669	0.1948476	linear	0.3163384483	mean	5	adamax	1797	44	6	100	67
-6.6065363	0.2080115	linear	0.7	median	1	adagrad	2200	44	1	1000	52
-6.6784649	0.1733779	linear	0.3257834059	mean	5	adagrad	701	44	5	100	83
-6.6942169	0.2108567	linear	0.3512324696	mean	3	adamax	1096	44	1	100	39
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.4945718	0.2042594	linear	0.3150047769	mean	4	adagrad	1741	44	4	100	75
-6.6517535	0.1927598	linear	0.3315354064	mean	4	adamax	876	44	5	100	100
-6.5856829	0.2151106	linear	0.7	median	1	adagrad	2200	44	1	1000	100
-6.4849158	0.1956155	linear	0.3	mean	4	adagrad	1782	44	5	100	20
-6.7527376	0.117421	linear	0.3587628906	mean	3	adamax	682	44	6	100	82
-6.6129877	0.2115829	linear	0.3	median	1	adagrad	2200	44	1	1000	98
